{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folder-wise Fast Microscopy Picture Analysis\n",
    "The following code opens a folder of the SlideScanner Microscope and automatically sets ROIs to the darkest and brightest portions of the picture. Consequently, it removes the background through the ROIs at the darkest positions and calculates the mean fluorescence at the brighter spots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tiff\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "from skimage import measure, draw\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "\n",
    "import gc\n",
    "import concurrent.futures as cf\n",
    "import multiprocessing\n",
    "import threading\n",
    "\n",
    "from AutoImgUtils import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up Matplotlib\n",
    "matplotlib.use('Agg')  # Use the Agg backend for non-interactive plotting\n",
    "plt_lock = threading.Lock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_serializable(obj):\n",
    "    \"\"\"\n",
    "    Convert NumPy types to native Python types for JSON serialization.\n",
    "    Handles nested dictionaries and lists.\n",
    "    \"\"\"\n",
    "    if isinstance(obj, (np.integer, np.int64, np.uint64)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.floating, np.float32, np.float64)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, (np.ndarray,)):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_serializable(i) for i in obj]\n",
    "    elif isinstance(obj, (np.bool_,)):\n",
    "        return bool(obj)\n",
    "    elif obj is None or isinstance(obj, (str, bool, int, float)):\n",
    "        return obj\n",
    "    else:\n",
    "        # Try to convert other types to string or their representation\n",
    "        try:\n",
    "            return str(obj)\n",
    "        except:\n",
    "            return repr(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_optimal_radius(reference_image_path, config):\n",
    "    \"\"\"\n",
    "    Calculate the optimal ROI radius from a reference image.\n",
    "    \n",
    "    Parameters:\n",
    "        reference_image_path (str): Path to the reference image\n",
    "        config (dict): Configuration parameters\n",
    "        \n",
    "    Returns:\n",
    "        int: The calculated optimal radius\n",
    "    \"\"\"\n",
    "    print(f\"Calculating optimal radius from reference image: {os.path.basename(reference_image_path)}\")\n",
    "    \n",
    "    # Extract parameters with defaults\n",
    "    lower_thresh_chan = config.get('lower_thresh_factor', [2, 3, 2, 2])\n",
    "    upper_thresh = config.get('upper_thresh', 60000)\n",
    "    background_threshold = config.get('background_threshold', None)\n",
    "    mask_channel = config.get('mask_channel', 1) - 1\n",
    "    channel_of_interest = config.get('channel_of_interest', 1) - 1\n",
    "    single_ch_background = config.get('single_ch_background', True)\n",
    "    \n",
    "    # Load the image\n",
    "    image = tiff.imread(reference_image_path)\n",
    "    image = np.moveaxis(image, 0, -1)\n",
    "    \n",
    "    # Subtract background\n",
    "    if single_ch_background:\n",
    "        background_values, mean_background_value, background_subtracted_image = bg_substraction_ROI_single_ch(\n",
    "            image, background_threshold, channel_of_interest, display_rois=False)\n",
    "    else:\n",
    "        background_values, mean_background_value, background_subtracted_image = bg_substraction_ROI(\n",
    "            image, background_threshold, display_rois=False)\n",
    "    \n",
    "    # Find regions in mask channel\n",
    "    channel_thresh = 2 * np.std(background_subtracted_image[:, :, mask_channel]) + np.mean(background_subtracted_image[:, :, mask_channel])\n",
    "    print(f'Channel threshold for mask channel {mask_channel+1}: {channel_thresh}')\n",
    "    thresh = (background_subtracted_image[:, :, mask_channel] > channel_thresh) & (background_subtracted_image[:, :, mask_channel] < upper_thresh)\n",
    "    labels = measure.label(thresh)\n",
    "    mask_props = measure.regionprops(labels)\n",
    "    \n",
    "    # Find regions in channel of interest\n",
    "    channel_thresh_interest = lower_thresh_chan[channel_of_interest] * np.std(background_subtracted_image[:, :, channel_of_interest]) + np.mean(background_subtracted_image[:, :, channel_of_interest])\n",
    "    print(f'Channel threshold for channel of interest {channel_of_interest+1}: {channel_thresh_interest}')\n",
    "    thresh_interest = (background_subtracted_image[:, :, channel_of_interest] > channel_thresh_interest) & (background_subtracted_image[:, :, channel_of_interest] < upper_thresh)\n",
    "    labels_interest = measure.label(thresh_interest)\n",
    "    props_interest = measure.regionprops(labels_interest)\n",
    "    \n",
    "    # Match regions and calculate radius\n",
    "    matched_radii = []\n",
    "    \n",
    "    for mask_prop in mask_props:\n",
    "        mask_x, mask_y = int(mask_prop.centroid[1]), int(mask_prop.centroid[0])\n",
    "        \n",
    "        for interest_prop in props_interest:\n",
    "            interest_x, interest_y = int(interest_prop.centroid[1]), int(interest_prop.centroid[0])\n",
    "            \n",
    "            distance = np.sqrt((mask_x - interest_x)**2 + (mask_y - interest_y)**2)\n",
    "            max_distance = np.sqrt(mask_prop.area) / 2\n",
    "            \n",
    "            if distance <= max_distance:\n",
    "                interest_radius = np.sqrt(interest_prop.area / np.pi)\n",
    "                matched_radii.append(interest_radius)\n",
    "                break\n",
    "    \n",
    "    if len(matched_radii) > 0:\n",
    "        mean_radius = np.mean(matched_radii)\n",
    "        std_radius = np.std(matched_radii)\n",
    "        radius_factor = int(mean_radius)\n",
    "        \n",
    "        print(f'Mean radius from matched regions: {mean_radius:.2f} Â± {std_radius:.2f} pixels')\n",
    "        print(f'Found {len(matched_radii)} matching regions between mask and channel of interest')\n",
    "        print(f'Using radius_factor = {radius_factor} for all subsequent processing')\n",
    "    else:\n",
    "        # Fall back to using the mask channel\n",
    "        areas = [prop.area for prop in mask_props]\n",
    "        radii = [np.sqrt(area/np.pi) for area in areas]\n",
    "        mean_radius = np.mean(radii)\n",
    "        radius_factor = int(mean_radius)\n",
    "        \n",
    "        print(f'No matching regions found. Using mask channel. Mean radius: {mean_radius:.2f} pixels')\n",
    "        print(f'Using radius_factor = {radius_factor} for all subsequent processing')\n",
    "    \n",
    "    # Save histogram of matched radii\n",
    "    plt.hist(matched_radii, bins=40, edgecolor='black')\n",
    "    plt.title('Histogram of Matched Radii')\n",
    "    plt.xlabel('Radius (pixels)')\n",
    "    plt.ylabel('Frequency')\n",
    "    histogram_path = os.path.join(os.path.dirname(reference_image_path), 'matched_radii_histogram.png')\n",
    "    plt.savefig(histogram_path)\n",
    "    plt.close()\n",
    "    print(f'Histogram of matched radii saved to {histogram_path}')\n",
    "    \n",
    "\n",
    "    # Force garbage collection to free memory \n",
    "    gc.collect()\n",
    "    \n",
    "    return radius_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(stacked_image_path, config):\n",
    "    '''\n",
    "    # Function to process a single set of 4-channel images and return analysis results\n",
    "    \n",
    "    Parameters:\n",
    "        stacked_image_path (string): Path to the multi-channel TIFF image\n",
    "        config (dict): Configuration parameters including:\n",
    "            - lower_thresh_factor: List of threshold factors for each channel\n",
    "            - upper_thresh: Upper threshold to avoid very bright spots\n",
    "            - background_threshold: Threshold for background values\n",
    "            - radius_factor: Radius for circular ROIs\n",
    "            - channel_of_interest: Primary channel to analyze (1-indexed)\n",
    "            - mask_channel: Channel to use for ROI detection (1-indexed)\n",
    "            - single_ch_background: Whether to calculate background per channel\n",
    "            \n",
    "    Returns:\n",
    "        dict: A structured dictionary containing all analysis results:\n",
    "            - image_info: Basic image metadata\n",
    "            - summary: Aggregated statistics across all cells\n",
    "            - background: Background measurement values\n",
    "            - cell_data: Individual measurements for all detected cells\n",
    "            - roi_data: Legacy ROI information for backward compatibility\n",
    "    '''\n",
    "    \n",
    "    # Extract parameters with defaults\n",
    "    lower_thresh_chan = config.get('lower_thresh_factor', [2, 3, 2, 2])\n",
    "    upper_thresh = config.get('upper_thresh', 60000)\n",
    "    background_threshold = config.get('background_threshold', None)\n",
    "    radius_factor = config.get('radius_factor', 10)\n",
    "    mask_channel = config.get('mask_channel', 1)\n",
    "    channel_of_interest = config.get('channel_of_interest', 1)\n",
    "    single_ch_background = config.get('single_ch_background', True)\n",
    "\n",
    "    channel_of_interest -= 1\n",
    "    mask_channel -= 1\n",
    "    \n",
    "    image = tiff.imread(stacked_image_path)\n",
    "    image = np.moveaxis(image, 0, -1)\n",
    "    base_name = os.path.splitext(stacked_image_path)[0]\n",
    "\n",
    "    n_channels = image.shape[2]\n",
    "\n",
    "    # Initialize dictionaries to store the mean fluorescence and background values \n",
    "    mean_fluorescence = {f'Channel {i+1}': [] for i in range(n_channels)}\n",
    "    background_values = {f'Channel {i+1}': [] for i in range(n_channels)}\n",
    "    positive_results = {f'Channel {i+1}': [] for i in range(n_channels)}\n",
    "    corrected_total_fluorescence = {f'Channel {i+1}': [] for i in range(n_channels)}\n",
    "    \n",
    "    # NEW: Create dictionary to store individual cell data with positive/negative flags\n",
    "    cell_data = {f'Channel {i+1}': [] for i in range(n_channels)}\n",
    "\n",
    "    # Subtract background from the image and display the background ROIs on the channel of interest\n",
    "    if single_ch_background:\n",
    "        background_values, mean_background_value, background_subtracted_image = bg_substraction_ROI_single_ch(image, background_threshold,channel_of_interest, display_rois=False)\n",
    "    else:\n",
    "        background_values, mean_background_value, background_subtracted_image = bg_substraction_ROI(image, background_threshold, display_rois=False)\n",
    "\n",
    "    # Display the histogram of the background subtracted image\n",
    "    # Use explicit figure creation and management\n",
    "    fig = plt.figure(figsize=(n_channels*4, 10))\n",
    "    axs = fig.subplots(1, n_channels)\n",
    "\n",
    "    for ax, channel_index in zip(axs, range(n_channels)):\n",
    "        ax.hist(image[:, :, channel_index].ravel(), bins=256, color='gray', alpha=0.75)\n",
    "        ax.set_title(f\"Histogram for Channel {channel_index+1}\")\n",
    "        ax.set_xlabel(\"Pixel intensity\")\n",
    "        ax.set_ylabel(\"Frequency\")\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_xscale('log')\n",
    "        ax.axvline(mean_background_value[channel_index], color='r', linestyle='dashed', linewidth=1)\n",
    "        ax.axvline(lower_thresh_chan[channel_index] * np.std(image[:, :, channel_index]) + np.mean(image[:, :, channel_index]), color='g', linestyle='dashed', linewidth=1)\n",
    "\n",
    "    # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "    for ax in axs.flat:\n",
    "        ax.label_outer()\n",
    "    \n",
    "    output_path = base_name + \"_0_histogram.png\"\n",
    "    with plt_lock:\n",
    "        fig.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close(fig)\n",
    "\n",
    "    # Apply thresholds to find maximum values in the background-subtracted depending on channel of interest, avoiding very bright spots\n",
    "    channel_thresh = 2 * np.std(background_subtracted_image[:, :, mask_channel]) + np.mean(background_subtracted_image[:, :, mask_channel])\n",
    "    print(f'Channel threshold for mask channel {mask_channel+1}: {channel_thresh}')\n",
    "    thresh = (background_subtracted_image[:, :, mask_channel] > channel_thresh) & (background_subtracted_image[:, :, mask_channel] < upper_thresh)\n",
    "\n",
    "    # Label the thresholded regions and return the number of cells\n",
    "    labels = measure.label(thresh)\n",
    "    props = measure.regionprops(labels)\n",
    "    \n",
    "    # Create circular ROIs around detected points\n",
    "    rois = []\n",
    "\n",
    "    for prop in props:\n",
    "        y, x = prop.centroid\n",
    "        radius = radius_factor \n",
    "        rois.append((int(x), int(y), int(radius)))\n",
    "\n",
    "    # Calculate mean fluorescence values for each channel and check if the signal is present\n",
    "    for channel_index in range(n_channels):\n",
    "        channel = background_subtracted_image[:, :, channel_index]\n",
    "        channel_thresh = 2 * lower_thresh_chan[channel_index] * np.std(channel) + np.mean(channel)\n",
    "\n",
    "        # Store each ROI index for reference\n",
    "        roi_index = 0\n",
    "        \n",
    "        for roi in rois:\n",
    "            x, y, radius = roi\n",
    "            rr, cc = draw.disk((y, x), radius, shape=channel.shape)\n",
    "            roi_area = channel[rr, cc]\n",
    "            mean_value = np.mean(roi_area)\n",
    "            integrated_density = np.sum(roi_area)\n",
    "            \n",
    "            # Determine if the cell is positive based on the threshold\n",
    "            is_positive = mean_value > channel_thresh\n",
    "            \n",
    "            # Store ALL cell data regardless of positive/negative status\n",
    "            cell_data[f'Channel {channel_index+1}'].append({\n",
    "                'roi_index': roi_index,\n",
    "                'position': (x, y, radius),\n",
    "                'mean_fluorescence': float(mean_value),  # Convert numpy types to native Python for serialization\n",
    "                'integrated_density': float(integrated_density),\n",
    "                'is_positive': bool(is_positive)\n",
    "            })\n",
    "            \n",
    "            # For backward compatibility, maintain previous data structures\n",
    "            if is_positive:\n",
    "                positive_results[f'Channel {channel_index+1}'].append((x, y, radius))\n",
    "                mean_fluorescence[f'Channel {channel_index+1}'].append(mean_value)\n",
    "                corrected_total_fluorescence[f'Channel {channel_index+1}'].append(integrated_density)\n",
    "            else:\n",
    "                positive_results[f'Channel {channel_index+1}'].append(None)\n",
    "                corrected_total_fluorescence[f'Channel {channel_index+1}'].append(None)\n",
    "            \n",
    "            roi_index += 1\n",
    "\n",
    "    # fig = plt.figure(figsize=(n_channels * 5, 20))\n",
    "    # axs = fig.subplots(1, n_channels)\n",
    "\n",
    "    # axs[0].imshow(normalize(image[:,:,0]), cmap='gray')\n",
    "    # axs[1].imshow(normalize(image[:,:,1]), cmap='gray')\n",
    "    # axs[2].imshow(normalize(image[:,:,2]), cmap='gray')\n",
    "    # axs[3].imshow(normalize(image[:,:,3]), cmap='gray')\n",
    "\n",
    "    # for ax, channel_index in zip(axs, range(n_channels)):\n",
    "    #     ax.set_title(f'Channel {channel_index+1} (Raw)')\n",
    "\n",
    "    # # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "    # for ax in axs.flat:\n",
    "    #     ax.label_outer()\n",
    "    #     ax.axis('off')\n",
    "\n",
    "    # output_path = base_name + \"_1_Originals.png\"\n",
    "    # with plt_lock:\n",
    "    #     fig.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
    "    #     plt.close(fig)\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "    # Delete original image to free memory\n",
    "    del image\n",
    "\n",
    "    # Display positive ROIs for each channel\n",
    "    fig = plt.figure(figsize=(n_channels * 5, 20))\n",
    "    ax = fig.subplots(1, n_channels)\n",
    "\n",
    "    for channel_index in range(n_channels):\n",
    "        channel_image = np.stack([normalize(background_subtracted_image[:, :, channel_index])]*3, axis=-1)  # Convert to RGB\n",
    "\n",
    "        for roi in positive_results[f'Channel {channel_index+1}']:\n",
    "            if roi is not None:\n",
    "                x, y, radius = roi\n",
    "                rr, cc = draw.disk((y, x), radius, shape=channel_image.shape)\n",
    "                channel_image[rr, cc] = [0, 1, 0]  # Green for positive ROIs\n",
    "\n",
    "        ax[channel_index].imshow(channel_image)\n",
    "        ax[channel_index].set_title(f'Positive ROIs on Channel {channel_index + 1}')\n",
    "        ax[channel_index].axis('off')\n",
    "\n",
    "    output_path = base_name + \"_2_ROIs.png\"\n",
    "    with plt_lock:\n",
    "        fig.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close(fig)\n",
    "    \n",
    "    # Force garbage collection to free memory\n",
    "    plt.close('all') \n",
    "    gc.collect()\n",
    "\n",
    "    # Build a unified results dictionary\n",
    "    results = {\n",
    "        'image_info': {\n",
    "            'path': stacked_image_path,\n",
    "            'filename': os.path.basename(stacked_image_path),\n",
    "            'channels': n_channels,\n",
    "            'shape': image.shape if 'image' in locals() else None\n",
    "        },\n",
    "        'summary': {\n",
    "            'mean_fluorescence': {ch: np.mean(values) if values else None for ch, values in mean_fluorescence.items()},\n",
    "            'positive_count': {ch: sum(x is not None for x in positive_results[ch]) for ch in positive_results},\n",
    "            'negative_count': {ch: sum(x is None for x in positive_results[ch]) for ch in positive_results},\n",
    "            'total_cells': len(rois)\n",
    "        },\n",
    "        'background': {\n",
    "            'values': background_values,\n",
    "            'mean_value': mean_background_value\n",
    "        },\n",
    "        'cell_data': cell_data,\n",
    "        'roi_data': {\n",
    "            'positive_results': positive_results,\n",
    "            'corrected_total_fluorescence': corrected_total_fluorescence\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filepath, config):\n",
    "    \"\"\"Process a single file with the given parameters and return results.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"Processing {os.path.basename(filepath)}...\")\n",
    "        \n",
    "        # Create a thread-local figure manager\n",
    "        with plt.rc_context():\n",
    "            # Force matplotlib to create new figures for this thread\n",
    "            plt.close('all')\n",
    "            plt.ioff()  # Turn off interactive mode\n",
    "            \n",
    "            # Process the image and get results dictionary\n",
    "            results = process_images(filepath, config)\n",
    "            \n",
    "            # Generate result dictionary for CSV\n",
    "            csv_result = {'Base Name': filepath}\n",
    "            \n",
    "            # Add summary metrics to CSV results\n",
    "            for channel, mean_value in results['summary']['mean_fluorescence'].items():\n",
    "                csv_result[f'{channel} Fluorescence mean value'] = mean_value\n",
    "                csv_result[f'{channel} Mean Background'] = np.mean(results['background']['values'][channel]) if results['background']['values'][channel] else None\n",
    "                csv_result[f'{channel} Positive Results'] = results['summary']['positive_count'][channel]\n",
    "                csv_result[f'{channel} Negative Results'] = results['summary']['negative_count'][channel]\n",
    "                \n",
    "                # Get corrected total fluorescence values (non-None values)\n",
    "                ctf_values = [x for x in results['roi_data']['corrected_total_fluorescence'][channel] if x is not None]\n",
    "                csv_result[f'{channel} Corrected Total Fluorescence'] = np.mean(ctf_values) if ctf_values else None\n",
    "            \n",
    "            # Make sure all figures are closed\n",
    "            plt.close('all')\n",
    "            \n",
    "            # Save individual cell data to a JSON file\n",
    "            base_name = os.path.splitext(filepath)[0]\n",
    "            cell_data_path = f\"{base_name}_cell_data.json\"\n",
    "            with open(cell_data_path, 'w') as f:\n",
    "                # Extract just the cell data portion for the individual file\n",
    "                json.dump(results['cell_data'], f, indent=2)\n",
    "            \n",
    "        # Explicit garbage collection\n",
    "        gc.collect()\n",
    "        return csv_result, results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filepath}: {str(e)}\")\n",
    "        plt.close('all')  # Make sure to close any open figures on error\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tiff_image(image_path):\n",
    "    \"\"\"Display a tiff image using matplotlib.\"\"\"\n",
    "    image = tiff.imread(image_path)\n",
    "    image = np.moveaxis(image, 0, -1)\n",
    "\n",
    "    n_channels = image.shape[2]\n",
    "    \n",
    "    fig, axs = plt.subplots(1, n_channels , figsize=(n_channels *5,20))\n",
    "\n",
    "    axs[0].imshow(normalize(image[:,:,0]), cmap='gray')\n",
    "    axs[1].imshow(normalize(image[:,:,1]), cmap='gray')\n",
    "    axs[2].imshow(normalize(image[:,:,2]), cmap='gray')\n",
    "    axs[3].imshow(normalize(image[:,:,3]), cmap='gray')\n",
    "\n",
    "    for ax, channel_index in zip(axs, range(n_channels)):\n",
    "        ax.set_title(f'Channel {channel_index+1} (Raw)')\n",
    "\n",
    "    # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "    for ax in axs.flat:\n",
    "        ax.label_outer()\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(folder_path, config):\n",
    "    \"\"\"Process all files in the given folder with the provided configuration.\"\"\"\n",
    "    \n",
    "    # Get all TIFF files in the folder\n",
    "    tiff_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) \n",
    "                 if f.lower().endswith(('.tif', '.tiff'))]\n",
    "    \n",
    "    if not tiff_files:\n",
    "        print(f\"No TIFF files found in {folder_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Found {len(tiff_files)} files to process\")\n",
    "\n",
    "    # Process all files using ThreadPoolExecutor\n",
    "    csv_results = []\n",
    "    \n",
    "    # Create a compact summary structure for metadata\n",
    "    experiment_metadata = {\n",
    "        'experiment_folder': folder_path,\n",
    "        'processed_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        'configuration': convert_to_serializable(config),\n",
    "        'file_count': len(tiff_files)\n",
    "    }\n",
    "    \n",
    "    max_workers = max(4, os.cpu_count() // 2)  # Limit workers to avoid memory issues\n",
    "    print(f\"Processing files with {max_workers} parallel workers\")\n",
    "    \n",
    "    # Create results directory if it doesn't exist\n",
    "    results_dir = os.path.join(folder_path, \"results\")\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # HDF5 file path\n",
    "    hdf5_path = os.path.join(results_dir, \"experiment_data.h5\")\n",
    "    \n",
    "    # Process images and collect results\n",
    "    image_results = {}\n",
    "    \n",
    "    with cf.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all jobs\n",
    "        future_to_file = {executor.submit(process_file, f, config): f for f in tiff_files}\n",
    "        \n",
    "        # Process results as they complete with progress bar\n",
    "        with tqdm(total=len(tiff_files), desc=\"Processing Images\", unit=\"file\") as progress_bar:\n",
    "            for future in cf.as_completed(future_to_file):\n",
    "                file_path = future_to_file[future]\n",
    "                file_name = os.path.basename(file_path)\n",
    "                \n",
    "                try:\n",
    "                    csv_result, full_results = future.result()\n",
    "                    if csv_result:\n",
    "                        csv_results.append(csv_result)\n",
    "                        image_results[file_name] = {\n",
    "                            'summary': convert_to_serializable(full_results['summary']),\n",
    "                            'cell_count': full_results['summary']['total_cells'],\n",
    "                            'individual_data_file': os.path.basename(os.path.splitext(file_path)[0]) + \"_cell_data.json\"\n",
    "                        }\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file_name}: {str(e)}\")\n",
    "                \n",
    "                # Update progress bar\n",
    "                progress_bar.update(1)\n",
    "    \n",
    "    if not csv_results:\n",
    "        print(\"No files were successfully processed.\")\n",
    "        return None\n",
    "    \n",
    "    # Create and save HDF5 file with experiment data\n",
    "    print(f\"Saving experiment data to HDF5...\")\n",
    "    with h5py.File(hdf5_path, 'w') as f:\n",
    "        # Store metadata as attributes in root group\n",
    "        for key, value in experiment_metadata.items():\n",
    "            if key == 'configuration':\n",
    "                # Store configuration as JSON string\n",
    "                f.attrs[key] = json.dumps(value)\n",
    "            else:\n",
    "                f.attrs[key] = value\n",
    "            \n",
    "        # Create images group\n",
    "        images_group = f.create_group('images')\n",
    "        \n",
    "        # Store data for each image\n",
    "        for img_name, img_data in image_results.items():\n",
    "            img_group = images_group.create_group(img_name.replace('.tif', '').replace('.tiff', ''))\n",
    "            \n",
    "            # Store image summary\n",
    "            summary_group = img_group.create_group('summary')\n",
    "            \n",
    "            # Store mean fluorescence for each channel\n",
    "            for channel, value in img_data['summary']['mean_fluorescence'].items():\n",
    "                if value is not None:\n",
    "                    summary_group.attrs[f'mean_fluorescence_{channel}'] = value\n",
    "            \n",
    "            # Store counts\n",
    "            for count_type in ['positive_count', 'negative_count']:\n",
    "                count_group = summary_group.create_group(count_type)\n",
    "                for channel, value in img_data['summary'][count_type].items():\n",
    "                    count_group.attrs[channel] = value\n",
    "            \n",
    "            # Store other metadata\n",
    "            img_group.attrs['cell_count'] = img_data['cell_count']\n",
    "            img_group.attrs['individual_data_file'] = img_data['individual_data_file']\n",
    "    \n",
    "    print(f\"Experiment data saved to {hdf5_path}\")\n",
    "    \n",
    "    # Also save a small JSON version of the metadata for easy inspection\n",
    "    metadata_json_path = os.path.join(results_dir, \"experiment_metadata.json\")\n",
    "    with open(metadata_json_path, 'w') as f:\n",
    "        json.dump({\n",
    "            'metadata': experiment_metadata,\n",
    "            'image_count': len(image_results),\n",
    "            'hdf5_file': os.path.basename(hdf5_path)\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(f\"Experiment metadata saved to {metadata_json_path}\")\n",
    "    \n",
    "    # Create a DataFrame from the results and save to CSV\n",
    "    df = pd.DataFrame(csv_results)\n",
    "    csv_path = os.path.join(results_dir, \"results.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    print(f\"Results saved to {csv_path}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_experiments_batch(main_directory, config):\n",
    "    \"\"\"\n",
    "    Process multiple experiment folders contained within a main directory.\n",
    "    Always processes all folders, overwriting any existing results.\n",
    "    \n",
    "    Parameters:\n",
    "        main_directory (str): Path to the directory containing multiple experiment folders\n",
    "        config (dict): Configuration dictionary for processing\n",
    "        \n",
    "    Returns:\n",
    "        dict: Summary of processing results for all experiments\n",
    "    \"\"\"\n",
    "    # Get all subdirectories in the main directory\n",
    "    experiment_folders = [os.path.join(main_directory, d) for d in os.listdir(main_directory) \n",
    "                         if os.path.isdir(os.path.join(main_directory, d))]\n",
    "    \n",
    "    if not experiment_folders:\n",
    "        print(f\"No experiment folders found in {main_directory}\")\n",
    "        return None\n",
    "    \n",
    "    total_experiments = len(experiment_folders)\n",
    "    print(f\"Found {total_experiments} experiment folders to process\")\n",
    "    \n",
    "    # Create a summary dictionary\n",
    "    summary = {\n",
    "        'main_directory': main_directory,\n",
    "        'start_time': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        'config': config,\n",
    "        'experiments': {},\n",
    "        'total_experiments': total_experiments,\n",
    "        'successful_experiments': 0,\n",
    "        'failed_experiments': 0\n",
    "    }\n",
    "    \n",
    "    # Process each experiment folder sequentially\n",
    "    for i, folder in enumerate(experiment_folders, 1):\n",
    "        folder_name = os.path.basename(folder)\n",
    "        \n",
    "        # Check for existing results and warn user\n",
    "        results_path = os.path.join(folder, \"results\", \"experiment_data.json\")\n",
    "        if os.path.exists(results_path):\n",
    "            print(f\"\\n[{i}/{total_experiments}] Processing {folder_name} (overwriting existing results)\")\n",
    "        else:\n",
    "            print(f\"\\n[{i}/{total_experiments}] Processing experiment: {folder_name}\")\n",
    "        \n",
    "        try:\n",
    "            # Use the provided configuration without modification\n",
    "            folder_config = config.copy()\n",
    "            \n",
    "            # Process the folder\n",
    "            print(f\"Using radius factor: {folder_config['radius_factor']}\")\n",
    "            df = process_folder(folder, folder_config)\n",
    "            \n",
    "            if df is not None:\n",
    "                summary['experiments'][folder_name] = {\n",
    "                    'status': 'success',\n",
    "                    'files_processed': len(df),\n",
    "                    'config': folder_config\n",
    "                }\n",
    "                summary['successful_experiments'] += 1\n",
    "            else:\n",
    "                summary['experiments'][folder_name] = {\n",
    "                    'status': 'failed',\n",
    "                    'reason': 'No files were successfully processed',\n",
    "                    'config': folder_config\n",
    "                }\n",
    "                summary['failed_experiments'] += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing folder {folder_name}: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()  # Print the full stack trace for better debugging\n",
    "            summary['experiments'][folder_name] = {\n",
    "                'status': 'failed',\n",
    "                'reason': str(e),\n",
    "                'config': config\n",
    "            }\n",
    "            summary['failed_experiments'] += 1\n",
    "    \n",
    "    # Add end time to summary\n",
    "    summary['end_time'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    start_time = datetime.strptime(summary['start_time'], \"%Y-%m-%d %H:%M:%S\")\n",
    "    end_time = datetime.strptime(summary['end_time'], \"%Y-%m-%d %H:%M:%S\")\n",
    "    summary['duration_seconds'] = (end_time - start_time).total_seconds()\n",
    "    \n",
    "    # Save summary to JSON\n",
    "    summary_path = os.path.join(main_directory, \"batch_processing_summary.json\")\n",
    "    with open(summary_path, 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nBatch processing complete:\")\n",
    "    print(f\"- Successful: {summary['successful_experiments']}\")\n",
    "    print(f\"- Failed: {summary['failed_experiments']}\")\n",
    "    print(f\"Total time: {summary['duration_seconds'] / 60:.2f} minutes\")\n",
    "    print(f\"Summary saved to {summary_path}\")\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative method to select the folder (open main folder with all subfolders)\n",
    "main_folder_path = select_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select refrerence image for radius calculation\n",
    "reference_image_path = select_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using predefined radius factor: 17\n"
     ]
    }
   ],
   "source": [
    "# Define processing configuration\n",
    "config = {\n",
    "    'lower_thresh_factor': [2, 2, 2, 2],\n",
    "    'upper_thresh': 50000,\n",
    "    'background_threshold': None,\n",
    "    'radius_factor': 17,\n",
    "    'mask_channel': 1,\n",
    "    'channel_of_interest': 4,\n",
    "    'single_ch_background': True\n",
    "}\n",
    "\n",
    "if config['radius_factor'] is None:\n",
    "    radius_factor = calculate_optimal_radius(reference_image_path, config)\n",
    "    config['radius_factor'] = radius_factor\n",
    "else:  \n",
    "    print(f'Using predefined radius factor: {config[\"radius_factor\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process an individual selected folder\n",
    "df = process_folder(main_folder_path, config)\n",
    "print(\"processing complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch processing with the following configuration:\n",
      "- Radius factor: 17\n",
      "- Mask channel: 1\n",
      "- Channel of interest: 4\n",
      "- Lower threshold factors: [2, 2, 2, 2]\n",
      "Found 3 experiment folders to process\n",
      "\n",
      "[1/3] Processing EXP01 (overwriting existing results)\n",
      "Using radius factor: 17\n",
      "Found 2 files to process\n",
      "Processing files with 16 parallel workers\n",
      "Processing EXP10_3_1_1_NB_BIC_5CO_scFL_NO_Doxy_1-Scene-1-ScanRegion0-OME.ome.tiff...\n",
      "Processing EXP10_3_1_1_NB_BIC_5CO_scFL_NO_Doxy_1-Scene-2-ScanRegion1-OME.ome.tiff...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   0%|          | 0/2 [00:00<?, ?file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background threshold for channel 4: 315.8717614040461\n",
      "Background threshold for channel 4: 322.3237002752985\n"
     ]
    }
   ],
   "source": [
    "# Process an experiment batch in the selected main folder\n",
    "main_directory = main_folder_path\n",
    "\n",
    "if main_directory:\n",
    "    \n",
    "    print(\"Starting batch processing with the following configuration:\")\n",
    "    print(f\"- Radius factor: {config['radius_factor']}\")\n",
    "    print(f\"- Mask channel: {config['mask_channel']}\")\n",
    "    print(f\"- Channel of interest: {config['channel_of_interest']}\")\n",
    "    print(f\"- Lower threshold factors: {config['lower_thresh_factor']}\")\n",
    "    \n",
    "    # Process all experiment folders\n",
    "    batch_summary = process_experiments_batch(main_directory, config)\n",
    "    print(\"Batch processing complete.\")\n",
    "else:\n",
    "    print(\"No directory selected. Processing cancelled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".auto_img",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
