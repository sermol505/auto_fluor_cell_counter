{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folder-wise Fast Microscopy Picture Analysis\n",
    "The following code opens a folder of the SlideScanner Microscope and automatically sets ROIs to the darkest and brightest portions of the picture. Consequently, it removes the background through the ROIs at the darkest positions and calculates the mean fluorescence at the brighter spots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tiff\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import gc\n",
    "import concurrent.futures as cf\n",
    "import multiprocessing\n",
    "import threading\n",
    "\n",
    "from AutoImgUtils import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up Matplotlib\n",
    "matplotlib.use('Agg')  # Use the Agg backend for non-interactive plotting\n",
    "plt_lock = threading.Lock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_optimal_radius(reference_image_path, config):\n",
    "    \"\"\"\n",
    "    Calculate the optimal ROI radius from a reference image.\n",
    "    \n",
    "    Parameters:\n",
    "        reference_image_path (str): Path to the reference image\n",
    "        config (dict): Configuration parameters\n",
    "        \n",
    "    Returns:\n",
    "        int: The calculated optimal radius\n",
    "    \"\"\"\n",
    "    print(f\"Calculating optimal radius from reference image: {os.path.basename(reference_image_path)}\")\n",
    "    \n",
    "    # Extract parameters with defaults\n",
    "    lower_thresh_chan = config.get('lower_thresh_factor', [2, 3, 2, 2])\n",
    "    upper_thresh = config.get('upper_thresh', 60000)\n",
    "    background_threshold = config.get('background_threshold', None)\n",
    "    mask_channel = config.get('mask_channel', 1) - 1\n",
    "    channel_of_interest = config.get('channel_of_interest', 1) - 1\n",
    "    single_ch_background = config.get('single_ch_background', True)\n",
    "    \n",
    "    # Load the image\n",
    "    image = tiff.imread(reference_image_path)\n",
    "    image = np.moveaxis(image, 0, -1)\n",
    "    \n",
    "    # Subtract background\n",
    "    if single_ch_background:\n",
    "        background_values, mean_background_value, background_subtracted_image = bg_substraction_ROI_single_ch(\n",
    "            image, background_threshold, channel_of_interest, display_rois=False)\n",
    "    else:\n",
    "        background_values, mean_background_value, background_subtracted_image = bg_substraction_ROI(\n",
    "            image, background_threshold, display_rois=False)\n",
    "    \n",
    "    # Find regions in mask channel\n",
    "    channel_thresh = 2 * np.std(background_subtracted_image[:, :, mask_channel]) + np.mean(background_subtracted_image[:, :, mask_channel])\n",
    "    print(f'Channel threshold for mask channel {mask_channel+1}: {channel_thresh}')\n",
    "    thresh = (background_subtracted_image[:, :, mask_channel] > channel_thresh) & (background_subtracted_image[:, :, mask_channel] < upper_thresh)\n",
    "    labels = measure.label(thresh)\n",
    "    mask_props = measure.regionprops(labels)\n",
    "    \n",
    "    # Find regions in channel of interest\n",
    "    channel_thresh_interest = lower_thresh_chan[channel_of_interest] * np.std(background_subtracted_image[:, :, channel_of_interest]) + np.mean(background_subtracted_image[:, :, channel_of_interest])\n",
    "    print(f'Channel threshold for channel of interest {channel_of_interest+1}: {channel_thresh_interest}')\n",
    "    thresh_interest = (background_subtracted_image[:, :, channel_of_interest] > channel_thresh_interest) & (background_subtracted_image[:, :, channel_of_interest] < upper_thresh)\n",
    "    labels_interest = measure.label(thresh_interest)\n",
    "    props_interest = measure.regionprops(labels_interest)\n",
    "    \n",
    "    # Match regions and calculate radius\n",
    "    matched_radii = []\n",
    "    \n",
    "    for mask_prop in mask_props:\n",
    "        mask_x, mask_y = int(mask_prop.centroid[1]), int(mask_prop.centroid[0])\n",
    "        \n",
    "        for interest_prop in props_interest:\n",
    "            interest_x, interest_y = int(interest_prop.centroid[1]), int(interest_prop.centroid[0])\n",
    "            \n",
    "            distance = np.sqrt((mask_x - interest_x)**2 + (mask_y - interest_y)**2)\n",
    "            max_distance = np.sqrt(mask_prop.area) / 2\n",
    "            \n",
    "            if distance <= max_distance:\n",
    "                interest_radius = np.sqrt(interest_prop.area / np.pi)\n",
    "                matched_radii.append(interest_radius)\n",
    "                break\n",
    "    \n",
    "    if len(matched_radii) > 0:\n",
    "        mean_radius = np.mean(matched_radii)\n",
    "        std_radius = np.std(matched_radii)\n",
    "        radius_factor = int(mean_radius)\n",
    "        \n",
    "        print(f'Mean radius from matched regions: {mean_radius:.2f} Â± {std_radius:.2f} pixels')\n",
    "        print(f'Found {len(matched_radii)} matching regions between mask and channel of interest')\n",
    "        print(f'Using radius_factor = {radius_factor} for all subsequent processing')\n",
    "    else:\n",
    "        # Fall back to using the mask channel\n",
    "        areas = [prop.area for prop in mask_props]\n",
    "        radii = [np.sqrt(area/np.pi) for area in areas]\n",
    "        mean_radius = np.mean(radii)\n",
    "        radius_factor = int(mean_radius)\n",
    "        \n",
    "        print(f'No matching regions found. Using mask channel. Mean radius: {mean_radius:.2f} pixels')\n",
    "        print(f'Using radius_factor = {radius_factor} for all subsequent processing')\n",
    "    \n",
    "    # Force garbage collection to free memory \n",
    "    gc.collect()\n",
    "    \n",
    "    return radius_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(stacked_image_path, config):\n",
    "    '''\n",
    "    # Function to process a single set of 4-channel images and return mean fluorescence values, mean background values, and number of positive and negative results\n",
    "\n",
    "            Parameters:\n",
    "                base_name (string): The path to the folder containing the 4-channel images\n",
    "                lower_thresh_chan (int): A list of 4 integers, the lower threshold for each channel\n",
    "                upper_thresh (int): The upper threshold for the channel of interest\n",
    "                background_threshold (int): The threshold for the background values, if left empty, it will be 2 standard deviations below the mean\n",
    "                radius_factor (int): The radius of the circular ROIs around detected points, if none is given, the mean radius will be calculated from the region properties\n",
    "                channel_of_interest (int): The channel of interest, default is 1\n",
    "                single_ch_background (bool): If True, the background will be calculated for each channel separately, if False, the background will be calculated for all channels together\n",
    "                mask_channel (int): The channel to use for masking bright spots (ROIs), default is 1\n",
    "\n",
    "            Returns:\n",
    "                mean_fluorescence (dict): A dictionary containing the mean fluorescence values for each channel\n",
    "                mean_fluorescence_value (float): The mean fluorescence value for each channel\n",
    "                background_values (dict): A dictionary containing the mean background values for each channel\n",
    "                mean_background_value (float): The mean background value for the channel of interest\n",
    "                positive_results (dict): A dictionary containing the number of positive results for each channel\n",
    "                negative_results (dict): A dictionary containing the number of negative results for each channel\n",
    "                corrected_total_fluorescence (dict): A dictionary containing the corrected total cell fluorescence for each channel\n",
    "    '''\n",
    "    \n",
    "    # Extract parameters with defaults\n",
    "    lower_thresh_chan = config.get('lower_thresh_factor', [2, 3, 2, 2])\n",
    "    upper_thresh = config.get('upper_thresh', 60000)\n",
    "    background_threshold = config.get('background_threshold', None)\n",
    "    radius_factor = config.get('radius_factor', 10)\n",
    "    mask_channel = config.get('mask_channel', 1)\n",
    "    channel_of_interest = config.get('channel_of_interest', 1)\n",
    "    single_ch_background = config.get('single_ch_background', True)\n",
    "\n",
    "    channel_of_interest -= 1\n",
    "    mask_channel -= 1\n",
    "    \n",
    "    image = tiff.imread(stacked_image_path)\n",
    "    image = np.moveaxis(image, 0, -1)\n",
    "    base_name = os.path.splitext(stacked_image_path)[0]\n",
    "\n",
    "    n_channels = image.shape[2]\n",
    "\n",
    "    # Initialize dictonaries to store the mean fluorescence and background values \n",
    "    mean_fluorescence = {f'Channel {i+1}': [] for i in range(n_channels)}\n",
    "    background_values = {f'Channel {i+1}': [] for i in range(n_channels)}\n",
    "    positive_results = {f'Channel {i+1}': [] for i in range(n_channels)}\n",
    "    corrected_total_fluorescence = {f'Channel {i+1}': [] for i in range(n_channels)}\n",
    "\n",
    "    # Subtract background from the image and display the background ROIs on the channel of interest\n",
    "    if single_ch_background:\n",
    "        background_values, mean_background_value, background_subtracted_image = bg_substraction_ROI_single_ch(image, background_threshold,channel_of_interest, display_rois=False)\n",
    "    else:\n",
    "        background_values, mean_background_value, background_subtracted_image = bg_substraction_ROI(image, background_threshold, display_rois=False)\n",
    "\n",
    "    # Display the histogram of the background subtracted image\n",
    "    # Use explicit figure creation and management\n",
    "    fig = plt.figure(figsize=(n_channels*4, 10))\n",
    "    axs = fig.subplots(1, n_channels)\n",
    "\n",
    "    for ax, channel_index in zip(axs, range(n_channels)):\n",
    "        ax.hist(image[:, :, channel_index].ravel(), bins=256, color='gray', alpha=0.75)\n",
    "        ax.set_title(f\"Histogram for Channel {channel_index+1}\")\n",
    "        ax.set_xlabel(\"Pixel intensity\")\n",
    "        ax.set_ylabel(\"Frequency\")\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_xscale('log')\n",
    "        ax.axvline(mean_background_value[channel_index], color='r', linestyle='dashed', linewidth=1)\n",
    "        ax.axvline(lower_thresh_chan[channel_index] * np.std(image[:, :, channel_index]) + np.mean(image[:, :, channel_index]), color='g', linestyle='dashed', linewidth=1)\n",
    "\n",
    "    # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "    for ax in axs.flat:\n",
    "        ax.label_outer()\n",
    "    \n",
    "    output_path = base_name + \"_0_histogram.png\"\n",
    "    with plt_lock:\n",
    "        fig.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close(fig)\n",
    "    \n",
    "    # plt.show()\n",
    "\n",
    "    # After processing, close original tiff image to free memory\n",
    "    plt.close('all')\n",
    "    del image\n",
    "\n",
    "    # Apply thresholds to find maximum values in the background-subtracted depending on channel of interest, avoiding very bright spots\n",
    "    channel_thresh = 2 * np.std(background_subtracted_image[:, :, mask_channel]) + np.mean(background_subtracted_image[:, :, mask_channel])\n",
    "    print(f'Channel threshold for mask channel {mask_channel+1}: {channel_thresh}')\n",
    "    thresh = (background_subtracted_image[:, :, mask_channel] > channel_thresh) & (background_subtracted_image[:, :, mask_channel] < upper_thresh)\n",
    "\n",
    "    # Label the thresholded regions and return the number of cells\n",
    "    labels = measure.label(thresh)\n",
    "    props = measure.regionprops(labels)\n",
    "    \n",
    "    # Create circular ROIs around detected points\n",
    "    rois = []\n",
    "\n",
    "    for prop in props:\n",
    "        y, x = prop.centroid\n",
    "        radius = radius_factor \n",
    "        rois.append((int(x), int(y), int(radius)))\n",
    "\n",
    "    # Calculate mean fluorescence values for each channel and check if the signal is present\n",
    "    for channel_index in range(n_channels):\n",
    "        channel = background_subtracted_image[:, :, channel_index]\n",
    "        channel_thresh = 2 * lower_thresh_chan[channel_index] * np.std(channel) + np.mean(channel)\n",
    "\n",
    "        for roi in rois:\n",
    "            x, y, radius = roi\n",
    "            rr, cc = draw.disk((y, x), radius, shape=channel.shape)\n",
    "            roi_area = channel[rr, cc]\n",
    "            mean_value = np.mean(roi_area)\n",
    "            integrated_density = np.sum(roi_area)\n",
    "            area_of_cell = len(rr)\n",
    "            corrected_fluorescence = integrated_density - (area_of_cell * mean_background_value[channel_index])\n",
    "\n",
    "            if mean_value > channel_thresh:\n",
    "                positive_results[f'Channel {channel_index+1}'].append((x, y, radius))\n",
    "                mean_fluorescence[f'Channel {channel_index+1}'].append(mean_value)\n",
    "                corrected_total_fluorescence[f'Channel {channel_index+1}'].append(corrected_fluorescence)\n",
    "            else:\n",
    "                positive_results[f'Channel {channel_index+1}'].append(None)\n",
    "                corrected_total_fluorescence[f'Channel {channel_index+1}'].append(None)\n",
    "    \n",
    "    # fig, axs = plt.subplots(1, n_channels , figsize=(n_channels *5,20))\n",
    "\n",
    "    # axs[0].imshow(normalize(image[:,:,0]), cmap='gray')\n",
    "    # axs[1].imshow(normalize(image[:,:,1]), cmap='gray')\n",
    "    # axs[2].imshow(normalize(image[:,:,2]), cmap='gray')\n",
    "    # axs[3].imshow(normalize(image[:,:,3]), cmap='gray')\n",
    "\n",
    "    # for ax, channel_index in zip(axs, range(n_channels)):\n",
    "    #     ax.set_title(f'Channel {channel_index+1} (Raw)')\n",
    "\n",
    "    # # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "    # for ax in axs.flat:\n",
    "    #     ax.label_outer()\n",
    "    #     ax.axis('off')\n",
    "    \n",
    "    # plt.show()\n",
    "\n",
    "    # Display positive ROIs for each channel\n",
    "    fig = plt.figure(figsize=(n_channels * 5, 20))\n",
    "    ax = fig.subplots(1, 4)\n",
    "\n",
    "    for channel_index in range(n_channels):\n",
    "        channel_image = np.stack([normalize(background_subtracted_image[:, :, channel_index])]*3, axis=-1)  # Convert to RGB\n",
    "\n",
    "        for roi in positive_results[f'Channel {channel_index+1}']:\n",
    "            if roi is not None:\n",
    "                x, y, radius = roi\n",
    "                rr, cc = draw.disk((y, x), radius, shape=channel_image.shape)\n",
    "                channel_image[rr, cc] = [0, 1, 0]  # Green for positive ROIs\n",
    "\n",
    "        ax[channel_index].imshow(channel_image)\n",
    "        ax[channel_index].set_title(f'Positive ROIs on Channel {channel_index + 1}')\n",
    "        ax[channel_index].axis('off')\n",
    "\n",
    "    output_path = base_name + \"_1_ROIs.png\"\n",
    "    with plt_lock:\n",
    "        fig.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close(fig)\n",
    "    # plt.show()\n",
    "    \n",
    "    # Force garbage collection to free memory\n",
    "    plt.close('all') \n",
    "    gc.collect()\n",
    "\n",
    "    return mean_fluorescence, background_values, mean_background_value, positive_results, corrected_total_fluorescence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filepath, config):\n",
    "    \"\"\"Process a single file with the given parameters and return results.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"Processing {os.path.basename(filepath)}...\")\n",
    "        \n",
    "        # Create a thread-local figure manager\n",
    "        with plt.rc_context():\n",
    "            # Force matplotlib to create new figures for this thread\n",
    "            plt.close('all')\n",
    "            plt.ioff()  # Turn off interactive mode\n",
    "            \n",
    "            mean_fluorescence, background_values, mean_background_value, positive_results, corrected_total_fluorescence = process_images(\n",
    "                filepath, config)\n",
    "            \n",
    "            # Generate result dictionary\n",
    "            result = {'Base Name': filepath}\n",
    "            for channel, values in mean_fluorescence.items():\n",
    "                result[f'{channel} Fluorescence mean value'] = np.mean(values) if values else None\n",
    "                result[f'{channel} Mean Background'] = np.mean(background_values[channel]) if background_values[channel] else None\n",
    "                result[f'{channel} Positive Results'] = sum(x is not None for x in positive_results[channel])\n",
    "                result[f'{channel} Negative Results'] = sum(x is None for x in positive_results[channel])\n",
    "                \n",
    "                # Handle empty lists gracefully\n",
    "                ctf_values = [x for x in corrected_total_fluorescence[channel] if x is not None]\n",
    "                result[f'{channel} Corrected Total Fluorescence'] = np.mean(ctf_values) if ctf_values else None\n",
    "            \n",
    "            # Make sure all figures are closed\n",
    "            plt.close('all')\n",
    "            \n",
    "        # Explicit garbage collection\n",
    "        gc.collect()\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filepath}: {str(e)}\")\n",
    "        plt.close('all')  # Make sure to close any open figures on error\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tiff_image(image_path):\n",
    "    \"\"\"Display a tiff image using matplotlib.\"\"\"\n",
    "    image = tiff.imread(image_path)\n",
    "    image = np.moveaxis(image, 0, -1)\n",
    "\n",
    "    n_channels = image.shape[2]\n",
    "    \n",
    "    fig, axs = plt.subplots(1, n_channels , figsize=(n_channels *5,20))\n",
    "\n",
    "    axs[0].imshow(normalize(image[:,:,0]), cmap='gray')\n",
    "    axs[1].imshow(normalize(image[:,:,1]), cmap='gray')\n",
    "    axs[2].imshow(normalize(image[:,:,2]), cmap='gray')\n",
    "    axs[3].imshow(normalize(image[:,:,3]), cmap='gray')\n",
    "\n",
    "    for ax, channel_index in zip(axs, range(n_channels)):\n",
    "        ax.set_title(f'Channel {channel_index+1} (Raw)')\n",
    "\n",
    "    # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "    for ax in axs.flat:\n",
    "        ax.label_outer()\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Workflow Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative method to select the folder (open main folder with all subfolders)\n",
    "main_folder_path = select_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select refrerence image for radius calculation\n",
    "reference_image_path = select_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating optimal radius from reference image: DARK01_1_4_1_NB_5CO_scFL_DARK_4d-Scene-2-ScanRegion1-OME.ome.tiff\n",
      "Background threshold for channel 4: 376.9558914597776\n",
      "Channel threshold for mask channel 1: 1963.1803896392507\n",
      "Channel threshold for channel of interest 4: 1762.732632151033\n",
      "Mean radius from matched regions: 18.25 Â± 3.92 pixels\n",
      "Found 1784 matching regions between mask and channel of interest\n",
      "Using radius_factor = 18 for all subsequent processing\n"
     ]
    }
   ],
   "source": [
    "# Define processing configuration\n",
    "config = {\n",
    "    'lower_thresh_factor': [2, 3, 2, 2],\n",
    "    'upper_thresh': 60000,\n",
    "    'background_threshold': None,\n",
    "    'radius_factor': None,\n",
    "    'mask_channel': 1,\n",
    "    'channel_of_interest': 4,\n",
    "    'single_ch_background': True\n",
    "}\n",
    "\n",
    "# Calculate optimal radius from the reference file\n",
    "optimal_radius = calculate_optimal_radius(reference_image_path, config)\n",
    "\n",
    "# Update configuration with the calculated radius\n",
    "config['radius_factor'] = optimal_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 files to process\n",
      "Processing remaining files with 3 parallel workers\n",
      "Processing DARK01_1_2_1_NB_5CO_Cal_DARK_1d-Scene-5-ScanRegion4-OME.ome.tiff...\n",
      "Processing DARK01_1_4_1_NB_5CO_scFL_DARK_4d-Scene-2-ScanRegion1-OME.ome.tiff...\n",
      "Processing EXP10_2_1_2_NB_BIC_5CO_Cal_Doxy_stop_48h_1-Scene-3-ScanRegion2-OME.ome.tiff...\n",
      "Background threshold for channel 4: 326.07866188331576\n",
      "Background threshold for channel 4: 376.9558914597776\n",
      "Background threshold for channel 4: 513.0006522961979\n",
      "Channel threshold for mask channel 1: 1831.1569643971827\n",
      "Channel threshold for mask channel 1: 2980.0407531189057\n",
      "Channel threshold for mask channel 1: 1963.1803896392507\n",
      "Completed 2/4 files (50.0%)\n",
      "Completed 3/4 files (75.0%)\n",
      "Completed 4/4 files (100.0%)\n",
      "Processing complete. Results saved to C:/04_Imaging/20241220\\mean_fluorescence_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Decide to test the configuration with the first file. If successful, continue with the remaining files\n",
    "First_Test = False\n",
    "\n",
    "# Collect all TIFF files to process\n",
    "files_to_process = []\n",
    "for root, dirs, files in os.walk(main_folder_path):\n",
    "    for filename in files:\n",
    "        if filename.endswith(\".tiff\"):\n",
    "            files_to_process.append(os.path.join(root, filename))\n",
    "\n",
    "# Process files in parallel or sequentially\n",
    "print(f\"Found {len(files_to_process)} files to process\")\n",
    "results = []\n",
    "\n",
    "try:\n",
    "    # First try sequential processing for one file to validate configuration\n",
    "    if files_to_process:\n",
    "        \n",
    "        if First_Test:\n",
    "            print(\"Testing configuration with first file...\")\n",
    "            test_result = process_file(files_to_process[0], config=config)\n",
    "            if test_result:\n",
    "                results.append(test_result)\n",
    "                print(\"Configuration test successful, continuing with remaining files...\")\n",
    "        \n",
    "        # Process remaining files\n",
    "        if len(files_to_process) >= 1:\n",
    "            # Use ThreadPoolExecutor instead of ProcessPoolExecutor to avoid serialization issues\n",
    "            max_workers = min(3, os.cpu_count() // 2) # Limit workers to avoid memory issues\n",
    "            print(f\"Processing remaining files with {max_workers} parallel workers\")\n",
    "            \n",
    "            # Show a progress counter\n",
    "            total_files = len(files_to_process)\n",
    "            completed = 0\n",
    "            \n",
    "            with cf.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "                future_to_file = {executor.submit(process_file, filepath, config=config): \n",
    "                                filepath for filepath in files_to_process}\n",
    "                \n",
    "                for future in cf.as_completed(future_to_file):\n",
    "                    filepath = future_to_file[future]\n",
    "                    try:\n",
    "                        result = future.result()\n",
    "                        if result:\n",
    "                            results.append(result)\n",
    "                        \n",
    "                        # Update progress\n",
    "                        completed += 1\n",
    "                        print(f\"Completed {completed+1}/{total_files+1} files ({(completed+1)/(total_files+1)*100:.1f}%)\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {filepath}: {str(e)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in processing pipeline: {str(e)}\")\n",
    "\n",
    "# Convert the results to a DataFrame and save to CSV\n",
    "if results:\n",
    "    df = pd.DataFrame(results)\n",
    "    output_path = os.path.join(main_folder_path, 'mean_fluorescence_results.csv')\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Processing complete. Results saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No results were successfully processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".auto_img",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
