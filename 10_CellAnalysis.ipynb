{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf37c9a6",
   "metadata": {},
   "source": [
    "# Cell Analysis Utilities for CSV Data\n",
    "\n",
    "This module provides functions for loading, analyzing, and visualizing \n",
    "cell measurement data from CSV files generated by the fluorescence \n",
    "microscopy processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c5bcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports for the module\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Union, Optional, Tuple\n",
    "\n",
    "\n",
    "import AutoImgUtils as autils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b41ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a605349e",
   "metadata": {},
   "source": [
    "## Function Definitions for Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e0bfd1",
   "metadata": {},
   "source": [
    "### Data I/O Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bdbd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(file_path: Union[str, Path]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load cell measurement data from a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame containing the cell measurement data.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File {file_path} does not exist.\")\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Ensure that the 'cell_id' column is present\n",
    "    if 'cell_id' not in df.columns:\n",
    "        raise ValueError(\"CSV file must contain a 'cell_id' column.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d536caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df: pd.DataFrame, column: str, method: str = 'iqr', \n",
    "                   factor: float = 1.5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove outliers from a DataFrame based on a specific column.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the cell measurement data\n",
    "    - column: Name of the column to use for outlier detection\n",
    "    - method: Method for outlier detection ('iqr', 'zscore' or 'mad')\n",
    "    - factor: Factor for outlier detection (1.5 for IQR, 3.0 for z-score typically and 3.5 for MAD)\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with outliers removed\n",
    "    \"\"\"\n",
    "    if column not in df.columns:\n",
    "        raise ValueError(f\"Column '{column}' not found in DataFrame. Available columns: {list(df.columns)}\")\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    if method == 'iqr':\n",
    "        Q1 = df_clean[column].quantile(0.25)\n",
    "        Q3 = df_clean[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - factor * IQR\n",
    "        upper_bound = Q3 + factor * IQR\n",
    "        \n",
    "        mask = (df_clean[column] >= lower_bound) & (df_clean[column] <= upper_bound)\n",
    "        \n",
    "    elif method == 'zscore':\n",
    "        mean = df_clean[column].mean()\n",
    "        std = df_clean[column].std()\n",
    "        z_scores = np.abs((df_clean[column] - mean) / std)\n",
    "        \n",
    "        mask = z_scores <= factor\n",
    "    elif method == 'mad':\n",
    "        median = df_clean[column].median()\n",
    "        mad = np.median(np.abs(df_clean[column] - median))\n",
    "        lower_bound = median - factor * mad\n",
    "        upper_bound = median + factor * mad\n",
    "        \n",
    "        mask = (df_clean[column] >= lower_bound) & (df_clean[column] <= upper_bound)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Method must be either 'iqr' or 'zscore'\")\n",
    "    \n",
    "    df_filtered = df_clean[mask].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Removed {len(df) - len(df_filtered)} outliers ({((len(df) - len(df_filtered))/len(df)*100):.1f}%) based on column '{column}'\")\n",
    "    print(f\"Original dataset: {len(df)} rows\")\n",
    "    print(f\"Filtered dataset: {len(df_filtered)} rows\")\n",
    "    \n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb17fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_multiple_csvs(file_paths: List[Union[str, Path]], \n",
    "                                 outlier_column: str,\n",
    "                                 method: str = 'mad',\n",
    "                                 factor: float = 3.0,\n",
    "                                 global_outlier_removal: bool = False) -> Tuple[pd.DataFrame, pd.DataFrame, Dict]:\n",
    "    \"\"\"\n",
    "    Load multiple CSV files, apply outlier removal, and return combined datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_paths: List of paths to CSV files\n",
    "    - outlier_column: Column to use for outlier detection\n",
    "    - method: Outlier detection method ('iqr', 'zscore', 'mad')\n",
    "    - factor: Factor for outlier detection\n",
    "    - global_outlier_removal: Whether to apply additional outlier removal on combined data\n",
    "    \n",
    "    Returns:\n",
    "    - original_combined: Combined original data with dataset labels\n",
    "    - cleaned_combined: Combined cleaned data with dataset labels  \n",
    "    - processing_stats: Dictionary with processing statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    original_dfs = []\n",
    "    cleaned_dfs = []\n",
    "    processing_stats = {}\n",
    "    global_cell_id = 0  # Global counter for unique cell IDs\n",
    "    \n",
    "    for i, file_path in enumerate(file_paths):\n",
    "        # Load data\n",
    "        df = load_csv_data(file_path)\n",
    "        dataset_name = Path(file_path).stem\n",
    "        \n",
    "        # Store original cell_id for reference\n",
    "        df['original_cell_id'] = df['cell_id']\n",
    "        \n",
    "        # Create unique cell_id across all datasets\n",
    "        df['cell_id'] = range(global_cell_id, global_cell_id + len(df))\n",
    "        global_cell_id += len(df)\n",
    "        \n",
    "        # Add dataset identifier\n",
    "        df['dataset'] = dataset_name\n",
    "        df['dataset_id'] = i\n",
    "        \n",
    "        # Store original\n",
    "        original_dfs.append(df)\n",
    "        \n",
    "        # Remove outliers within dataset\n",
    "        df_clean = remove_outliers(df, outlier_column, method, factor)\n",
    "        \n",
    "        # Ensure dataset info is preserved after outlier removal\n",
    "        df_clean['dataset'] = dataset_name\n",
    "        df_clean['dataset_id'] = i\n",
    "        \n",
    "        cleaned_dfs.append(df_clean)\n",
    "        \n",
    "        # Store stats\n",
    "        processing_stats[dataset_name] = {\n",
    "            'original_count': len(df),\n",
    "            'cleaned_count': len(df_clean),\n",
    "            'outliers_removed': len(df) - len(df_clean),\n",
    "            'outlier_percentage': ((len(df) - len(df_clean))/len(df)*100)\n",
    "        }\n",
    "    \n",
    "    # Combine datasets\n",
    "    original_combined = pd.concat(original_dfs, ignore_index=True)\n",
    "    cleaned_combined = pd.concat(cleaned_dfs, ignore_index=True)\n",
    "    \n",
    "    # Optional global outlier removal\n",
    "    if global_outlier_removal:\n",
    "        print(\"\\nApplying global outlier removal...\")\n",
    "        cleaned_combined = remove_outliers(cleaned_combined, outlier_column, method, factor)\n",
    "    \n",
    "    return original_combined, cleaned_combined, processing_stats\n",
    "\n",
    "def compare_datasets_statistics(df: pd.DataFrame, \n",
    "                              column: str, \n",
    "                              group_by: str = 'dataset') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate comparative statistics across datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: Combined DataFrame with dataset labels\n",
    "    - column: Column to analyze\n",
    "    - group_by: Column to group by (default: 'dataset')\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with comparative statistics\n",
    "    \"\"\"\n",
    "    stats = df.groupby(group_by)[column].agg([\n",
    "        'count', 'mean', 'median', 'std', 'min', 'max',\n",
    "        lambda x: x.quantile(0.25),  # Q1\n",
    "        lambda x: x.quantile(0.75),  # Q3\n",
    "    ]).round(3)\n",
    "    \n",
    "    stats.columns = ['Count', 'Mean', 'Median', 'Std', 'Min', 'Max', 'Q1', 'Q3']\n",
    "    stats['IQR'] = stats['Q3'] - stats['Q1']\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0ed8a3",
   "metadata": {},
   "source": [
    "### Visualization (Statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c8d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_violin(df: pd.DataFrame, column: str, title: Optional[str] = None, \n",
    "                figsize: Tuple[int, int] = (8, 6)) -> None:\n",
    "    \"\"\"\n",
    "    Create a violin plot for a specific column in the cell data DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the cell measurement data\n",
    "    - column: Name of the column to plot\n",
    "    - title: Optional title for the plot\n",
    "    - figsize: Figure size as (width, height)\n",
    "    \n",
    "    Returns:\n",
    "    - None (displays the plot)\n",
    "    \"\"\"\n",
    "    if column not in df.columns:\n",
    "        raise ValueError(f\"Column '{column}' not found in DataFrame. Available columns: {list(df.columns)}\")\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.violinplot(y=df[column])\n",
    "    \n",
    "    if title is None:\n",
    "        title = f\"Distribution of {column}\"\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.ylabel(column)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_violin_comparison(datasets: List[pd.DataFrame], column: str, \n",
    "                            dataset_labels: Optional[List[str]] = None,\n",
    "                            hue = None,\n",
    "                            title: Optional[str] = None, \n",
    "                            figsize: Optional[Tuple[int, int]] = None) -> None:\n",
    "    \"\"\"\n",
    "    Create violin plots comparing the same column across multiple datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    - datasets: List of DataFrames containing the cell measurement data\n",
    "    - column: Name of the column to plot\n",
    "    - dataset_labels: Optional list of labels for each dataset\n",
    "    - title: Optional title for the plot\n",
    "    - figsize: Optional figure size as (width, height). If None, adapts to number of datasets\n",
    "    \n",
    "    Returns:\n",
    "    - None (displays the plot)\n",
    "    \"\"\"\n",
    "    if not datasets:\n",
    "        raise ValueError(\"At least one dataset must be provided\")\n",
    "    \n",
    "    # Check if column exists in all datasets\n",
    "    for i, df in enumerate(datasets):\n",
    "        if column not in df.columns:\n",
    "            raise ValueError(f\"Column '{column}' not found in dataset {i}. Available columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Set default labels if not provided\n",
    "    if dataset_labels is None:\n",
    "        dataset_labels = [f\"Dataset {i+1}\" for i in range(len(datasets))]\n",
    "    elif len(dataset_labels) != len(datasets):\n",
    "        raise ValueError(\"Number of dataset labels must match number of datasets\")\n",
    "    # Prepare data for seaborn\n",
    "    combined_data = []\n",
    "    for i, (df, label) in enumerate(zip(datasets, dataset_labels)):\n",
    "        temp_df = pd.DataFrame({\n",
    "            column: df[column],\n",
    "            'Dataset': label\n",
    "        })\n",
    "        combined_data.append(temp_df)\n",
    "    \n",
    "    plot_data = pd.concat(combined_data, ignore_index=True)\n",
    "    \n",
    "    # Adaptive figure size\n",
    "    if figsize is None:\n",
    "        width = max(8, len(datasets) * 2)\n",
    "        figsize = (width, 6)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.violinplot(data=plot_data, x='Dataset', y=column , color= 'seagreen', log_scale=False)\n",
    "    \n",
    "    if title is None:\n",
    "        title = f\"Comparison of {column} across datasets\"\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.ylabel(column)\n",
    "    plt.xticks(rotation=45 if len(dataset_labels) > 3 else 0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    def plot_scatter(df: pd.DataFrame, x_column: str, y_column: str, \n",
    "                     title: Optional[str] = None, \n",
    "                     figsize: Tuple[int, int] = (8, 6),\n",
    "                     alpha: float = 0.6) -> None:\n",
    "        \"\"\"\n",
    "        Create a scatter plot of one column against another.\n",
    "        \n",
    "        Parameters:\n",
    "        - df: DataFrame containing the cell measurement data\n",
    "        - x_column: Name of the column for x-axis\n",
    "        - y_column: Name of the column for y-axis\n",
    "        - title: Optional title for the plot\n",
    "        - figsize: Figure size as (width, height)\n",
    "        - alpha: Transparency of points (0-1)\n",
    "        \n",
    "        Returns:\n",
    "        - None (displays the plot)\n",
    "        \"\"\"\n",
    "        if x_column not in df.columns:\n",
    "            raise ValueError(f\"Column '{x_column}' not found in DataFrame. Available columns: {list(df.columns)}\")\n",
    "        if y_column not in df.columns:\n",
    "            raise ValueError(f\"Column '{y_column}' not found in DataFrame. Available columns: {list(df.columns)}\")\n",
    "        \n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.scatter(df[x_column], df[y_column], alpha=alpha)\n",
    "        \n",
    "        if title is None:\n",
    "            title = f\"{y_column} vs {x_column}\"\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.xlabel(x_column)\n",
    "        plt.ylabel(y_column)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d0b00c",
   "metadata": {},
   "source": [
    "## Cell-Analysis (Dark Experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab291d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_data_path = autils.select_file()\n",
    "print(f\"Selected cell data file: {os.path.basename(cell_data_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c25f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_data_no_dox_dark_path = autils.select_files()\n",
    "cell_data_no_dox_light_path = autils.select_files()\n",
    "cell_data_48_dox_dark_path = autils.select_files()\n",
    "cell_data_48_dox_light_path = autils.select_files()\n",
    "cell_data_cont_dox_dark_path = autils.select_files()\n",
    "cell_data_cont_dox_light_path = autils.select_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07417bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_data_no_dox_dark =load_and_process_multiple_csvs(cell_data_no_dox_dark_path, outlier_column='channel_2_ctcf')\n",
    "cell_data_no_dox_light = load_and_process_multiple_csvs(cell_data_no_dox_light_path, outlier_column='channel_2_ctcf')\n",
    "cell_data_48_dox_dark = load_and_process_multiple_csvs(cell_data_48_dox_dark_path, outlier_column='channel_2_ctcf')\n",
    "cell_data_48_dox_light = load_and_process_multiple_csvs(cell_data_48_dox_light_path, outlier_column='channel_2_ctcf')\n",
    "cell_data_cont_dox_dark = load_and_process_multiple_csvs(cell_data_cont_dox_dark_path, outlier_column='channel_2_ctcf')\n",
    "cell_data_cont_dox_light = load_and_process_multiple_csvs(cell_data_cont_dox_light_path, outlier_column='channel_2_ctcf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9e8fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_data_list_dox_cal= [\n",
    "    cell_data_no_dox_dark[1],\n",
    "    cell_data_no_dox_light[1],\n",
    "    cell_data_48_dox_dark[1],\n",
    "    cell_data_48_dox_light[1],\n",
    "    cell_data_cont_dox_dark[1],\n",
    "    cell_data_cont_dox_light[1]\n",
    "]\n",
    "\n",
    "for i, dataset in enumerate(cell_data_list_dox_cal):\n",
    "    dataset['Type'] = 'Cal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f935d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_violin_comparison(\n",
    "    cell_data_list_dox_cal,\n",
    "    column='channel_2_ctcf',\n",
    "    dataset_labels=[\n",
    "        'No Dox Dark', \n",
    "        'No Dox Light', \n",
    "        '48h Dox Dark', \n",
    "        '48h Dox Light', \n",
    "        'Continuous Dox Dark', \n",
    "        'Continuous Dox Light'\n",
    "    ],\n",
    "    title='Comparison of Channel 2 mean across datasets',\n",
    "    # figsize=(12, 6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adcfb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_data_dark_1d = load_and_process_multiple_csvs(cell_data_dark_1d_paths, \n",
    "                                                  outlier_column='channel_2_ctcf')\n",
    "cell_data_dark_2d = load_and_process_multiple_csvs(cell_data_dark_2d_paths,\n",
    "                                                  outlier_column='channel_2_ctcf')\n",
    "# cell_data_dark_3d = load_and_process_multiple_csvs(cell_data_dark_3d_paths,\n",
    "#                                                   outlier_column='channel_2_ctcf')\n",
    "cell_data_dark_4d = load_and_process_multiple_csvs(cell_data_dark_4d_paths,\n",
    "                                                    outlier_column='channel_2_ctcf')\n",
    "cell_data_dark_5d = load_and_process_multiple_csvs(cell_data_dark_5d_paths,\n",
    "                                                    outlier_column='channel_2_ctcf')\n",
    "cell_data_dark_6d = load_and_process_multiple_csvs(cell_data_dark_6d_paths,\n",
    "                                                    outlier_column='channel_2_ctcf')\n",
    "cell_data_dark_7d = load_and_process_multiple_csvs(cell_data_dark_7d_paths,\n",
    "                                                    outlier_column='channel_2_ctcf')\n",
    "cell_data_dark_8d = load_and_process_multiple_csvs(cell_data_dark_8d_paths,\n",
    "                                                    outlier_column='channel_2_ctcf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a85f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_data_dark_1d[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7cdfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_data_list_original = [\n",
    "    cell_data_dark_1d[0],cell_data_dark_2d[0],\n",
    "    # cell_data_dark_3d[0],\n",
    "    cell_data_dark_4d[0],\n",
    "    cell_data_dark_5d[0],cell_data_dark_6d[0],\n",
    "    cell_data_dark_7d[0],cell_data_dark_8d[0]\n",
    "]\n",
    "\n",
    "plot_violin_comparison(cell_data_list_original,\n",
    "                       column='channel_2_ctcf',\n",
    "                          dataset_labels=[\n",
    "                            '1D', '2D', '4D', '5D', '6D', '7D', '8D'\n",
    "                          ],\n",
    "                          title='Comparison of channel_2_ctcf across datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0e3ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_data_list =  [cell_data_dark_1d[1], cell_data_dark_2d[1],\n",
    "                    #cell_data_dark_3d[1], \n",
    "                    cell_data_dark_4d[1],\n",
    "                    cell_data_dark_5d[1], cell_data_dark_6d[1],\n",
    "                    cell_data_dark_7d[1], cell_data_dark_8d[1]]\n",
    "\n",
    "plot_violin_comparison(cell_data_list,\n",
    "                       column='channel_2_ctcf',\n",
    "                       dataset_labels=['1D', '2D', '4D', '5D', '6D', '7D', '8D'],\n",
    "                       title='Comparison of Channel 2 CTCF across ST-CalLight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd07129",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_violin_comparison(cell_data_list,\n",
    "                       column='channel_4_ctcf',\n",
    "                          dataset_labels=['1D', '2D', '4D', '5D', '6D', '7D', '8D'],\n",
    "                          title='Comparison of channel_4_ctcf across CalLight datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c511cd7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97965407",
   "metadata": {},
   "source": [
    "## Cell-Analysis (Dox-Experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb3a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_dox_48_L_path = autils.select_files()\n",
    "cal_dox_cont_L_path = autils.select_files()\n",
    "cal_dox_no_L_path = autils.select_files()\n",
    "\n",
    "cal_dox_48_D_paths = autils.select_files()\n",
    "cal_dox_cont_D_paths = autils.select_files()\n",
    "cal_dox_no_D_paths = autils.select_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3a2f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_dox_48_L_df = load_and_process_multiple_csvs(cal_dox_48_L_path,\n",
    "                                                outlier_column='channel_2_ctcf')\n",
    "cal_dox_cont_L_df = load_and_process_multiple_csvs(cal_dox_cont_L_path,\n",
    "                                                    outlier_column='channel_2_ctcf')\n",
    "cal_dox_no_L_df = load_and_process_multiple_csvs(cal_dox_no_L_path,\n",
    "                                                  outlier_column='channel_2_ctcf')\n",
    "\n",
    "cal_dox_48_D_df = load_and_process_multiple_csvs(cal_dox_48_D_paths,\n",
    "                                                outlier_column='channel_2_ctcf')\n",
    "cal_dox_cont_D_df = load_and_process_multiple_csvs(cal_dox_cont_D_paths,\n",
    "                                                    outlier_column='channel_2_ctcf')\n",
    "cal_dox_no_D_df = load_and_process_multiple_csvs(cal_dox_no_D_paths,\n",
    "                                                  outlier_column='channel_2_ctcf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a9130",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_data_list_dox = [\n",
    "    cal_dox_48_L_df[1], cal_dox_cont_L_df[1], cal_dox_no_L_df[1],\n",
    "    cal_dox_48_D_df[1], cal_dox_cont_D_df[1], cal_dox_no_D_df[1]\n",
    "]\n",
    "\n",
    "for i, dataset in enumerate(cell_data_list_dox):\n",
    "    dataset['Type'] = 'Cal'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8335492",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_data_list_dox_scfl = [\n",
    "    cal_dox_48_L_df[1], cal_dox_cont_L_df[1], cal_dox_no_L_df[1],\n",
    "    cal_dox_48_D_df[1], cal_dox_cont_D_df[1], cal_dox_no_D_df[1]\n",
    "]\n",
    "\n",
    "for i, dataset in enumerate(cell_data_list_dox_scfl):\n",
    "    dataset['Type'] = 'scFL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2182286",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_violin_comparison(cell_data_list_dox,\n",
    "                       column='channel_2_ctcf',\n",
    "                       dataset_labels=['48h L', 'Cont L', 'No L', '48h D', 'Cont D', 'No D'],\n",
    "                       title='Comparison of Channel 2 CTCF across Dox datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191e8ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_violin_comparison(cell_data_list_dox_scfl,\n",
    "                       column='channel_2_ctcf',\n",
    "                       dataset_labels=['48h L', 'Cont L', 'No L', '48h D', 'Cont D', 'No D'],\n",
    "                       title='Comparison of Channel 2 CTCF across Dox scFL datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0578b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".auto_img",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
