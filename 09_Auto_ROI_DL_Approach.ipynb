{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideal Processing Pipeline for Consistent CTCF in Fluorescence Microscopy\n",
    "\n",
    "Here's a comprehensive pipeline for analyzing fluorescence microscopy images with consistent CTCF measurement across different conditions and microscopes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import necessary libraries\n",
    "import time, os, sys\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "import tifffile as tiff\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import measure, draw, exposure\n",
    "from skimage.transform import resize\n",
    "from skimage.segmentation import find_boundaries\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "import scipy.stats\n",
    "\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "from functools import partial\n",
    "from filelock import FileLock\n",
    "import torch\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 200\n",
    "mpl.use('Agg')  # Set non-interactive backend globally\n",
    "\n",
    "from AutoImgUtils import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2025 NVIDIA Corporation\n",
      "Built on Fri_Feb_21_20:42:46_Pacific_Standard_Time_2025\n",
      "Cuda compilation tools, release 12.8, V12.8.93\n",
      "Build cuda_12.8.r12.8/compiler.35583870_0\n",
      "Fri Apr 11 20:32:27 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 572.61                 Driver Version: 572.61         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA TITAN RTX             WDDM  |   00000000:81:00.0 Off |                  N/A |\n",
      "| 41%   42C    P8             22W /  280W |     997MiB /  24576MiB |     18%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            1640    C+G   ...h_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A            2920    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A            3872    C+G   ...x64__8wekyb3d8bbwe\\Photos.exe      N/A      |\n",
      "|    0   N/A  N/A            4316    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A            7944    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A            8480    C+G   ...Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A            8928    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           11056    C+G   ...h_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A           11372    C+G   ....0.3179.54\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           13056    C+G   ...App_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A           14780    C+G   ...crosoft\\OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A           15352    C+G   ...es\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A           15400    C+G   ...rage Manager\\JRE\\bin\\java.exe      N/A      |\n",
      "|    0   N/A  N/A           16024      C   C:\\Python312\\python.exe               N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      ">>> GPU activated? YES\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version\n",
    "!nvidia-smi\n",
    "\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import core, utils, io, models, metrics, denoise\n",
    "from glob import glob\n",
    "\n",
    "use_GPU = core.use_gpu()\n",
    "yn = ['NO', 'YES']\n",
    "print(f'>>> GPU activated? {yn[use_GPU]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization functions\n",
    "Here the visualization functions are defined, that can be used to save plots regarding the background substraction as well as the segmentation results for quality control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_background_mask(channel_image, bg_model, output_path, n_components=3, enhance_contrast=True):\n",
    "    \"\"\"Visualize background mask from GMM model with distribution plots\"\"\"\n",
    "    # Create figure with 4 subplots (2x2 grid)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12), gridspec_kw={'height_ratios': [3, 1]})\n",
    "    \n",
    "    # Enhance contrast for visualization if requested\n",
    "    if enhance_contrast:\n",
    "        # Use percentile-based contrast stretching (robust to outliers)\n",
    "        p_low, p_high = 2, 98  # Percentiles for contrast stretching\n",
    "        display_img = exposure.rescale_intensity(\n",
    "            channel_image, \n",
    "            in_range=tuple(np.percentile(channel_image, (p_low, p_high))),\n",
    "            out_range='dtype'\n",
    "        )\n",
    "    else:\n",
    "        display_img = channel_image\n",
    "    \n",
    "    # Original image with enhanced contrast\n",
    "    axes[0, 0].imshow(display_img, cmap='gray')\n",
    "    axes[0, 0].set_title('Original Channel' + (' (Contrast Enhanced)' if enhance_contrast else ''))\n",
    "    plt.colorbar(axes[0, 0].get_images()[0], ax=axes[0, 0])\n",
    "    \n",
    "    # Background mask\n",
    "    axes[0, 1].imshow(bg_model['mask'], cmap='hot')\n",
    "    axes[0, 1].set_title(f'Background Mask\\nMean: {bg_model[\"mean\"]:.2f}, Std: {bg_model[\"std\"]:.2f}')\n",
    "    plt.colorbar(axes[0, 1].get_images()[0], ax=axes[0, 1])\n",
    "    \n",
    "    # Original with background highlighted\n",
    "    norm_img = (channel_image - np.min(channel_image)) / (np.max(channel_image) - np.min(channel_image))\n",
    "    rgb_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
    "    \n",
    "    # Highlight background in red\n",
    "    rgb_img[:,:,0][bg_model['mask']] = 1.0  # Set red high for background\n",
    "    rgb_img[:,:,1][bg_model['mask']] = 0.0  # Set green low for background\n",
    "    rgb_img[:,:,2][bg_model['mask']] = 0.0  # Set blue low for background\n",
    "    \n",
    "    axes[1, 0].imshow(rgb_img)\n",
    "    axes[1, 0].set_title('Background Regions (Red)')\n",
    "    \n",
    "    # Plot intensity histogram with GMM distributions\n",
    "    # Modified to use component parameters instead of GMM object\n",
    "    if 'component_weights' in bg_model and 'component_means' in bg_model and 'component_covs' in bg_model:\n",
    "        flat_img = channel_image.flatten()\n",
    "        \n",
    "        # Plot histogram\n",
    "        hist_range = (np.min(flat_img), np.max(flat_img))\n",
    "        n_bins = 100\n",
    "        axes[1, 1].hist(flat_img, bins=n_bins, range=hist_range, density=True, \n",
    "                       alpha=0.6, color='gray', label='Pixel Intensity')\n",
    "        \n",
    "        # Create x values for plotting GMM curves\n",
    "        x = np.linspace(hist_range[0], hist_range[1], 1000)\n",
    "        \n",
    "        # Plot the individual components\n",
    "        colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "        bg_component = bg_model['bg_component']\n",
    "        \n",
    "        for i in range(len(bg_model['component_means'])):\n",
    "            # Calculate component density\n",
    "            weight = bg_model['component_weights'][i]\n",
    "            mean = bg_model['component_means'][i]\n",
    "            std = np.sqrt(bg_model['component_covs'][i])\n",
    "            \n",
    "            # Create a normal distribution for this component\n",
    "            y = weight * scipy.stats.norm.pdf(x, mean, std)\n",
    "            \n",
    "            # Plot with higher alpha for background component\n",
    "            alpha = 0.8 if i == bg_component else 0.5\n",
    "            label = f\"Background (μ={mean:.1f})\" if i == bg_component else f\"Component {i+1} (μ={mean:.1f})\"\n",
    "            axes[1, 1].plot(x, y, color=colors[i % len(colors)], \n",
    "                         alpha=alpha, linewidth=2, label=label)\n",
    "            \n",
    "        axes[1, 1].set_title('Pixel Intensity Distribution')\n",
    "        axes[1, 1].set_xlabel('Pixel Value')\n",
    "        axes[1, 1].set_xscale('log')\n",
    "        axes[1, 1].set_ylabel('Density')\n",
    "        axes[1, 1].legend()\n",
    "        \n",
    "        del flat_img, hist_range, n_bins, x\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=200)\n",
    "    plt.close('all')\n",
    "\n",
    "    del display_img, rgb_img\n",
    "\n",
    "def save_segmentation_qc_images(image, cell_masks, output_dir, img_name, config=None):\n",
    "    \"\"\"\n",
    "    Save quality control images showing zoomed-in regions of segmentation results\n",
    "    \n",
    "    Parameters:\n",
    "    - image: Multi-channel image array\n",
    "    - cell_masks: Integer mask with cell labels\n",
    "    - output_dir: Directory to save output images\n",
    "    - img_name: Base name of the image being processed\n",
    "    - config: Configuration dictionary with QC settings\n",
    "    \"\"\"\n",
    "    if config is None:\n",
    "        config = {}\n",
    "    \n",
    "    # Extract configuration\n",
    "    num_regions = config.get('qc_num_regions', 3)\n",
    "    region_size = config.get('qc_region_size', 400)\n",
    "    channels_to_show = config.get('qc_channels', list(range(image.shape[-1])))\n",
    "    \n",
    "    # Get cell properties and centroids\n",
    "    props = measure.regionprops(cell_masks)\n",
    "    \n",
    "    if len(props) == 0:\n",
    "        print(\"No cells detected for QC visualization\")\n",
    "        return\n",
    "    \n",
    "    # Create QC directory\n",
    "    qc_dir = os.path.join(output_dir, \"qc_regions\")\n",
    "    os.makedirs(qc_dir, exist_ok=True)\n",
    "    \n",
    "    # Select cell regions to display\n",
    "    # Strategy 1: Select cells with most area (likely most interesting)\n",
    "    props_sorted_by_area = sorted(props, key=lambda x: x.area, reverse=True)\n",
    "    \n",
    "    # Select some large cells and some random cells for diversity\n",
    "    selected_props = props_sorted_by_area[:min(num_regions, len(props))]\n",
    "    \n",
    "    # Add some random cells from the remaining population if available\n",
    "    remaining_props = props_sorted_by_area[min(num_regions, len(props)):]\n",
    "    if remaining_props and len(remaining_props) > num_regions:\n",
    "        random_indices = np.random.choice(len(remaining_props), \n",
    "                                         min(num_regions, len(remaining_props)), \n",
    "                                         replace=False)\n",
    "        selected_props.extend([remaining_props[i] for i in random_indices])\n",
    "    \n",
    "    # Process each selected region\n",
    "    for i, prop in enumerate(selected_props):\n",
    "        # Get centroid and bounds for region extraction\n",
    "        y, x = int(prop.centroid[0]), int(prop.centroid[1])\n",
    "        \n",
    "        # Define boundaries ensuring they're within image bounds\n",
    "        h, w = image.shape[0:2]\n",
    "        half_size = region_size // 2\n",
    "        \n",
    "        y1 = max(0, y - half_size)\n",
    "        y2 = min(h, y + half_size)\n",
    "        x1 = max(0, x - half_size)\n",
    "        x2 = min(w, x + half_size)\n",
    "        \n",
    "        # Extract region masks\n",
    "        region_mask = cell_masks[y1:y2, x1:x2]\n",
    "        \n",
    "        # Create figure with rows for each channel and columns for (original, mask overlay)\n",
    "        num_channels = len(channels_to_show)\n",
    "        fig, axes = plt.subplots(num_channels, 2, figsize=(12, 4*num_channels))\n",
    "        \n",
    "        if num_channels == 1:\n",
    "            axes = np.array([axes])  # Make it 2D for consistent indexing\n",
    "            \n",
    "        region_name = f\"region_{i+1}_cell_{prop.label}\"\n",
    "        fig.suptitle(f\"Region {i+1}: Cell {prop.label} (Area: {prop.area}px)\")\n",
    "        \n",
    "        # Process each channel\n",
    "        for ch_idx, ch in enumerate(channels_to_show):\n",
    "            if ch < image.shape[-1]:  # Ensure channel exists\n",
    "                # Extract region for this channel\n",
    "                region_img = image[y1:y2, x1:x2, ch]\n",
    "                \n",
    "                # Normalize for display\n",
    "                p2, p98 = np.percentile(region_img, (2, 98))\n",
    "                region_img_norm = np.clip((region_img - p2) / (p98 - p2) * 255, 0, 255).astype(np.uint8)\n",
    "                \n",
    "                # Display original channel\n",
    "                axes[ch_idx, 0].imshow(region_img_norm, cmap='gray')\n",
    "                axes[ch_idx, 0].set_title(f\"Channel {ch+1}\")\n",
    "                axes[ch_idx, 0].axis('off')\n",
    "                \n",
    "                # Create mask overlay\n",
    "                mask_overlay = np.zeros((*region_img.shape, 4), dtype=np.uint8)\n",
    "                \n",
    "                # Unique colors for each cell in the region\n",
    "                unique_labels = np.unique(region_mask)\n",
    "                unique_labels = unique_labels[unique_labels > 0]  # Skip background\n",
    "                \n",
    "                # Create colorful mask overlay\n",
    "                for label in unique_labels:\n",
    "                    color = np.array(plt.cm.tab10(label % 10)) * 255\n",
    "                    mask_overlay[region_mask == label] = [*color[:3], 128]  # Semi-transparent\n",
    "                    \n",
    "                # Show mask overlaid on original image\n",
    "                axes[ch_idx, 1].imshow(region_img_norm, cmap='gray')\n",
    "                axes[ch_idx, 1].imshow(mask_overlay)\n",
    "                axes[ch_idx, 1].set_title(f\"Channel {ch+1} with segmentation\")\n",
    "                axes[ch_idx, 1].axis('off')\n",
    "        \n",
    "        # Adjust layout and save\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.95)  # Make room for suptitle\n",
    "        region_filename = os.path.join(qc_dir, f\"{os.path.splitext(img_name)[0]}_{region_name}.png\")\n",
    "        plt.savefig(region_filename, dpi=150)\n",
    "        plt.close(fig)\n",
    "    \n",
    "    print(f\"Saved {len(selected_props)} QC region visualizations to {qc_dir}\")\n",
    "\n",
    "def create_visualization(image, masks, measurements, output_path, debug=False):\n",
    "    \"\"\"\n",
    "    Create multi-panel visualization for QC with optimized memory usage and enhanced contrast\n",
    "    \n",
    "    Parameters:\n",
    "    - image: Multi-channel image\n",
    "    - masks: Cell segmentation masks\n",
    "    - measurements: Cell measurements\n",
    "    - output_path: Where to save the visualization\n",
    "    - debug: Enable detailed timing and progress tracking\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if debug:\n",
    "            start_time = time.time()\n",
    "            print(f\"Starting visualization for {output_path}...\")\n",
    "        \n",
    "        # Force garbage collection before starting\n",
    "        gc.collect()\n",
    "        \n",
    "        # Get image dimensions and channel count\n",
    "        h, w, n_channels = image.shape\n",
    "        \n",
    "        # Calculate reasonable figure size to avoid excessive memory usage\n",
    "        max_dim = 2000  # Maximum dimension in pixels\n",
    "        scale_factor = min(1.0, max_dim / max(h, w))\n",
    "        \n",
    "        # Create figure without displaying (reduces memory usage)\n",
    "        dpi = 300  # Mantain good quality\n",
    "        fig_width = (n_channels + 1) * 4  # 4 inches per panel\n",
    "        fig_height = 4  # Fixed height\n",
    "        \n",
    "        # Use Figure directly instead of pyplot to avoid memory leaks\n",
    "        fig = Figure(figsize=(fig_width, fig_height), dpi=dpi)\n",
    "        canvas = FigureCanvasAgg(fig)\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Created figure with size {fig_width}x{fig_height} inches at {dpi} DPI\")\n",
    "            print(f\"Processing {n_channels} channels and {len(measurements)} cells\")\n",
    "        \n",
    "        # Create subplot grid\n",
    "        grid = fig.add_gridspec(1, n_channels + 1)\n",
    "        \n",
    "        # Plot segmentation mask (first panel) with enhanced contrast\n",
    "        if debug:\n",
    "            print(\"Rendering segmentation mask...\")\n",
    "        \n",
    "        ax = fig.add_subplot(grid[0, 0])\n",
    "        \n",
    "        # Convert mask to float for better visualization\n",
    "        mask_display = (masks > 0).astype(float)\n",
    "        # Apply contrast enhancement to make it more visible\n",
    "        mask_display = exposure.equalize_adapthist(mask_display)\n",
    "        ax.imshow(mask_display, cmap='viridis')  # Use viridis for better contrast\n",
    "        ax.set_title('Cell Segmentation (Enhanced)')\n",
    "        ax.axis('off')  # Turn off axes to save memory\n",
    "        \n",
    "        # Only add labels for a subset of cells\n",
    "        if len(measurements) > 0:\n",
    "            if debug:\n",
    "                print(\"Adding cell labels...\")\n",
    "            # Select a random subset of 50 cells or fewer if there are less than 50\n",
    "            num_labels = min(50, len(measurements))\n",
    "            # Use numpy's random choice if measurements is a list, otherwise select first num_labels\n",
    "            if isinstance(measurements, list):\n",
    "                indices = np.random.choice(len(measurements), num_labels, replace=False)\n",
    "                label_subset = [measurements[i] for i in indices]\n",
    "            else:\n",
    "                label_subset = measurements[:num_labels]\n",
    "                \n",
    "            for cell in label_subset:\n",
    "                y, x = cell['centroid']\n",
    "                ax.text(x, y, str(cell['label']), color='red', fontsize=5)\n",
    "        \n",
    "        # Process channels with progress tracking\n",
    "        channel_range = range(n_channels)\n",
    "        if debug:\n",
    "            from tqdm import tqdm\n",
    "            channel_range = tqdm(channel_range, desc=\"Processing channels\")\n",
    "        \n",
    "        for ch_idx, ch in enumerate(channel_range):\n",
    "            if debug:\n",
    "                ch_start = time.time()\n",
    "                \n",
    "            # Create subplot for this channel\n",
    "            ax = fig.add_subplot(grid[0, ch_idx + 1])\n",
    "            \n",
    "            # Get channel data and apply adaptive contrast enhancement\n",
    "            channel_data = image[:,:,ch].copy()  # Make a copy to avoid modifying original\n",
    "            \n",
    "            # Adaptive histogram equalization - best for visualizing local features\n",
    "            enhanced_data = exposure.equalize_adapthist(channel_data, clip_limit=0.03)\n",
    "            \n",
    "            # Display the image\n",
    "            ax.imshow(enhanced_data, cmap='hot')\n",
    "            ax.set_title(f'Channel {ch+1} (Enhanced)')\n",
    "            ax.axis('off')  # Turn off axes to save memory\n",
    "            \n",
    "            # Show cell boundaries efficiently\n",
    "            boundaries = find_boundaries(masks > 0)\n",
    "            ax.imshow(boundaries, alpha=0.3, cmap='cool')\n",
    "            \n",
    "            # Free memory\n",
    "            del channel_data\n",
    "            del enhanced_data\n",
    "            del boundaries\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"  Channel {ch+1} rendered in {time.time() - ch_start:.2f}s\")\n",
    "        \n",
    "        # Adjust layout and save\n",
    "        if debug:\n",
    "            print(\"Saving figure...\")\n",
    "            save_start = time.time()\n",
    "            \n",
    "        fig.tight_layout()\n",
    "        fig.savefig(output_path, bbox_inches='tight')\n",
    "        \n",
    "        # Clean up matplotlib resources explicitly\n",
    "        fig.clf()\n",
    "        canvas.renderer.clear()\n",
    "        del fig\n",
    "        del canvas\n",
    "        \n",
    "        # Force garbage collection\n",
    "        gc.collect()\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Visualization saved in {time.time() - save_start:.2f}s\")\n",
    "            print(f\"Total visualization time: {time.time() - start_time:.2f}s\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in visualization: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        # Ensure cleanup even on error\n",
    "        if 'fig' in locals():\n",
    "            fig.clf()\n",
    "            del fig\n",
    "        if 'canvas' in locals():\n",
    "            canvas.renderer.clear()\n",
    "            del canvas\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background substraction and CellPose based Segmentation Functions\n",
    "Here the main functions for background substraction and cell segmentation based on de cyto3 model are defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for File processing and Directory Handling \n",
    "def process_experiments_batch(main_directory, config):\n",
    "    \"\"\"\n",
    "    Process all experiments in the main directory with improved memory management\n",
    "    \"\"\"\n",
    "    # Create results directory\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_dir = os.path.join(main_directory, f\"CTCF_Analysis_{timestamp}\")\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Find all experiment folders\n",
    "    experiment_folders = [f.path for f in os.scandir(main_directory) if f.is_dir() \n",
    "                         and not f.name.startswith('.') and not \"CTCF_Analysis\" in f.name]\n",
    "    \n",
    "    # Process each experiment folder\n",
    "    for experiment_folder in experiment_folders:\n",
    "        exp_name = os.path.basename(experiment_folder)\n",
    "        print(f\"\\nProcessing experiment: {exp_name}\")\n",
    "        \n",
    "        # Create experiment results folder\n",
    "        exp_results_dir = os.path.join(results_dir, exp_name)\n",
    "        os.makedirs(exp_results_dir, exist_ok=True)\n",
    "        \n",
    "        # Process all images in experiment folder\n",
    "        image_files = [f for f in os.listdir(experiment_folder) \n",
    "                      if f.endswith(('.tif', '.tiff')) and not f.startswith('.')]\n",
    "        \n",
    "        # Create a DataFrame for experiment results instead of list to save memory\n",
    "        exp_results_df = pd.DataFrame()\n",
    "        \n",
    "        for image_file in image_files:\n",
    "            # Full image processing pipeline for each image\n",
    "            img_result = process_single_image(\n",
    "                os.path.join(experiment_folder, image_file),\n",
    "                exp_results_dir,\n",
    "                config\n",
    "            )\n",
    "            \n",
    "            # Append result to DataFrame directly\n",
    "            exp_results_df = pd.concat([exp_results_df, pd.DataFrame([img_result])], ignore_index=True)\n",
    "            \n",
    "            # Force garbage collection after each image\n",
    "            gc.collect()\n",
    "        \n",
    "        # Save experiment results\n",
    "        exp_results_df.to_csv(os.path.join(exp_results_dir, f\"{exp_name}_results.csv\"), index=False)\n",
    "        \n",
    "        # Write to batch summary file incrementally instead of keeping in memory\n",
    "        batch_summary_path = os.path.join(results_dir, \"batch_summary.csv\")\n",
    "        if os.path.exists(batch_summary_path):\n",
    "            exp_results_df.to_csv(batch_summary_path, mode='a', header=False, index=False)\n",
    "        else:\n",
    "            exp_results_df.to_csv(batch_summary_path, index=False)\n",
    "        \n",
    "        # Clear DataFrame to free memory\n",
    "        del exp_results_df\n",
    "        gc.collect()\n",
    "    \n",
    "    print(f\"All experiments processed. Results saved to: {results_dir}\")\n",
    "    return results_dir\n",
    "\n",
    "def process_single_image(image_path, output_dir, config):\n",
    "    \"\"\"Process a single fluorescence microscopy image with improved memory management\"\"\"\n",
    "    try:\n",
    "        # Load image and normalize channels\n",
    "        image = tiff.imread(image_path)\n",
    "        img_name = os.path.basename(image_path)\n",
    "        img_base = os.path.splitext(img_name)[0]\n",
    "\n",
    "        print(f\"\\nProcessing image: {img_name}\")\n",
    "\n",
    "        # Extract debug flag from config\n",
    "        debug = config.get('debug', False)\n",
    "        \n",
    "        # Move the shortest axis (channels) to the last index\n",
    "        shortest_axis = np.argmin(image.shape)\n",
    "        image = np.moveaxis(image, shortest_axis, -1)\n",
    "        \n",
    "        # Extract configuration\n",
    "        channels_of_interest = config.get('channels_of_interest', list(range(image.shape[-1])))\n",
    "        \n",
    "        # 1. BACKGROUND ESTIMATION USING GMM\n",
    "        print(\"Estimating background using GMM...\")\n",
    "        bg_models = {}\n",
    "        for ch in tqdm(range(image.shape[-1]), desc=\"Background estimation\", leave=False):\n",
    "            # Process one channel at a time to reduce memory usage\n",
    "            channel_data = image[:,:,ch].copy()  # Make a copy to avoid reference issues\n",
    "            bg_models[ch] = estimate_background_gmm(channel_data,config)\n",
    "            \n",
    "            # Save background mask visualization if needed\n",
    "            if config.get('visualize_bg', True):\n",
    "                visualize_background_mask(channel_data, bg_models[ch], \n",
    "                                         os.path.join(output_dir, f\"{img_base}_bg_mask_ch{ch+1}.png\"))\n",
    "                plt.close('all')  # Ensure all plots are closed\n",
    "            \n",
    "            # Remove channel data from memory\n",
    "            del channel_data\n",
    "        \n",
    "        print(\"Background estimation complete.\")\n",
    "        \n",
    "        # 2. CELL SEGMENTATION USING CELLPOSE\n",
    "        cell_masks = segment_cells_with_downsampling(image, config, bg_models)\n",
    "        \n",
    "        # 3. MEASURE CTCF FOR EACH CELL AND CHANNEL\n",
    "        cell_measurements = measure_cells(image, cell_masks, bg_models, config)\n",
    "        \n",
    "        # Store key results in a DataFrame and save immediately\n",
    "        cell_df = pd.DataFrame([\n",
    "            {\n",
    "                'image': img_name,\n",
    "                'cell_id': i,\n",
    "                'area': cell['area'],\n",
    "                **{f'channel_{ch+1}_ctcf': cell['ctcf'][ch] for ch in channels_of_interest},\n",
    "                **{f'channel_{ch+1}_mean': cell['mean'][ch] for ch in channels_of_interest},\n",
    "                'centroid_x': cell['centroid'][0],\n",
    "                'centroid_y': cell['centroid'][1]\n",
    "            }\n",
    "            for i, cell in enumerate(cell_measurements)\n",
    "        ])\n",
    "        cell_df.to_csv(os.path.join(output_dir, f\"{img_base}_cells.csv\"), index=False)\n",
    "        \n",
    "        # 4. GENERATE VISUALIZATIONS - do this after saving measurements to free memory\n",
    "        if debug:\n",
    "            print(f\"Starting visualization with debug mode...\")\n",
    "        if config.get('visualize_segmentation', True):\n",
    "            create_visualization(image, cell_masks, cell_measurements, \n",
    "                                os.path.join(output_dir, f\"{img_name}_analysis.png\"),\n",
    "                                debug=debug)\n",
    "            \n",
    "            # Explicitly close all plots and collect garbage\n",
    "            plt.close('all')\n",
    "        \n",
    "        if config.get('save_qc_regions', True):\n",
    "            save_segmentation_qc_images(\n",
    "                image, \n",
    "                cell_masks, \n",
    "                output_dir, \n",
    "                img_name, \n",
    "                config\n",
    "            )\n",
    "            \n",
    "        gc.collect()\n",
    "        \n",
    "        # 5. CLEANUP AND RETURN RESULTS\n",
    "        # Create a minimal results dictionary with just the summary stats\n",
    "        results = {\n",
    "            'image_name': img_name,\n",
    "            'total_cells': len(cell_measurements),\n",
    "            'image_path': image_path,\n",
    "        }\n",
    "        \n",
    "        # Add summarized measurements\n",
    "        for ch in channels_of_interest:\n",
    "            ch_ctcf = [cell['ctcf'][ch] for cell in cell_measurements]\n",
    "            results[f'channel_{ch+1}_mean_ctcf'] = np.mean(ch_ctcf)\n",
    "            results[f'channel_{ch+1}_median_ctcf'] = np.median(ch_ctcf)\n",
    "            results[f'channel_{ch+1}_std_ctcf'] = np.std(ch_ctcf)\n",
    "            \n",
    "        # Clean up large objects\n",
    "        del image, cell_masks, cell_measurements, bg_models, cell_df\n",
    "        gc.collect()\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        gc.collect()\n",
    "        return {'image_name': os.path.basename(image_path), 'error': str(e), 'total_cells': 0}\n",
    "\n",
    "def resample_image(image, scale_factor=0.5):\n",
    "    \"\"\"Resample image by the given scale factor\"\"\"\n",
    "    \n",
    "    # Get original dimensions\n",
    "    h, w, c = image.shape\n",
    "    \n",
    "    # Calculate new dimensions\n",
    "    new_h, new_w = int(h * scale_factor), int(w * scale_factor)\n",
    "    \n",
    "    # Resize image\n",
    "    resized = resize(image, (new_h, new_w, c), preserve_range=True, anti_aliasing=True)\n",
    "    \n",
    "    return resized.astype(image.dtype)\n",
    "\n",
    "def check_gpu_availability():\n",
    "    \"\"\"Check if GPU is available for processing\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def estimate_background_gmm(channel_image, config = None, n_components=3, sample_ratio=0.1, \n",
    "                                max_iter=100, max_components=6):\n",
    "    \"\"\"\n",
    "    Fast background estimation using GMM with optional adaptive component selection\n",
    "    \"\"\"\n",
    "    try:\n",
    "        adaptive = config.get('adaptive_gmm', False) if config else False\n",
    "\n",
    "        # Flatten image\n",
    "        flat_img = channel_image.flatten()\n",
    "        \n",
    "        # Downsample by random sampling\n",
    "        n_samples = max(10000, int(sample_ratio * flat_img.size))\n",
    "        indices = np.random.choice(flat_img.size, size=n_samples, replace=False)\n",
    "        sample_data = flat_img[indices].reshape(-1, 1)\n",
    "        \n",
    "        # Select GMM model - adaptive or fixed\n",
    "        if adaptive:\n",
    "            bic_scores = []\n",
    "            models = []\n",
    "            \n",
    "            # Try different numbers of components\n",
    "            for n in range(1, max_components + 1):\n",
    "                # Initialize with K-means for faster convergence\n",
    "                kmeans = KMeans(n_clusters=n, n_init=1, max_iter=100)\n",
    "                kmeans.fit(sample_data)\n",
    "                \n",
    "                # Configure and fit GMM\n",
    "                gmm = GaussianMixture(\n",
    "                    n_components=n, \n",
    "                    random_state=42,\n",
    "                    n_init=1, \n",
    "                    max_iter=max_iter,\n",
    "                    tol=1e-3,\n",
    "                    means_init=kmeans.cluster_centers_\n",
    "                )\n",
    "                \n",
    "                gmm.fit(sample_data)\n",
    "                bic_scores.append(gmm.bic(sample_data))\n",
    "                models.append(gmm)\n",
    "                \n",
    "                del kmeans\n",
    "                \n",
    "            # Select model with lowest BIC score\n",
    "            best_idx = np.argmin(bic_scores)\n",
    "            gmm = models[best_idx]\n",
    "            n_components = models[best_idx].n_components\n",
    "            print(f\"Adaptive GMM selected {n_components} components with BIC: {bic_scores[best_idx]:.2f}\")\n",
    "            \n",
    "            # Clean up unused models\n",
    "            for i, model in enumerate(models):\n",
    "                if i != best_idx:\n",
    "                    del model\n",
    "            models = None\n",
    "        else:\n",
    "            # Non-adaptive - just use specified components\n",
    "            # Initialize with K-means for faster convergence\n",
    "            kmeans = KMeans(n_clusters=n_components, n_init=1, max_iter=100)\n",
    "            kmeans.fit(sample_data)\n",
    "            \n",
    "            # Configure GMM and fit\n",
    "            gmm = GaussianMixture(\n",
    "                n_components=n_components,\n",
    "                random_state=42,\n",
    "                n_init=1,\n",
    "                max_iter=max_iter,\n",
    "                tol=1e-3,\n",
    "                means_init=kmeans.cluster_centers_\n",
    "            )\n",
    "            gmm.fit(sample_data)\n",
    "            del kmeans\n",
    "        \n",
    "        # Extract model parameters\n",
    "        means = gmm.means_.flatten()\n",
    "        covs = np.array([gmm.covariances_[i].flatten()[0] for i in range(gmm.n_components)])\n",
    "        weights = gmm.weights_\n",
    "        \n",
    "        # Identify background component (lowest mean)\n",
    "        bg_component = np.argmin(means)\n",
    "        bg_mean = means[bg_component]\n",
    "        bg_std = np.sqrt(covs[bg_component])\n",
    "        \n",
    "        # Use original model to predict components - more efficient\n",
    "        pixel_labels = gmm.predict(flat_img.reshape(-1, 1))\n",
    "        bg_mask = (pixel_labels == bg_component).reshape(channel_image.shape)\n",
    "        \n",
    "        # Clean up sample data to free memory\n",
    "        del sample_data, flat_img, pixel_labels\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'mean': bg_mean,\n",
    "            'std': bg_std,\n",
    "            'mask': bg_mask,\n",
    "            'bg_percentage': np.sum(bg_mask) / bg_mask.size * 100,\n",
    "            'component_means': means,\n",
    "            'component_weights': weights,\n",
    "            'component_covs': covs,\n",
    "            'n_components': n_components,\n",
    "            'bg_component': bg_component,\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in GMM background estimation: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        # Return fallback values\n",
    "        return {'mean': 0, 'std': 0, 'mask': np.zeros_like(channel_image, dtype=bool)}\n",
    "    \n",
    "def segment_cells_cellpose(image, config, bg_models=None):\n",
    "\n",
    "    \"\"\"Cell segmentation using CellPose with optimized memory usage\"\"\"\n",
    "    io.logger_setup()\n",
    "    \n",
    "    # Extract the right channels for segmentation\n",
    "    cyto_channel_idx = config.get('cytoplasm_channel', 4) - 1 \n",
    "    nuc_channel_idx = config.get('nucleus_channel', 1) - 1\n",
    "    \n",
    "    # Choose model based on segmentation type\n",
    "    if config.get('segmentation_type') == 'nuclei_only':\n",
    "        model = models.Cellpose(gpu=config.get('use_gpu', True), model_type='nuclei')\n",
    "        cellpose_channels = [0, 0]  # Standard for nuclei model\n",
    "        \n",
    "        # For single-channel segmentation\n",
    "        img_to_segment = image[:,:,nuc_channel_idx].copy()\n",
    "        \n",
    "        # Apply background subtraction if needed\n",
    "        if bg_models is not None and nuc_channel_idx in bg_models:\n",
    "            ch_mean = bg_models[nuc_channel_idx]['mean']\n",
    "            img_to_segment = np.clip(img_to_segment - ch_mean, 0, None)\n",
    "            print(f\"Channel {nuc_channel_idx}: Subtracted mean background {ch_mean:.2f}\")\n",
    "            \n",
    "    else:\n",
    "        model = models.Cellpose(gpu=config.get('use_gpu', True), model_type=\"cyto3\")\n",
    "        cellpose_channels = [2, 1]  # Standard for cyto model: 1=nuclei, 2=cyto\n",
    "        \n",
    "        # Create channels array with proper mapping between original and stacked indices\n",
    "        channel_mapping = [cyto_channel_idx, nuc_channel_idx] \n",
    "        \n",
    "        # Create the segmentation image \n",
    "        img_to_segment = np.stack([image[:,:,nuc_channel_idx], image[:,:,cyto_channel_idx]], axis=-1).copy()\n",
    "        \n",
    "        # Apply background subtraction with correct index mapping\n",
    "        if bg_models is not None:\n",
    "            for i, orig_idx in enumerate(channel_mapping):\n",
    "                if orig_idx in bg_models:\n",
    "                    ch_mean = bg_models[orig_idx]['mean']\n",
    "                    img_to_segment[:,:,i] = np.clip(img_to_segment[:,:,i] - ch_mean, 0, None)\n",
    "                    print(f\"Channel {orig_idx} (stack position {i}): Subtracted mean background {ch_mean:.2f}\")\n",
    "    \n",
    "    print(f\"Running Cellpose with channels: {ch+1}\" for ch in cellpose_channels)\n",
    "    print(f\"Image shape for segmentation: {img_to_segment.shape}\")\n",
    "    \n",
    "    # Run segmentation with debug info\n",
    "    try:\n",
    "        masks, flows, styles, diams = model.eval(\n",
    "            img_to_segment, \n",
    "            channels=cellpose_channels,\n",
    "            diameter=config.get('cell_diameter', 20.0),\n",
    "            flow_threshold=config.get('flow_threshold', 0.4),\n",
    "            cellprob_threshold=config.get('cellprob_threshold', 0.0),\n",
    "            normalize=True,\n",
    "            progress=True\n",
    "        )\n",
    "        \n",
    "        # Free memory\n",
    "        del img_to_segment, model\n",
    "        if 'flows' in locals() and flows is not None:\n",
    "            del flows\n",
    "        if 'styles' in locals() and styles is not None:\n",
    "            del styles\n",
    "        if 'diams' in locals() and diams is not None:\n",
    "            del diams\n",
    "\n",
    "        gc.collect()\n",
    "        \n",
    "        print(f\"Segmentation complete! Found {len(np.unique(masks))-1} objects\")\n",
    "        return masks\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR in Cellpose: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        return np.zeros(image.shape[:2], dtype=np.int32)\n",
    "\n",
    "def segment_cells_with_downsampling(image, config, bg_models=None):\n",
    "    \"\"\"Segment cells with better memory management\"\"\"\n",
    "    # Get downsampling factor from config\n",
    "    downsample_factor = config.get('downsample_factor', 1.0)\n",
    "    \n",
    "    try:\n",
    "        if downsample_factor >= 1.0:\n",
    "            # Process at original resolution\n",
    "            masks = segment_cells_cellpose(image, config, bg_models)\n",
    "            return masks\n",
    "        \n",
    "        # Downsample image for processing\n",
    "        small_image = resample_image(image, downsample_factor)\n",
    "        \n",
    "        # Adjust cell diameter for downsampled image\n",
    "        small_config = config.copy()\n",
    "        small_config['cell_diameter'] = config.get('cell_diameter', 20.0) * downsample_factor\n",
    "        \n",
    "        # Run segmentation on smaller image\n",
    "        small_masks = segment_cells_cellpose(small_image, small_config, bg_models)\n",
    "        \n",
    "        # Free memory before upsampling\n",
    "        del small_image\n",
    "        gc.collect()\n",
    "        \n",
    "        # Upsample masks to original size\n",
    "        masks_upscaled = resize(small_masks, image.shape[0:2], order=0, preserve_range=True)\n",
    "        masks_upscaled = masks_upscaled.astype(np.int32)\n",
    "        \n",
    "        # Free memory\n",
    "        del small_masks\n",
    "        \n",
    "        return masks_upscaled\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in segmentation: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        # Return empty mask in case of error\n",
    "        return np.zeros(image.shape[:2], dtype=np.int32)\n",
    "\n",
    "def measure_cells(image, cell_masks, bg_models, config = None):\n",
    "    \"\"\"\n",
    "    Unified CTCF measurement function that uses GPU if available/configured\n",
    "    \n",
    "    Parameters:\n",
    "    - image: Multi-channel image array\n",
    "    - cell_masks: Integer mask with cell labels\n",
    "    - bg_models: Background models for each channel\n",
    "    - config: Configuration dictionary\n",
    "    \n",
    "    Returns:\n",
    "    - List of cell measurements\n",
    "    \"\"\"\n",
    "    # Check if GPU should be used\n",
    "    use_gpu = config.get('use_gpu', True)\n",
    "    if use_gpu and config.get('auto_detect_gpu', True):\n",
    "        use_gpu = check_gpu_availability()\n",
    "    \n",
    "    # Select appropriate implementation\n",
    "    if use_gpu:\n",
    "        try:\n",
    "            return measure_cells_ctcf_gpu(image, cell_masks, bg_models, config)\n",
    "        except Exception as e:\n",
    "            print(f\"GPU CTCF measurement failed: {str(e)}. Falling back to CPU.\")\n",
    "            return measure_cells_ctcf_cpu(image, cell_masks, bg_models, config)\n",
    "    else:\n",
    "        return measure_cells_ctcf_cpu(image, cell_masks, bg_models, config)\n",
    "    \n",
    "def measure_cells_ctcf_cpu(image, cell_masks, bg_models, config = None):\n",
    "    \"\"\"\n",
    "    Measure CTCF for all cells and channels with progress tracking and debugging\n",
    "    \n",
    "    Parameters:\n",
    "    - image: Multi-channel image array\n",
    "    - cell_masks: Integer mask with cell labels\n",
    "    - bg_models: Background models for each channel\n",
    "    \"\"\"\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Get unique cell labels\n",
    "    unique_labels = np.unique(cell_masks)\n",
    "    unique_labels = unique_labels[unique_labels > 0]  # Skip background (0)\n",
    "    total_cells = len(unique_labels)\n",
    "    \n",
    "    if total_cells == 0:\n",
    "        print(\"No cells found in mask.\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"Measuring CTCF for {total_cells} cells using parallel CPU processing...\")\n",
    "    \n",
    "    # Determine optimal batch size and number of workers\n",
    "    max_workers = config.get('max_workers', min(os.cpu_count(), 8))\n",
    "    batch_size = config.get('batch_size', max(10, total_cells // (max_workers * 2)))\n",
    "    \n",
    "    # Create batches of cell labels\n",
    "    label_batches = [unique_labels[i:i + batch_size] for i in range(0, len(unique_labels), batch_size)]\n",
    "    print(f\"Processing {len(label_batches)} batches with up to {max_workers} workers\")\n",
    "    \n",
    "    # Prepare partial function with fixed arguments\n",
    "    process_batch_func = partial(\n",
    "        process_cell_batch,\n",
    "        image=image,\n",
    "        cell_masks=cell_masks,\n",
    "        bg_models=bg_models\n",
    "    )\n",
    "    \n",
    "    # Process batches in parallel\n",
    "    results = []\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        batch_results = list(\n",
    "            tqdm(\n",
    "                executor.map(process_batch_func, label_batches), \n",
    "                total=len(label_batches),\n",
    "                desc=\"Processing batches\"\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Combine batch results\n",
    "        for batch_result in batch_results:\n",
    "            results.extend(batch_result)\n",
    "    \n",
    "    # Final timing\n",
    "    total_time = time.time() - start_time\n",
    "    cells_per_sec = total_cells / (total_time + 1e-6)\n",
    "    print(f\"Parallel CTCF measurement complete: {total_cells} cells in {total_time:.2f}s ({cells_per_sec:.2f} cells/sec)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def process_cell_batch(cell_labels, image, cell_masks, bg_models):\n",
    "    \"\"\"\n",
    "    Process a batch of cells for CTCF measurement (called by parallel worker).\n",
    "    \"\"\"\n",
    "    # Process-safe matplotlib configuration (avoid conflicts)\n",
    "    \n",
    "    batch_results = []\n",
    "    \n",
    "    for label in cell_labels:\n",
    "        # Create mask for this cell only\n",
    "        cell_mask = cell_masks == label\n",
    "        \n",
    "        # Get cell properties\n",
    "        y_indices, x_indices = np.where(cell_mask)\n",
    "        if len(y_indices) == 0:\n",
    "            continue\n",
    "            \n",
    "        area = len(y_indices)\n",
    "        y_centroid = np.mean(y_indices)\n",
    "        x_centroid = np.mean(x_indices)\n",
    "        \n",
    "        # Initialize cell data\n",
    "        cell_data = {\n",
    "            'label': int(label),  # Ensure label is int for serialization\n",
    "            'area': int(area),\n",
    "            'centroid': (float(y_centroid), float(x_centroid)),\n",
    "            'ctcf': {},\n",
    "            'mean': {},\n",
    "            'total': {},\n",
    "            'bg_value': {}\n",
    "        }\n",
    "        \n",
    "        # Process each channel\n",
    "        for ch in range(image.shape[-1]):\n",
    "            # Extract the channel data\n",
    "            channel = image[:,:,ch]\n",
    "            \n",
    "            # Use efficient boolean indexing\n",
    "            cell_pixels = channel[cell_mask]\n",
    "            \n",
    "            # Get background value\n",
    "            bg_value = bg_models[ch]['mean'] if ch in bg_models else 0\n",
    "            cell_data['bg_value'][ch] = float(bg_value)\n",
    "            \n",
    "            # Calculate measurements\n",
    "            total_intensity = np.sum(cell_pixels)\n",
    "            mean_intensity = np.mean(cell_pixels)\n",
    "            ctcf = total_intensity - (area * bg_value)\n",
    "            \n",
    "            # Store results (convert to Python types for serialization)\n",
    "            cell_data['total'][ch] = float(total_intensity)\n",
    "            cell_data['mean'][ch] = float(mean_intensity)\n",
    "            cell_data['ctcf'][ch] = float(ctcf)\n",
    "            \n",
    "        batch_results.append(cell_data)\n",
    "    \n",
    "    return batch_results\n",
    "\n",
    "def measure_cells_ctcf_gpu(image, cell_masks, bg_models, config = None, debug=False):\n",
    "    \"\"\"GPU-accelerated CTCF measurement for improved performance\"\"\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Convert arrays to PyTorch tensors on GPU with explicit data type conversion\n",
    "    device = torch.device('cuda')\n",
    "    try:    \n",
    "        # Convert to float32 since uint16 is not supported by all operations\n",
    "        image_tensor = torch.from_numpy(image).to(device).float()\n",
    "        mask_tensor = torch.from_numpy(cell_masks).to(device)\n",
    "        \n",
    "        # Get unique cell IDs for processing\n",
    "        cell_ids = torch.unique(mask_tensor)[1:]  # Skip 0 (background)\n",
    "        total_cells = len(cell_ids)\n",
    "        print(f\"Measuring CTCF for {total_cells} cells across {image.shape[-1]} channels on GPU...\")\n",
    "        \n",
    "        # Prepare results container\n",
    "        measurements = []\n",
    "        \n",
    "        # Process in batches if there are many cells\n",
    "        batch_size = config.get('gpu_batch_size', min(500, total_cells))\n",
    "\n",
    "        for batch_start in tqdm(range(0, total_cells, batch_size), desc=\"Processing cell batches\"):\n",
    "            batch_end = min(batch_start + batch_size, total_cells)\n",
    "            batch_ids = cell_ids[batch_start:batch_end]\n",
    "            \n",
    "            # Process each cell in the batch\n",
    "            for cell_idx in range(len(batch_ids)):\n",
    "                cell_id = batch_ids[cell_idx].item()\n",
    "                \n",
    "                # Create binary mask for this cell\n",
    "                with torch.no_grad():  # Reduce memory usage\n",
    "                    cell_mask = (mask_tensor == cell_id).bool()\n",
    "                    cell_area = torch.sum(cell_mask).item()\n",
    "                    \n",
    "                    if cell_area == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    # Calculate centroid\n",
    "                    y_indices, x_indices = torch.where(cell_mask)\n",
    "                    centroid_y = torch.mean(y_indices.float()).item()\n",
    "                    centroid_x = torch.mean(x_indices.float()).item()\n",
    "                \n",
    "                cell_data = {\n",
    "                    'label': int(cell_id),\n",
    "                    'area': int(cell_area),\n",
    "                    'centroid': (float(centroid_y), float(centroid_x)),\n",
    "                    'ctcf': {},\n",
    "                    'mean': {},\n",
    "                    'total': {},\n",
    "                    'bg_value': {}\n",
    "                }\n",
    "                \n",
    "                # Process all channels\n",
    "                for ch in range(image_tensor.shape[2]):\n",
    "                    with torch.no_grad():  # Reduce memory usage\n",
    "                        channel_data = image_tensor[:, :, ch]\n",
    "                        bg_value = bg_models[ch]['mean'] if ch in bg_models else 0\n",
    "                        cell_data['bg_value'][ch] = float(bg_value)\n",
    "                        \n",
    "                        # GPU-accelerated measurements\n",
    "                        cell_pixels = torch.masked_select(channel_data, cell_mask)\n",
    "                        total_intensity = torch.sum(cell_pixels).item()\n",
    "                        mean_intensity = torch.mean(cell_pixels).item() if cell_pixels.numel() > 0 else 0\n",
    "                        ctcf = total_intensity - (cell_area * bg_value)\n",
    "                        \n",
    "                        cell_data['total'][ch] = float(total_intensity)\n",
    "                        cell_data['mean'][ch] = float(mean_intensity)\n",
    "                        cell_data['ctcf'][ch] = float(ctcf)\n",
    "                \n",
    "                measurements.append(cell_data)\n",
    "            \n",
    "            # Free GPU memory after each batch\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        cells_per_sec = total_cells / total_time\n",
    "        print(f\"GPU CTCF measurement complete: {total_cells} cells in {total_time:.2f}s ({cells_per_sec:.2f} cells/sec)\")\n",
    "        \n",
    "        return measurements\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU memory error: {str(e)}. Falling back to chunked GPU processing.\")\n",
    "        traceback.print_exc()\n",
    "        measurements = {}  \n",
    "        return measurements # Return empty list in case of error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image_for_cellpose(image, config, bg_models):\n",
    "    \"\"\"Prepare image for CellPose segmentation with background subtraction\"\"\"\n",
    "    if config.get('segmentation_type') == 'nuclei_only':\n",
    "        nuc_channel_idx = config.get('nucleus_channel', 1) - 1\n",
    "        img_to_segment = image[:,:,nuc_channel_idx].copy()\n",
    "        \n",
    "        # Apply background subtraction if available\n",
    "        if nuc_channel_idx in bg_models:\n",
    "            ch_mean = bg_models[nuc_channel_idx]['mean']\n",
    "            img_to_segment = np.clip(img_to_segment - ch_mean, 0, None)\n",
    "            \n",
    "        return img_to_segment\n",
    "    else:\n",
    "        # Use cytoplasm and nucleus channels\n",
    "        cyto_channel_idx = config.get('cytoplasm_channel', 4) - 1\n",
    "        nuc_channel_idx = config.get('nucleus_channel', 1) - 1\n",
    "        \n",
    "        # Create a 2-channel image for CellPose\n",
    "        img_to_segment = np.stack([\n",
    "            image[:,:,nuc_channel_idx].copy(), \n",
    "            image[:,:,cyto_channel_idx].copy()\n",
    "        ], axis=-1)\n",
    "        \n",
    "        # Apply background subtraction if available\n",
    "        if nuc_channel_idx in bg_models:\n",
    "            ch_mean = bg_models[nuc_channel_idx]['mean']\n",
    "            img_to_segment[:,:,0] = np.clip(img_to_segment[:,:,0] - ch_mean, 0, None)\n",
    "            \n",
    "        if cyto_channel_idx in bg_models:\n",
    "            ch_mean = bg_models[cyto_channel_idx]['mean']\n",
    "            img_to_segment[:,:,1] = np.clip(img_to_segment[:,:,1] - ch_mean, 0, None)\n",
    "            \n",
    "        return img_to_segment\n",
    "    \n",
    "def process_experiment_folder(experiment_folder, config, results_dir=None):\n",
    "    \"\"\"\n",
    "    Process a single experiment folder containing TIF/TIFF files\n",
    "    \n",
    "    Parameters:\n",
    "    - experiment_folder: Path to folder containing TIF/TIFF files\n",
    "    - config: Configuration dictionary\n",
    "    - results_dir: Optional custom results directory (if None, one will be created)\n",
    "    \n",
    "    Returns:\n",
    "    - Path to results directory\n",
    "    \"\"\"\n",
    "    # Create results directory if not provided\n",
    "    if results_dir is None:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        exp_name = os.path.basename(experiment_folder)\n",
    "        results_dir = os.path.join(experiment_folder, f\"{exp_name}_Analysis_{timestamp}\")\n",
    "    \n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Get all images in experiment folder\n",
    "    image_files = [f for f in os.listdir(experiment_folder) \n",
    "                  if f.endswith(('.tif', '.tiff')) and not f.startswith('.')]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"No TIF/TIFF files found in {experiment_folder}\")\n",
    "        return results_dir\n",
    "        \n",
    "    print(f\"Found {len(image_files)} images to process in {experiment_folder}\")\n",
    "    \n",
    "    # Initialize CellPose model once\n",
    "    model_type = \"nuclei\" if config.get('segmentation_type') == 'nuclei_only' else \"cyto3\"\n",
    "    print(f\"Initializing CellPose model: {model_type}\")\n",
    "    cellpose_model = models.Cellpose(gpu=config.get('use_gpu', True), model_type=model_type)\n",
    "    \n",
    "    # Process in batches\n",
    "    batch_size = config.get('batch_size', 4)\n",
    "    all_results = []\n",
    "    \n",
    "    for batch_idx in range(0, len(image_files), batch_size):\n",
    "        batch_files = image_files[batch_idx:batch_idx + batch_size]\n",
    "        batch_paths = [os.path.join(experiment_folder, f) for f in batch_files]\n",
    "        \n",
    "        print(f\"Processing batch {batch_idx//batch_size + 1}/{(len(image_files) + batch_size - 1)//batch_size} \"\n",
    "             f\"({len(batch_files)} images)\")\n",
    "        \n",
    "        # 1. LOAD BATCH IMAGES\n",
    "        loaded_images = []\n",
    "        for path in tqdm(batch_paths, desc=\"Loading images\"):\n",
    "            try:\n",
    "                image = tiff.imread(path)\n",
    "                img_name = os.path.basename(path)\n",
    "                \n",
    "                # Move the shortest axis (channels) to the last index\n",
    "                shortest_axis = np.argmin(image.shape)\n",
    "                image = np.moveaxis(image, shortest_axis, -1)\n",
    "                \n",
    "                loaded_images.append({\n",
    "                    'path': path,\n",
    "                    'name': img_name,\n",
    "                    'image': image\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {os.path.basename(path)}: {str(e)}\")\n",
    "        \n",
    "        if not loaded_images:\n",
    "            continue\n",
    "        \n",
    "        # 2. PREPARE FOR BATCH PROCESSING\n",
    "        cellpose_inputs = []\n",
    "        bg_models_by_image = {}\n",
    "        \n",
    "        # Process background sequentially for each image\n",
    "        for img_data in loaded_images:\n",
    "            path = img_data['path']\n",
    "            image = img_data['image']\n",
    "            img_name = img_data['name']\n",
    "            img_base = os.path.splitext(img_name)[0]\n",
    "            \n",
    "            # Calculate background for each channel (SEQUENTIAL)\n",
    "            bg_models = {}\n",
    "            for ch_idx in tqdm(range(image.shape[-1]), desc=\"Background estimation\", leave=False):\n",
    "                channel_data = image[:,:,ch_idx].copy()\n",
    "                bg_models[ch_idx] = estimate_background_gmm(channel_data, config)\n",
    "                \n",
    "                # Generate background visualization if needed\n",
    "                if config.get('visualize_bg', True):\n",
    "                    visualize_background_mask(\n",
    "                        channel_data, \n",
    "                        bg_models[ch_idx],\n",
    "                        os.path.join(results_dir, f\"{img_base}_bg_mask_ch{ch_idx+1}.png\")\n",
    "                    )\n",
    "            \n",
    "            # Store background models\n",
    "            bg_models_by_image[path] = bg_models\n",
    "            \n",
    "            # Prepare image for CellPose\n",
    "            prepared_img = prepare_image_for_cellpose(image, config, bg_models)\n",
    "            \n",
    "            # Apply downsampling if needed\n",
    "            if config.get('downsample_factor', 1.0) < 1.0:\n",
    "                original_shape = prepared_img.shape[:2]\n",
    "                prepared_img = resample_image(\n",
    "                    prepared_img if len(prepared_img.shape) == 3 else prepared_img[:,:,np.newaxis],\n",
    "                    config.get('downsample_factor')\n",
    "                )\n",
    "                \n",
    "                cellpose_inputs.append({\n",
    "                    'image': prepared_img,\n",
    "                    'orig_path': path,\n",
    "                    'orig_shape': original_shape\n",
    "                })\n",
    "            else:\n",
    "                cellpose_inputs.append({\n",
    "                    'image': prepared_img,\n",
    "                    'orig_path': path,\n",
    "                    'orig_shape': image.shape[:2]\n",
    "                })\n",
    "        \n",
    "        # 3. BATCH SEGMENTATION WITH CELLPOSE\n",
    "        print(\"Running CellPose segmentation in batch mode...\")\n",
    "        cell_masks = {}\n",
    "        \n",
    "        # Process batch group with CellPose\n",
    "        # Stack images for batch processing\n",
    "        batch_images = [item['image'] for item in cellpose_inputs]\n",
    "        batch_paths = [item['orig_path'] for item in cellpose_inputs]\n",
    "        \n",
    "        # Configure CellPose parameters\n",
    "        if config.get('segmentation_type') == 'nuclei_only':\n",
    "            channels = [0, 0]  # Standard for nuclei model\n",
    "        else:\n",
    "            channels = [2, 1]  # Standard for cyto model (nuclei, cytoplasm)\n",
    "        \n",
    "        # Scale cell diameter based on downsampling\n",
    "        if config.get('downsample_factor', 1.0) < 1.0:\n",
    "            cell_diameter = config.get('cell_diameter', 20.0) * config.get('downsample_factor')\n",
    "        else:\n",
    "            cell_diameter = config.get('cell_diameter', 20.0)\n",
    "        \n",
    "        try:\n",
    "            # Run batch segmentation\n",
    "            masks, _, _, _ = cellpose_model.eval(\n",
    "                batch_images,\n",
    "                channels=channels,\n",
    "                diameter=cell_diameter,\n",
    "                flow_threshold=config.get('flow_threshold', 0.4),\n",
    "                cellprob_threshold=config.get('cellprob_threshold', 0.0),\n",
    "                normalize=True\n",
    "            )\n",
    "            \n",
    "            # Handle upscaling if needed\n",
    "            for i, path in enumerate(batch_paths):\n",
    "                # Get original shape for this image\n",
    "                for input_data in cellpose_inputs:\n",
    "                    if input_data['orig_path'] == path:\n",
    "                        orig_shape = input_data['orig_shape']\n",
    "                        \n",
    "                        # Upscale mask if downsampled\n",
    "                        if config.get('downsample_factor', 1.0) < 1.0:\n",
    "                            cell_masks[path] = resize(masks[i], orig_shape, \n",
    "                                                    order=0, preserve_range=True).astype(np.int32)\n",
    "                        else:\n",
    "                            cell_masks[path] = masks[i]\n",
    "                        break\n",
    "            \n",
    "            # Clean up memory\n",
    "            del masks\n",
    "            gc.collect()\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Batch segmentation error: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "            \n",
    "            # Create empty masks for failures\n",
    "            for input_data in cellpose_inputs:\n",
    "                path = input_data['orig_path']\n",
    "                orig_shape = input_data['orig_shape']\n",
    "                cell_masks[path] = np.zeros(orig_shape, dtype=np.int32)\n",
    "\n",
    "        print(\"Batch segmentation complete!\")\n",
    "    \n",
    "        # 4. PARALLEL CTCF MEASUREMENT AND RESULT GENERATION\n",
    "        batch_results = []\n",
    "        \n",
    "        # Process each image (CTCF calculation can be parallel)\n",
    "        for img_data in loaded_images:\n",
    "            path = img_data['path']\n",
    "            img_name = img_data['name']\n",
    "            img_base = os.path.splitext(img_name)[0]\n",
    "            \n",
    "            if path in cell_masks:\n",
    "                # Get mask and background models\n",
    "                masks = cell_masks[path]\n",
    "                bg_models = bg_models_by_image.get(path, {})\n",
    "                \n",
    "                try:\n",
    "                    # Measure cells with GPU or CPU\n",
    "                    cell_measurements = measure_cells(\n",
    "                        img_data['image'], masks, bg_models, config\n",
    "                    )\n",
    "                    \n",
    "                    # Save cell measurements to CSV\n",
    "                    cell_df = pd.DataFrame([\n",
    "                        {\n",
    "                            'image': img_name,\n",
    "                            'cell_id': cell['label'],\n",
    "                            'area': cell['area'],\n",
    "                            **{f'channel_{ch+1}_ctcf': cell['ctcf'][ch] for ch in range(img_data['image'].shape[-1])},\n",
    "                            **{f'channel_{ch+1}_mean': cell['mean'][ch] for ch in range(img_data['image'].shape[-1])},\n",
    "                            'centroid_x': cell['centroid'][1],\n",
    "                            'centroid_y': cell['centroid'][0]\n",
    "                        }\n",
    "                        for cell in cell_measurements\n",
    "                    ])\n",
    "                    cell_df.to_csv(os.path.join(results_dir, f\"{img_base}_cells.csv\"), index=False)\n",
    "                    \n",
    "                    # Create visualization if configured\n",
    "                    if config.get('visualize_segmentation', True):\n",
    "                        create_visualization(\n",
    "                            img_data['image'],\n",
    "                            masks,\n",
    "                            cell_measurements,\n",
    "                            os.path.join(results_dir, f\"{img_name}_analysis.png\"),\n",
    "                            debug=config.get('debug', False)\n",
    "                        )\n",
    "                    \n",
    "                    # Create QC region images if configured\n",
    "                    if config.get('save_qc_regions', True):\n",
    "                        save_segmentation_qc_images(\n",
    "                            img_data['image'],\n",
    "                            masks,\n",
    "                            results_dir,\n",
    "                            img_name,\n",
    "                            config\n",
    "                        )\n",
    "                    \n",
    "                    # Summarize results\n",
    "                    channels_of_interest = config.get('channels_of_interest', \n",
    "                                                   list(range(img_data['image'].shape[-1])))\n",
    "                    summary = {\n",
    "                        'image_name': img_name,\n",
    "                        'image_path': path,\n",
    "                        'total_cells': len(cell_measurements)\n",
    "                    }\n",
    "                    \n",
    "                    # Add channel statistics\n",
    "                    for ch in channels_of_interest:\n",
    "                        if ch < img_data['image'].shape[-1]:\n",
    "                            ch_ctcf = [cell['ctcf'][ch] for cell in cell_measurements]\n",
    "                            if ch_ctcf:\n",
    "                                summary[f'channel_{ch+1}_mean_ctcf'] = np.mean(ch_ctcf)\n",
    "                                summary[f'channel_{ch+1}_median_ctcf'] = np.median(ch_ctcf)\n",
    "                                summary[f'channel_{ch+1}_std_ctcf'] = np.std(ch_ctcf)\n",
    "                            else:\n",
    "                                summary[f'channel_{ch+1}_mean_ctcf'] = 0\n",
    "                                summary[f'channel_{ch+1}_median_ctcf'] = 0\n",
    "                                summary[f'channel_{ch+1}_std_ctcf'] = 0\n",
    "                    \n",
    "                    batch_results.append(summary)\n",
    "                    \n",
    "                    # Clean up memory\n",
    "                    del cell_measurements, cell_df\n",
    "                    gc.collect()\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {img_name}: {str(e)}\")\n",
    "                    batch_results.append({\n",
    "                        'image_name': img_name,\n",
    "                        'error': str(e),\n",
    "                        'total_cells': 0\n",
    "                    })\n",
    "            else:\n",
    "                batch_results.append({\n",
    "                    'image_name': img_name,\n",
    "                    'error': \"No mask generated\",\n",
    "                    'total_cells': 0\n",
    "                })\n",
    "        \n",
    "        # Append batch results to all results\n",
    "        all_results.extend(batch_results)\n",
    "        \n",
    "        # Clean up batch memory\n",
    "        del loaded_images, cellpose_inputs, cell_masks, bg_models_by_image, batch_results\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache() if config.get('use_gpu', True) else None\n",
    "    \n",
    "    # Save experiment results\n",
    "    if all_results:\n",
    "        exp_df = pd.DataFrame(all_results)\n",
    "        exp_df.to_csv(os.path.join(results_dir, \"experiment_results.csv\"), index=False)\n",
    "    \n",
    "    print(f\"Experiment processing complete. Results saved to: {results_dir}\")\n",
    "    return results_dir\n",
    "\n",
    "def process_experiments_optimized(main_directory, config):\n",
    "    \"\"\"\n",
    "    Process experiments in a main directory or a single experiment folder\n",
    "    \n",
    "    Parameters:\n",
    "    - main_directory: Path to main directory with multiple experiment folders\n",
    "                     OR path to a single experiment folder with TIF/TIFF files\n",
    "    - config: Configuration dictionary\n",
    "    \n",
    "    Returns:\n",
    "    - Path to results directory\n",
    "    \"\"\"\n",
    "    # Check if the main_directory contains TIF/TIFF files directly\n",
    "    tif_files = [f for f in os.listdir(main_directory) \n",
    "                if f.endswith(('.tif', '.tiff')) and not f.startswith('.')]\n",
    "    \n",
    "    if tif_files:\n",
    "        # This is a single experiment folder - process it directly\n",
    "        print(f\"Processing single experiment folder: {main_directory}\")\n",
    "        return process_experiment_folder(main_directory, config)\n",
    "    \n",
    "    # Create results directory for multiple experiments\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_dir = os.path.join(main_directory, f\"CTCF_Analysis_{timestamp}\")\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Find all experiment folders\n",
    "    experiment_folders = [f.path for f in os.scandir(main_directory) if f.is_dir() \n",
    "                         and not f.name.startswith('.') and not \"CTCF_Analysis\" in f.name]\n",
    "    \n",
    "    # Process each experiment folder\n",
    "    for experiment_folder in experiment_folders:\n",
    "        exp_name = os.path.basename(experiment_folder)\n",
    "        print(f\"\\nProcessing experiment: {exp_name}\")\n",
    "        \n",
    "        # Create experiment results folder\n",
    "        exp_results_dir = os.path.join(results_dir, exp_name)\n",
    "        \n",
    "        # Process this experiment folder\n",
    "        process_experiment_folder(experiment_folder, config, results_dir=exp_results_dir)\n",
    "        \n",
    "    print(f\"All experiments processed. Results saved to: {results_dir}\")\n",
    "    return results_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop Section testing \n",
    "In this section the functions for testing on a small cropped picture of the image are dealigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_central_region(image, crop_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Crop the central region of an image for quick segmentation testing\n",
    "    \n",
    "    Parameters:\n",
    "    - image: The input image (H, W, C)\n",
    "    - crop_ratio: Size of the crop relative to original image (0.1 = 10%)\n",
    "    \n",
    "    Returns:\n",
    "    - cropped_image: The central cropped region\n",
    "    - crop_coords: (y_start, y_end, x_start, x_end) for reference\n",
    "    \"\"\"\n",
    "    # Get image dimensions\n",
    "    h, w, c = image.shape\n",
    "    \n",
    "    # Calculate crop size\n",
    "    crop_h = int(h * crop_ratio)\n",
    "    crop_w = int(w * crop_ratio)\n",
    "    \n",
    "    # Calculate central coordinates\n",
    "    center_y, center_x = h // 2, w // 2\n",
    "    \n",
    "    # Calculate crop boundaries\n",
    "    y_start = center_y - (crop_h // 2)\n",
    "    y_end = center_y + (crop_h // 2)\n",
    "    x_start = center_x - (crop_w // 2)\n",
    "    x_end = center_x + (crop_w // 2)\n",
    "    \n",
    "    # Ensure coordinates are within image bounds\n",
    "    y_start = max(0, y_start)\n",
    "    y_end = min(h, y_end)\n",
    "    x_start = max(0, x_start)\n",
    "    x_end = min(w, x_end)\n",
    "    \n",
    "    # Extract crop\n",
    "    cropped_image = image[y_start:y_end, x_start:x_end, :]\n",
    "    \n",
    "    return cropped_image, (y_start, y_end, x_start, x_end)    \n",
    "\n",
    "def test_segmentation_on_crop(image_path, output_dir, config, crop_ratio=0.1):\n",
    "        \"\"\"\n",
    "        Test segmentation on a central crop of an image\n",
    "        \n",
    "        Parameters:\n",
    "        - image_path: Path to the input image\n",
    "        - output_dir: Directory to save results\n",
    "        - config: Configuration dictionary\n",
    "        - crop_ratio: Size of the crop relative to original image (0.1 = 10%)\n",
    "        \n",
    "        Returns:\n",
    "        - Dictionary with segmentation results and parameters\n",
    "        \"\"\"\n",
    "        # Load image and normalize channels\n",
    "        image = tiff.imread(image_path)\n",
    "        img_name = os.path.basename(image_path)\n",
    "        img_base = os.path.splitext(img_name)[0]\n",
    "        \n",
    "        print(f\"\\nTesting segmentation on cropped region of: {img_name}\")\n",
    "        \n",
    "        # Move the shortest axis (channels) to the last index if needed\n",
    "        shortest_axis = np.argmin(image.shape)\n",
    "        image = np.moveaxis(image, shortest_axis, -1)\n",
    "        \n",
    "        # Crop central region\n",
    "        cropped_image, crop_coords = crop_central_region(image, crop_ratio)\n",
    "        y_start, y_end, x_start, x_end = crop_coords\n",
    "        \n",
    "        print(f\"Original image shape: {image.shape}\")\n",
    "        print(f\"Cropped region shape: {cropped_image.shape}\")\n",
    "        print(f\"Crop coordinates: (y={y_start}:{y_end}, x={x_start}:{x_end})\")\n",
    "        \n",
    "        # Create output directory for this test if it doesn't exist\n",
    "        crop_output_dir = os.path.join(output_dir, f\"{img_base}_crop_test\")\n",
    "        os.makedirs(crop_output_dir, exist_ok=True)\n",
    "        \n",
    "        # 1. Estimate background for the cropped region\n",
    "        print(\"Estimating background using GMM...\")\n",
    "        bg_models = {}\n",
    "        for ch in range(cropped_image.shape[-1]):\n",
    "            channel_data = cropped_image[:,:,ch].copy()\n",
    "            bg_models[ch] = estimate_background_gmm(channel_data)\n",
    "            \n",
    "            # Save background mask visualization\n",
    "            visualize_background_mask(channel_data, bg_models[ch], \n",
    "                                     os.path.join(crop_output_dir, f\"crop_bg_mask_ch{ch+1}.png\"))\n",
    "        \n",
    "        # 2. Segment cells on the cropped region\n",
    "        cell_masks = segment_cells_with_downsampling(cropped_image, config, bg_models)\n",
    "        \n",
    "        # 3. Measure CTCF for each cell in the cropped region\n",
    "        cell_measurements = measure_cells(cropped_image, cell_masks, bg_models)\n",
    "        \n",
    "        # Save visualization of the segmentation results\n",
    "        create_visualization(cropped_image, cell_masks, cell_measurements, \n",
    "                            os.path.join(crop_output_dir, f\"{img_base}_crop_segmentation.png\"), \n",
    "                            debug=True)\n",
    "        \n",
    "        # Create a comparison visualization showing where the crop is from\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Show original with crop region highlighted\n",
    "        plt.subplot(1, 2, 1)\n",
    "        # Use first channel for display or create a composite\n",
    "        if image.shape[-1] >= 3:\n",
    "            display_img = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "            for i in range(min(3, image.shape[-1])):\n",
    "                ch_data = exposure.equalize_adapthist(image[:,:,i])\n",
    "                display_img[:,:,i] = ch_data\n",
    "        else:\n",
    "            display_img = exposure.equalize_adapthist(image[:,:,0])\n",
    "        \n",
    "        plt.imshow(display_img)\n",
    "        plt.gca().add_patch(plt.Rectangle((x_start, y_start), \n",
    "                                         x_end - x_start, \n",
    "                                         y_end - y_start, \n",
    "                                         fill=False, \n",
    "                                         edgecolor='red', \n",
    "                                         linewidth=2))\n",
    "        plt.title('Original Image with Crop Region')\n",
    "        \n",
    "        # Show the cropped region with segmentation overlay\n",
    "        plt.subplot(1, 2, 2)\n",
    "        # Create overlay of segmentation on image\n",
    "        if cropped_image.shape[-1] >= 3:\n",
    "            crop_display = np.zeros((cropped_image.shape[0], cropped_image.shape[1], 3))\n",
    "            for i in range(min(3, cropped_image.shape[-1])):\n",
    "                ch_data = exposure.equalize_adapthist(cropped_image[:,:,i])\n",
    "                crop_display[:,:,i] = ch_data\n",
    "        else:\n",
    "            crop_display = exposure.equalize_adapthist(cropped_image[:,:,0])\n",
    "        \n",
    "        plt.imshow(crop_display)\n",
    "        # Add cell mask overlay\n",
    "        plt.imshow(cell_masks > 0, alpha=0.7, cmap='cool')\n",
    "        plt.title(f'Segmentation on Cropped Region ({len(cell_measurements)} cells)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(crop_output_dir, f\"{img_base}_crop_location.png\"), dpi=150)\n",
    "        plt.close()\n",
    "        \n",
    "        # Save cell measurements to CSV\n",
    "        cell_df = pd.DataFrame([\n",
    "            {\n",
    "                'cell_id': cell['label'],\n",
    "                'area': cell['area'],\n",
    "                **{f'channel_{ch+1}_ctcf': cell['ctcf'][ch] for ch in range(cropped_image.shape[-1])},\n",
    "                **{f'channel_{ch+1}_mean': cell['mean'][ch] for ch in range(cropped_image.shape[-1])},\n",
    "                'centroid_x': cell['centroid'][1],\n",
    "                'centroid_y': cell['centroid'][0]\n",
    "            }\n",
    "            for cell in cell_measurements\n",
    "        ])\n",
    "        cell_df.to_csv(os.path.join(crop_output_dir, f\"{img_base}_crop_cells.csv\"), index=False)\n",
    "        \n",
    "        # Return info about the test\n",
    "        return {\n",
    "            'image_name': img_name,\n",
    "            'crop_region': crop_coords,\n",
    "            'cell_count': len(cell_measurements),\n",
    "            'output_dir': crop_output_dir\n",
    "        }\n",
    "\n",
    "# Test segmentation on a cropped region before full processing\n",
    "def test_segmentation_parameters(image_path, config, crop_ratio=0.1):\n",
    "    \"\"\"Test segmentation parameters on a cropped region of an image\"\"\"\n",
    "    # Create a temporary output directory\n",
    "    output_dir = os.path.join(os.path.dirname(image_path), \"segmentation_tests\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Run the crop test\n",
    "    test_result = test_segmentation_on_crop(\n",
    "        image_path=image_path,\n",
    "        output_dir=output_dir,\n",
    "        config=config,\n",
    "        crop_ratio=crop_ratio\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n✓ Segmentation test complete!\")\n",
    "    print(f\"  - Found {test_result['cell_count']} cells in the cropped region\")\n",
    "    print(f\"  - Results saved to: {test_result['output_dir']}\")\n",
    "    print(\"\\nTIP: Review the results and adjust segmentation parameters in config as needed\")\n",
    "    \n",
    "    return test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Images\n",
    "In this section firstly the configuratin will be set for the segmentation, and a test can be done for an individual file. On the second part, a batch processing of multiple files can be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the configuration for the pipeline\n",
    "config = {\n",
    "    # Hardware settings\n",
    "    'use_gpu': True,  # Set to False to force CPU processing\n",
    "    'auto_detect_gpu': True,  # Auto-detect and use GPU if available\n",
    "    \n",
    "    # CellPose settings\n",
    "    'segmentation_type': 'cyto_and_nuclei',  # or 'nuclei_only'\n",
    "    'cytoplasm_channel': 4,  # Far Red channel for cytoplasm/membrane\n",
    "    'nucleus_channel': 1,    # Blue channel (DAPI) for nuclei\n",
    "    'cell_diameter': 25.0,     # Approximate diameter in pixels\n",
    "    'flow_threshold': 0.4,   # Flow threshold for CellPose\n",
    "    'cellprob_threshold': 0.6,  # Cell probability threshold for CellPose\n",
    "    'downsample_factor': 0.5,  # Downsample factor for speed (1.0 = no downsampling)\n",
    "    \n",
    "    # Visualization settings\n",
    "    'visualize_bg': True,  # Set to False if you don't want intermediate visualizations\n",
    "    'visualize_segmentation': False,  # Show segmentation results\n",
    "    'save_qc_regions': True,  # Save QC regions for review\n",
    "    'qc_region_size': 500,  # Size of the QC region in pixels\n",
    "    \n",
    "    # Other pipeline settings\n",
    "    'channels_of_interest': [0, 1, 2, 3]  # All channels to measure\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropped segmentation and background substraction testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_test = select_folder()\n",
    "print(f'>>> Selected folder: {folder_path_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage in your script\n",
    "image_paths = glob.glob(os.path.join(folder_path_test, \"*.tiff\"))\n",
    "if len(image_paths) > 0:\n",
    "    # Test segmentation on first image before batch processing\n",
    "    test_result = test_segmentation_parameters(image_paths[0], config, crop_ratio=0.1)\n",
    "    \n",
    "else:\n",
    "    print(f\"No TIFF images found in {folder_path_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_folder = select_folder()\n",
    "print(f'>>> Selected folder: {batch_folder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all experiments in the selected folder\n",
    "batch_results = process_experiments_batch(batch_folder, config)\n",
    "print(f'>>> Batch processing complete. Results saved to: {batch_results}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.update({\n",
    "    # Parallelization settings\n",
    "    'max_workers': min(os.cpu_count(), 8),  # Maximum number of parallel workers\n",
    "    'batch_size': 4,                         # Number of images to process in a batch\n",
    "    \n",
    "    # Memory settings\n",
    "    'memory_limit_gb': None,                 # Set a memory limit in GB (None = auto)\n",
    "    'auto_batch_sizing': True,               # Automatically adjust batch size based on available memory\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Selected folder: H:/01_Colaboration/02_Slide_Scanner/20250605_TestFolder/Exp2\n"
     ]
    }
   ],
   "source": [
    "exp_folder = select_folder()\n",
    "print(f'>>> Selected folder: {exp_folder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 images to process in H:/01_Colaboration/02_Slide_Scanner/20250605_TestFolder/Exp2\n",
      "Initializing CellPose model: cyto3\n",
      "Processing batch 1/1 (2 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images:   0%|          | 0/2 [00:00<?, ?it/s]<tifffile.TiffTag 270 @296827004> coercing invalid ASCII to bytes, due to UnicodeDecodeError('charmap', b'<?xml version=\"1.0\" encoding=\"utf-8\"?>\\r\\n<OME xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-insta\n",
      "Loading images: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]\n",
      "Background estimation:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# process single experiment folder\n",
    "results_dir = process_experiment_folder(exp_folder, config)\n",
    "print(f'>>> Experiment processing complete. Results saved to: {results_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all experiments in the selected folder with parallel execution\n",
    "batch_results = process_experiments_optimized(batch_folder, config)\n",
    "print(f'>>> Batch processing complete. Results saved to: {batch_results}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".auto_img",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
