{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Pipeline for Consistent CTCF in Fluorescence Microscopy\n",
    "\n",
    "Here's a comprehensive pipeline for analyzing fluorescence microscopy images with consistent CTCF measurement across different conditions and microscopes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import necessary libraries\n",
    "import time, os, sys\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "import tifffile as tiff\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.ndimage as ndi\n",
    "from scipy import sparse\n",
    "from skimage import measure, draw, exposure\n",
    "from skimage.transform import resize\n",
    "from skimage.segmentation import find_boundaries, watershed\n",
    "from skimage.filters import threshold_otsu, gaussian\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import remove_small_objects, binary_closing, disk\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "import scipy.stats\n",
    "\n",
    "from tqdm import tqdm\n",
    "import traceback\n",
    "import concurrent.futures\n",
    "from functools import partial\n",
    "from filelock import FileLock\n",
    "import torch\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 200\n",
    "mpl.use('Agg')  # Set non-interactive backend globally\n",
    "\n",
    "from AutoImgUtils import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version\n",
    "!nvidia-smi\n",
    "\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import core, utils, io, models, metrics, denoise\n",
    "from glob import glob\n",
    "\n",
    "use_GPU = core.use_gpu()\n",
    "yn = ['NO', 'YES']\n",
    "print(f'>>> GPU activated? {yn[use_GPU]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization functions\n",
    "Here the visualization functions are defined, that can be used to save plots regarding the background substraction as well as the segmentation results for quality control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_background_mask(channel_image, bg_model, output_path, n_components=3, enhance_contrast=True):\n",
    "    \"\"\"Visualize background mask from GMM model with distribution plots\"\"\"\n",
    "\n",
    "    # Detect if we're working with 3D data\n",
    "    is_3d = len(channel_image.shape) == 3 and channel_image.shape[0] > 1\n",
    "\n",
    "    if is_3d:\n",
    "        # 3D visualization setup (3x3 grid)\n",
    "        fig, axes = plt.subplots(3, 3, figsize=(18, 15), gridspec_kw={'height_ratios': [3, 3, 1]})\n",
    "        \n",
    "        # Get dimensions\n",
    "        z_depth, height, width = channel_image.shape\n",
    "        \n",
    "        # Show representative Z-slices\n",
    "        z_positions = [z_depth // 4, z_depth // 2, 3 * z_depth // 4]\n",
    "        slice_titles = [\"25% Z-Depth\", \"50% Z-Depth\", \"75% Z-Depth\"]\n",
    "        \n",
    "        # Row 1: Z-slices with background highlighted\n",
    "        for i, (z_pos, title) in enumerate(zip(z_positions, slice_titles)):\n",
    "            slice_img = channel_image[z_pos]\n",
    "            slice_mask = bg_model['mask'][z_pos] if len(bg_model['mask'].shape) == 3 else None\n",
    "\n",
    "            \n",
    "            # Enhance contrast for visualization if requested\n",
    "            if enhance_contrast:\n",
    "                p_low, p_high = 2, 98  # Percentiles for contrast stretching\n",
    "                display_img = exposure.rescale_intensity(\n",
    "                    slice_img,\n",
    "                    in_range=tuple(np.percentile(slice_img, (p_low, p_high))),\n",
    "                    out_range='dtype'\n",
    "                )\n",
    "            else:\n",
    "                display_img = slice_img\n",
    "            \n",
    "            # Display image slice\n",
    "            axes[0, i].imshow(display_img, cmap='gray')\n",
    "            axes[0, i].set_title(f'Original - {title}')\n",
    "            \n",
    "            # If we have a 3D mask, overlay it on the slice\n",
    "            if slice_mask is not None:\n",
    "                # Create RGB image for overlay\n",
    "                norm_img = (display_img - np.min(display_img)) / (np.max(display_img) - np.min(display_img))\n",
    "                rgb_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
    "                \n",
    "                # Highlight background in red\n",
    "                rgb_img[:,:,0][slice_mask] = 1.0  # Red\n",
    "                rgb_img[:,:,1][slice_mask] = 0.0  # Green\n",
    "                rgb_img[:,:,2][slice_mask] = 0.0  # Blue\n",
    "                \n",
    "                axes[0, i].imshow(rgb_img)\n",
    "            \n",
    "            axes[0, i].axis('off')\n",
    "        \n",
    "        # Row 2: Maximum Intensity Projections with background mask overlay\n",
    "        # XY projection (top view)\n",
    "        mip_xy = np.max(channel_image, axis=0)\n",
    "        mip_bg_xy = np.max(bg_model['mask'], axis=0) if len(bg_model['mask'].shape) == 3 else bg_model['mask']\n",
    "        \n",
    "        if enhance_contrast:\n",
    "            mip_xy = exposure.equalize_adapthist(mip_xy)\n",
    "        \n",
    "        axes[1, 0].imshow(mip_xy, cmap='gray')\n",
    "        axes[1, 0].set_title('XY Maximum Projection')\n",
    "        axes[1, 0].axis('off')\n",
    "        \n",
    "        # Create a red overlay for the background on XY projection\n",
    "        norm_img = np.zeros_like(mip_xy)\n",
    "        if mip_xy.max() > 0:\n",
    "            norm_img = (mip_xy - np.min(mip_xy)) / (np.max(mip_xy) - np.min(mip_xy))\n",
    "        rgb_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
    "        rgb_img[:,:,0][mip_bg_xy > 0.5] = 1.0  # Red\n",
    "        rgb_img[:,:,1][mip_bg_xy > 0.5] = 0.0  # Green\n",
    "        rgb_img[:,:,2][mip_bg_xy > 0.5] = 0.0  # Blue\n",
    "        axes[1, 0].imshow(rgb_img)\n",
    "        \n",
    "        # YZ projection (side view)\n",
    "        mip_yz = np.max(channel_image, axis=2)\n",
    "        mip_bg_yz = np.max(bg_model['mask'], axis=2) if len(bg_model['mask'].shape) == 3 else np.zeros_like(mip_yz)\n",
    "        \n",
    "        if enhance_contrast:\n",
    "            mip_yz = exposure.equalize_adapthist(mip_yz)\n",
    "        \n",
    "        axes[1, 1].imshow(mip_yz, cmap='gray')\n",
    "        axes[1, 1].set_title('YZ Maximum Projection')\n",
    "        axes[1, 1].axis('off')\n",
    "        \n",
    "        # Overlay for YZ\n",
    "        norm_img = np.zeros_like(mip_yz)\n",
    "        if mip_yz.max() > 0:\n",
    "            norm_img = (mip_yz - np.min(mip_yz)) / (np.max(mip_yz) - np.min(mip_yz))\n",
    "        rgb_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
    "        rgb_img[:,:,0][mip_bg_yz > 0.5] = 1.0\n",
    "        rgb_img[:,:,1][mip_bg_yz > 0.5] = 0.0\n",
    "        rgb_img[:,:,2][mip_bg_yz > 0.5] = 0.0\n",
    "        axes[1, 1].imshow(rgb_img)\n",
    "        \n",
    "        # XZ projection (front view)\n",
    "        mip_xz = np.max(channel_image, axis=1)\n",
    "        mip_bg_xz = np.max(bg_model['mask'], axis=1) if len(bg_model['mask'].shape) == 3 else np.zeros_like(mip_xz)\n",
    "        \n",
    "        if enhance_contrast:\n",
    "            mip_xz = exposure.equalize_adapthist(mip_xz)\n",
    "        \n",
    "        axes[1, 2].imshow(mip_xz, cmap='gray')\n",
    "        axes[1, 2].set_title('XZ Maximum Projection')\n",
    "        axes[1, 2].axis('off')\n",
    "        \n",
    "        # Overlay for XZ\n",
    "        norm_img = np.zeros_like(mip_xz)\n",
    "        if mip_xz.max() > 0:\n",
    "            norm_img = (mip_xz - np.min(mip_xz)) / (np.max(mip_xz) - np.min(mip_xz))\n",
    "        rgb_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
    "        rgb_img[:,:,0][mip_bg_xz > 0.5] = 1.0\n",
    "        rgb_img[:,:,1][mip_bg_xz > 0.5] = 0.0\n",
    "        rgb_img[:,:,2][mip_bg_xz > 0.5] = 0.0\n",
    "        axes[1, 2].imshow(rgb_img)\n",
    "        \n",
    "    else:\n",
    "        # Create figure with 4 subplots (2x2 grid)\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12), gridspec_kw={'height_ratios': [3, 1]})\n",
    "        \n",
    "        # Enhance contrast for visualization if requested\n",
    "        if enhance_contrast:\n",
    "            # Use percentile-based contrast stretching (robust to outliers)\n",
    "            p_low, p_high = 2, 98  # Percentiles for contrast stretching\n",
    "            display_img = exposure.rescale_intensity(\n",
    "                channel_image, \n",
    "                in_range=tuple(np.percentile(channel_image, (p_low, p_high))),\n",
    "                out_range='dtype'\n",
    "            )\n",
    "        else:\n",
    "            display_img = channel_image\n",
    "        \n",
    "        # Original image with enhanced contrast\n",
    "        axes[0, 0].imshow(display_img, cmap='gray')\n",
    "        axes[0, 0].set_title('Original Channel' + (' (Contrast Enhanced)' if enhance_contrast else ''))\n",
    "        \n",
    "        # Background mask\n",
    "        axes[0, 1].imshow(bg_model['mask'], cmap='hot')\n",
    "        axes[0, 1].set_title(f'Background Mask\\nMean: {bg_model[\"mean\"]:.2f}, Std: {bg_model[\"std\"]:.2f}')\n",
    "        \n",
    "        # Original with background highlighted\n",
    "        norm_img = (channel_image - np.min(channel_image)) / (np.max(channel_image) - np.min(channel_image))\n",
    "        rgb_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
    "        \n",
    "        # Highlight background in red\n",
    "        rgb_img[:,:,0][bg_model['mask']] = 1.0  # Set red high for background\n",
    "        rgb_img[:,:,1][bg_model['mask']] = 0.0  # Set green low for background\n",
    "        rgb_img[:,:,2][bg_model['mask']] = 0.0  # Set blue low for background\n",
    "        \n",
    "        axes[1, 0].imshow(rgb_img)\n",
    "        axes[1, 0].set_title('Background Regions (Red)')\n",
    "    \n",
    "    # Plot intensity histogram with GMM distributions\n",
    "    if 'component_weights' in bg_model and 'component_means' in bg_model and 'component_covs' in bg_model:\n",
    "        \n",
    "        # Create histogram - use the appropriate axes depending on 2D/3D\n",
    "        hist_ax = axes[2, 1] if is_3d else axes[1, 1]\n",
    "\n",
    "        flat_img = channel_image.flatten()\n",
    "        \n",
    "        # Plot histogram\n",
    "        hist_range = (np.min(flat_img), np.max(flat_img))\n",
    "        n_bins = 100\n",
    "        hist_ax.hist(flat_img, bins=n_bins, range=hist_range, density=True, \n",
    "                    alpha=0.6, color='gray', label='Pixel Intensity')\n",
    "        \n",
    "        # Create x values for plotting GMM curves\n",
    "        x = np.linspace(hist_range[0], hist_range[1], 1000)\n",
    "        \n",
    "        # Plot the individual components\n",
    "        colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "        bg_component = bg_model['bg_component']\n",
    "        \n",
    "        # Check if this is a composite background model\n",
    "        is_composite = bg_model.get('method') == 'composite_enhanced'\n",
    "        \n",
    "        for i in range(len(bg_model['component_means'])):\n",
    "            # Calculate component density\n",
    "            weight = bg_model['component_weights'][i]\n",
    "            mean = bg_model['component_means'][i]\n",
    "            std = np.sqrt(bg_model['component_covs'][i])\n",
    "            \n",
    "            # Create a normal distribution for this component\n",
    "            y = weight * scipy.stats.norm.pdf(x, mean, std)\n",
    "            \n",
    "            # Plot with higher alpha for background component\n",
    "            alpha = 0.8 if i == bg_component else 0.5\n",
    "            \n",
    "            # Adjust labeling based on whether this is composite or individual\n",
    "            if is_composite:\n",
    "                if i == bg_component:\n",
    "                    label = f\"Background (μ={mean:.1f}) [Composite]\"\n",
    "                else:\n",
    "                    label = f\"Component {i+1} (μ={mean:.1f}) [Composite]\"\n",
    "            else:\n",
    "                if i == bg_component:\n",
    "                    label = f\"Background (μ={mean:.1f})\"\n",
    "                else:\n",
    "                    label = f\"Component {i+1} (μ={mean:.1f})\"\n",
    "            \n",
    "            hist_ax.plot(x, y, color=colors[i % len(colors)], \n",
    "                        alpha=alpha, linewidth=2, label=label)\n",
    "        \n",
    "        # Add additional information for composite models\n",
    "        if is_composite:\n",
    "            # Add text box with composite model info\n",
    "            info_text = f\"Composite Model Applied\\nChannel-specific mean: {bg_model['mean']:.2f}\\nChannel-specific std: {bg_model['std']:.2f}\\nBackground pixels: {bg_model['bg_percentage']:.1f}%\"\n",
    "            hist_ax.text(0.02, 0.98, info_text, transform=hist_ax.transAxes, \n",
    "                        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
    "                        fontsize=8)\n",
    "        \n",
    "        hist_ax.set_title('Pixel Intensity Distribution')\n",
    "        hist_ax.set_xlabel('Pixel Value')\n",
    "        \n",
    "        # Use log scale only if there's a wide dynamic range\n",
    "        if hist_range[1] / hist_range[0] > 100:\n",
    "            hist_ax.set_xscale('log')\n",
    "        \n",
    "        hist_ax.set_ylabel('Density')\n",
    "        hist_ax.legend(fontsize=8)\n",
    "        \n",
    "        # Add channel-specific background statistics as text\n",
    "        bg_stats_text = f\"Channel BG: μ={bg_model['mean']:.2f}, σ={bg_model['std']:.2f}\"\n",
    "        hist_ax.text(0.98, 0.02, bg_stats_text, transform=hist_ax.transAxes,\n",
    "                    horizontalalignment='right', verticalalignment='bottom',\n",
    "                    bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8),\n",
    "                    fontsize=8)\n",
    "        \n",
    "        del flat_img, hist_range, n_bins, x\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=200)\n",
    "    plt.close('all')\n",
    "\n",
    "    del display_img, rgb_img\n",
    "\n",
    "def save_mask_as_tiff(mask, output_path, bit_depth=16):\n",
    "    \"\"\"\n",
    "    Save a labeled mask as TIFF with specified bit depth\n",
    "    \n",
    "    Parameters:\n",
    "    - mask: Integer labeled mask\n",
    "    - output_path: Path to save the TIFF file\n",
    "    - bit_depth: Bit depth (16 or 32) for the output file\n",
    "    \"\"\"\n",
    "    if np.max(mask) > 65535 and bit_depth == 16:\n",
    "        print(f\"Warning: Mask has {np.max(mask)} labels which exceeds 16-bit range. Using 32-bit.\")\n",
    "        bit_depth = 32\n",
    "    \n",
    "    if bit_depth == 16:\n",
    "        # Convert to 16-bit unsigned integer\n",
    "        mask_out = mask.astype(np.uint16)\n",
    "    else:\n",
    "        # Convert to 32-bit unsigned integer\n",
    "        mask_out = mask.astype(np.uint32)\n",
    "    \n",
    "    # Save as TIFF\n",
    "    tiff.imwrite(output_path, mask_out) \n",
    "    # print(f\"Saved mask with {len(np.unique(mask))-1} objects to: {output_path}\")\n",
    "\n",
    "def save_segmentation_qc_images(image, cell_masks, output_dir, img_name, config=None):\n",
    "    \"\"\"\n",
    "    Save quality control images showing zoomed-in regions of segmentation results,\n",
    "    with enhanced support for 3D data visualization\n",
    "    \n",
    "    Parameters:\n",
    "    - image: Multi-channel image array (H,W,C for 2D or Z,H,W,C for 3D)\n",
    "    - cell_masks: Integer mask with cell labels (H,W for 2D or Z,H,W for 3D)\n",
    "    - output_dir: Directory to save output images\n",
    "    - img_name: Base name of the image being processed\n",
    "    - config: Configuration dictionary with QC settings\n",
    "    \"\"\"\n",
    "    if config is None:\n",
    "        config = {}\n",
    "        # Check if 3D data is used\n",
    "        is_3d = len(image.shape) == 4 and image.shape[0] > 1\n",
    "    else:\n",
    "        is_3d = config.get('use_3d', False) or (len(image.shape) == 4 and image.shape[0] > 1)\n",
    "    \n",
    "    # Extract configuration\n",
    "    num_regions = config.get('qc_num_regions', 3)\n",
    "    region_size = config.get('qc_region_size', 400)\n",
    "    channels_to_show = config.get('qc_channels', list(range(image.shape[-1])))\n",
    "    \n",
    "    # Get cell properties and centroids\n",
    "    props = measure.regionprops(cell_masks)\n",
    "    \n",
    "    if len(props) == 0:\n",
    "        print(\"No cells detected for QC visualization\")\n",
    "        return\n",
    "    \n",
    "    # Create QC directory\n",
    "    qc_dir = os.path.join(output_dir, \"qc_regions\")\n",
    "    os.makedirs(qc_dir, exist_ok=True)\n",
    "    \n",
    "    # Select cell regions to display\n",
    "    props_sorted_by_area = sorted(props, key=lambda x: x.area, reverse=True)\n",
    "    \n",
    "    # Select some large cells and some random cells for diversity\n",
    "    selected_props = props_sorted_by_area[:min(num_regions, len(props))]\n",
    "    \n",
    "    # Add some random cells from the remaining population if available\n",
    "    remaining_props = props_sorted_by_area[min(num_regions, len(props)):]\n",
    "    if remaining_props and len(remaining_props) > num_regions:\n",
    "        random_indices = np.random.choice(len(remaining_props), \n",
    "                                         min(num_regions, len(remaining_props)), \n",
    "                                         replace=False)\n",
    "        selected_props.extend([remaining_props[i] for i in random_indices])\n",
    "    \n",
    "    # Process each selected region\n",
    "    for i, prop in enumerate(selected_props):\n",
    "        if is_3d:\n",
    "            # For 3D data, handle differently\n",
    "            z_depth, h, w, _ = image.shape\n",
    "            \n",
    "            # Extract centroid coordinates correctly\n",
    "            z, y, x = prop.centroid\n",
    "            z, y, x = int(z), int(y), int(x)\n",
    "            \n",
    "            # Calculate region boundaries\n",
    "            half_size = region_size // 2\n",
    "            \n",
    "            # Define region in X and Y dimensions\n",
    "            y1 = max(0, y - half_size)\n",
    "            y2 = min(h, y + half_size)\n",
    "            x1 = max(0, x - half_size)\n",
    "            x2 = min(w, x + half_size)\n",
    "            \n",
    "            # Define Z range for visualization (use a portion of the cell's Z extent)\n",
    "            z_min, z_max = prop.bbox[0], prop.bbox[3]\n",
    "            z_center = (z_min + z_max) // 2\n",
    "            z_half_range = min(5, (z_max - z_min) // 2)  # Show at most 11 z-slices\n",
    "            z_start = max(0, z_center - z_half_range)\n",
    "            z_end = min(z_depth, z_center + z_half_range + 1)\n",
    "            \n",
    "            # Extract region masks for all Z-slices of interest\n",
    "            region_masks = cell_masks[z_start:z_end, y1:y2, x1:x2]\n",
    "            \n",
    "            # Calculate z-slice indices to visualize\n",
    "            z_indices = list(range(z_start, z_end))\n",
    "            \n",
    "            # Create figure with a grid: rows for channels, columns for z-slices\n",
    "            num_channels = len(channels_to_show)\n",
    "            num_z_slices = len(z_indices)\n",
    "            \n",
    "            # Create figure with 3 rows: original image slices, mask overlays, MIP projection\n",
    "            fig_width = min(20, num_z_slices * 3)  # Cap width at 20 inches\n",
    "            fig, axes = plt.subplots(num_channels, 3, figsize=(fig_width, 4*num_channels))\n",
    "            \n",
    "            if num_channels == 1:\n",
    "                axes = np.array([axes])  # Make 2D for consistent indexing\n",
    "                \n",
    "            region_name = f\"region_{i+1}_cell_{prop.label}\"\n",
    "            fig.suptitle(f\"3D Region {i+1}: Cell {prop.label} (Volume: {prop.area}px, Z-range: {z_min}-{z_max})\")\n",
    "            \n",
    "            # Process each channel\n",
    "            for ch_idx, ch in enumerate(channels_to_show):\n",
    "                if ch < image.shape[-1]:  # Ensure channel exists\n",
    "                    # First column: Middle Z-slice\n",
    "                    middle_z_idx = len(z_indices) // 2\n",
    "                    middle_z = z_indices[middle_z_idx]\n",
    "                    \n",
    "                    # Extract middle slice for this channel\n",
    "                    mid_slice = image[middle_z, y1:y2, x1:x2, ch]\n",
    "                    \n",
    "                    # Normalize for display\n",
    "                    p2, p98 = np.percentile(mid_slice, (2, 98))\n",
    "                    mid_slice_norm = np.clip((mid_slice - p2) / (p98 - p2) * 255, 0, 255).astype(np.uint8)\n",
    "                    \n",
    "                    # Display middle slice\n",
    "                    axes[ch_idx, 0].imshow(mid_slice_norm, cmap='gray')\n",
    "                    axes[ch_idx, 0].set_title(f\"Channel {ch+1} (Z={middle_z})\")\n",
    "                    axes[ch_idx, 0].axis('off')\n",
    "                    \n",
    "                    # Create mask overlay for middle slice\n",
    "                    mid_mask = region_masks[middle_z_idx]\n",
    "                    \n",
    "                    # Second column: Middle Z-slice with mask overlay\n",
    "                    mask_overlay = np.zeros((*mid_slice.shape, 4), dtype=np.uint8)\n",
    "                    \n",
    "                    # Unique colors for each cell in the region\n",
    "                    unique_labels = np.unique(mid_mask)\n",
    "                    unique_labels = unique_labels[unique_labels > 0]  # Skip background\n",
    "                    \n",
    "                    # Create colorful mask overlay\n",
    "                    for label in unique_labels:\n",
    "                        color = np.array(plt.cm.tab10(label % 10)) * 255\n",
    "                        mask_overlay[mid_mask == label] = [*color[:3], 128]  # Semi-transparent\n",
    "                    \n",
    "                    # Show mask overlaid on middle slice\n",
    "                    axes[ch_idx, 1].imshow(mid_slice_norm, cmap='gray')\n",
    "                    axes[ch_idx, 1].imshow(mask_overlay)\n",
    "                    axes[ch_idx, 1].set_title(f\"Channel {ch+1} with segmentation\")\n",
    "                    axes[ch_idx, 1].axis('off')\n",
    "                    \n",
    "                    # Third column: Maximum Intensity Projection\n",
    "                    # Extract full region for this channel and create MIP\n",
    "                    region_vol = image[z_start:z_end, y1:y2, x1:x2, ch]\n",
    "                    mip = np.max(region_vol, axis=0)\n",
    "                    \n",
    "                    # Normalize MIP for display\n",
    "                    p2, p98 = np.percentile(mip, (2, 98))\n",
    "                    mip_norm = np.clip((mip - p2) / (p98 - p2) * 255, 0, 255).astype(np.uint8)\n",
    "                    \n",
    "                    # Create mask MIP\n",
    "                    mask_mip = np.max(region_masks > 0, axis=0).astype(np.uint8)\n",
    "                    \n",
    "                    # Create overlay for MIP\n",
    "                    mask_overlay_mip = np.zeros((*mip.shape, 4), dtype=np.uint8)\n",
    "                    mask_overlay_mip[mask_mip > 0] = [255, 0, 0, 128]  # Red semi-transparent\n",
    "                    \n",
    "                    # Display MIP with overlay\n",
    "                    axes[ch_idx, 2].imshow(mip_norm, cmap='gray')\n",
    "                    axes[ch_idx, 2].imshow(mask_overlay_mip)\n",
    "                    axes[ch_idx, 2].set_title(f\"Channel {ch+1} MIP\")\n",
    "                    axes[ch_idx, 2].axis('off')\n",
    "            \n",
    "        else:\n",
    "            # 2D processing (existing code)\n",
    "            # Get centroid and bounds for region extraction\n",
    "            y, x = int(prop.centroid[0]), int(prop.centroid[1])\n",
    "            \n",
    "            # Define boundaries ensuring they're within image bounds\n",
    "            h, w = image.shape[0:2]\n",
    "            half_size = region_size // 2\n",
    "            \n",
    "            y1 = max(0, y - half_size)\n",
    "            y2 = min(h, y + half_size)\n",
    "            x1 = max(0, x - half_size)\n",
    "            x2 = min(w, x + half_size)\n",
    "            \n",
    "            # Extract region masks\n",
    "            region_mask = cell_masks[y1:y2, x1:x2]\n",
    "            \n",
    "            # Create figure with rows for each channel and columns for (original, mask overlay)\n",
    "            num_channels = len(channels_to_show)\n",
    "            fig, axes = plt.subplots(num_channels, 2, figsize=(12, 4*num_channels))\n",
    "            \n",
    "            if num_channels == 1:\n",
    "                axes = np.array([axes])  # Make it 2D for consistent indexing\n",
    "                \n",
    "            region_name = f\"region_{i+1}_cell_{prop.label}\"\n",
    "            fig.suptitle(f\"Region {i+1}: Cell {prop.label} (Area: {prop.area}px)\")\n",
    "            \n",
    "            # Process each channel\n",
    "            for ch_idx, ch in enumerate(channels_to_show):\n",
    "                if ch < image.shape[-1]:  # Ensure channel exists\n",
    "                    # Extract region for this channel\n",
    "                    region_img = image[y1:y2, x1:x2, ch]\n",
    "                    \n",
    "                    # Normalize for display\n",
    "                    p2, p98 = np.percentile(region_img, (2, 98))\n",
    "                    region_img_norm = np.clip((region_img - p2) / (p98 - p2) * 255, 0, 255).astype(np.uint8)\n",
    "                    \n",
    "                    # Display original channel\n",
    "                    axes[ch_idx, 0].imshow(region_img_norm, cmap='gray')\n",
    "                    axes[ch_idx, 0].set_title(f\"Channel {ch+1}\")\n",
    "                    axes[ch_idx, 0].axis('off')\n",
    "                    \n",
    "                    # Create mask overlay\n",
    "                    mask_overlay = np.zeros((*region_img.shape, 4), dtype=np.uint8)\n",
    "                    \n",
    "                    # Unique colors for each cell in the region\n",
    "                    unique_labels = np.unique(region_mask)\n",
    "                    unique_labels = unique_labels[unique_labels > 0]  # Skip background\n",
    "                    \n",
    "                    # Create colorful mask overlay\n",
    "                    for label in unique_labels:\n",
    "                        color = np.array(plt.cm.tab10(label % 10)) * 255\n",
    "                        mask_overlay[region_mask == label] = [*color[:3], 128]  # Semi-transparent\n",
    "                        \n",
    "                    # Show mask overlaid on original image\n",
    "                    axes[ch_idx, 1].imshow(region_img_norm, cmap='gray')\n",
    "                    axes[ch_idx, 1].imshow(mask_overlay)\n",
    "                    axes[ch_idx, 1].set_title(f\"Channel {ch+1} with segmentation\")\n",
    "                    axes[ch_idx, 1].axis('off')\n",
    "        \n",
    "        # Adjust layout and save\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.95)  # Make room for suptitle\n",
    "        region_filename = os.path.join(qc_dir, f\"{os.path.splitext(img_name)[0]}_{region_name}.png\")\n",
    "        plt.savefig(region_filename, dpi=150)\n",
    "        plt.close(fig)\n",
    "    \n",
    "    # print(f\"Saved {len(selected_props)} QC region visualizations to {qc_dir}\")\n",
    "\n",
    "def create_visualization(image, masks, measurements, output_path, debug=False):\n",
    "    \"\"\"\n",
    "    Create multi-panel visualization for QC with 2D/3D support and optimized memory usage\n",
    "    \n",
    "    Parameters:\n",
    "    - image: Multi-channel image (H,W,C for 2D or Z,H,W,C for 3D)\n",
    "    - masks: Cell segmentation masks\n",
    "    - measurements: Cell measurements\n",
    "    - output_path: Where to save the visualization\n",
    "    - debug: Enable detailed timing and progress tracking\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if debug:\n",
    "            start_time = time.time()\n",
    "            print(f\"Starting visualization for {output_path}...\")\n",
    "        \n",
    "        # Force garbage collection before starting\n",
    "        gc.collect()\n",
    "\n",
    "        # Check if we're working with 3D data\n",
    "        is_3d = len(image.shape) == 4 and image.shape[0] > 1\n",
    "        \n",
    "        if is_3d:\n",
    "            # 3D visualization\n",
    "            z_depth, h, w, n_channels = image.shape\n",
    "            \n",
    "            # Calculate representative z-slices to display\n",
    "            z_positions = [z_depth // 4, z_depth // 2, 3 * z_depth // 4]\n",
    "            \n",
    "            # Create figure for 3D data - we'll use 2 rows:\n",
    "            # Row 1: Z-slices of representative planes\n",
    "            # Row 2: Maximum intensity projections (XY, YZ, XZ)\n",
    "            fig_width = max(15, n_channels * 3)  # Scale width based on channel count\n",
    "            fig = Figure(figsize=(fig_width, 10), dpi=200)\n",
    "            canvas = FigureCanvasAgg(fig)\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"Created 3D visualization figure with size {fig_width}x10 inches\")\n",
    "                \n",
    "            # Create grid with 2 rows\n",
    "            grid = fig.add_gridspec(2, n_channels + 1)\n",
    "            \n",
    "            # Row 1, Col 1: Show segmentation masks at middle z-slice\n",
    "            ax = fig.add_subplot(grid[0, 0])\n",
    "            middle_z = z_depth // 2\n",
    "            mask_slice = masks[middle_z]\n",
    "            ax.imshow(mask_slice > 0, cmap='viridis')\n",
    "            ax.set_title(f'Segmentation (Z={middle_z})')\n",
    "            ax.axis('off')\n",
    "\n",
    "            # Add cell labels to middle slice\n",
    "            if len(measurements) > 0:\n",
    "                # For 3D, filter cells that are present in this z-slice\n",
    "                if 'z_range' in measurements[0]:\n",
    "                    # Get cells that span this z-slice\n",
    "                    slice_cells = [cell for cell in measurements \n",
    "                                if cell['z_range'][0] <= middle_z <= cell['z_range'][1]]\n",
    "                    \n",
    "                    # Only label a subset of cells\n",
    "                    num_labels = min(30, len(slice_cells))\n",
    "                    if num_labels > 0:\n",
    "                        label_subset = slice_cells[:num_labels]\n",
    "                        \n",
    "                        for cell in label_subset:\n",
    "                            # Use 3D centroid if available, otherwise use 2D\n",
    "                            if 'centroid_3d' in cell:\n",
    "                                z, y, x = cell['centroid_3d']\n",
    "                                # Only add label if close to this z-slice\n",
    "                                if abs(z - middle_z) <= 2:  # Within 2 slices\n",
    "                                    ax.text(x, y, str(cell['label']), color='red', fontsize=5)\n",
    "            \n",
    "            # Row 2, Col 1: XY Maximum Intensity Projection\n",
    "            ax = fig.add_subplot(grid[1, 0])\n",
    "            mip_xy = np.max(masks, axis=0) > 0  # Binary MIP of masks\n",
    "            ax.imshow(mip_xy, cmap='viridis')\n",
    "            ax.set_title('Segmentation MIP (XY)')\n",
    "            ax.axis('off')\n",
    "            \n",
    "            # For each channel, show representative Z-slices and MIPs\n",
    "            for ch_idx in range(n_channels):\n",
    "                # Extract this channel's 3D data\n",
    "                channel_3d = image[:, :, :, ch_idx].copy()\n",
    "                \n",
    "                # Row 1: Middle z-slice of this channel\n",
    "                ax = fig.add_subplot(grid[0, ch_idx + 1])\n",
    "                \n",
    "                # Enhance contrast for better visualization\n",
    "                ch_slice = channel_3d[middle_z]\n",
    "                enhanced_slice = exposure.equalize_adapthist(ch_slice, clip_limit=0.03)\n",
    "                \n",
    "                # Show the channel with segmentation boundaries\n",
    "                ax.imshow(enhanced_slice, cmap='hot')\n",
    "                \n",
    "                # Add cell boundaries overlay\n",
    "                boundaries = find_boundaries(masks[middle_z] > 0)\n",
    "                ax.imshow(boundaries, alpha=0.3, cmap='cool')\n",
    "                \n",
    "                ax.set_title(f'Ch {ch_idx+1} (Z={middle_z})')\n",
    "                ax.axis('off')\n",
    "                \n",
    "                # Row 2: MIP of this channel with segmentation\n",
    "                ax = fig.add_subplot(grid[1, ch_idx + 1])\n",
    "                \n",
    "                # Create channel MIP with contrast enhancement\n",
    "                ch_mip = np.max(channel_3d, axis=0)\n",
    "                enhanced_mip = exposure.equalize_adapthist(ch_mip, clip_limit=0.03)\n",
    "                \n",
    "                # Show MIP with segmentation overlay\n",
    "                ax.imshow(enhanced_mip, cmap='hot')\n",
    "                \n",
    "                # Add MIP of boundaries\n",
    "                boundaries_mip = find_boundaries(mip_xy)\n",
    "                ax.imshow(boundaries_mip, alpha=0.3, cmap='cool')\n",
    "                \n",
    "                ax.set_title(f'Ch {ch_idx+1} MIP')\n",
    "                ax.axis('off')\n",
    "                \n",
    "                # Free memory\n",
    "                del channel_3d, ch_slice, enhanced_slice, enhanced_mip, boundaries\n",
    "                \n",
    "        else:\n",
    "            # Standard 2D visualization (existing code)\n",
    "            h, w, n_channels = image.shape\n",
    "            \n",
    "            # Calculate reasonable figure size to avoid excessive memory usage\n",
    "            max_dim = 2000  # Maximum dimension in pixels\n",
    "            scale_factor = min(1.0, max_dim / max(h, w))\n",
    "            \n",
    "            # Create figure without displaying (reduces memory usage)\n",
    "            dpi = 300  # Maintain good quality\n",
    "            fig_width = (n_channels + 1) * 4  # 4 inches per panel\n",
    "            fig_height = 4  # Fixed height\n",
    "            \n",
    "            # Use Figure directly instead of pyplot to avoid memory leaks\n",
    "            fig = Figure(figsize=(fig_width, fig_height), dpi=dpi)\n",
    "            canvas = FigureCanvasAgg(fig)\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"Created figure with size {fig_width}x{fig_height} inches at {dpi} DPI\")\n",
    "                print(f\"Processing {n_channels} channels and {len(measurements)} cells\")\n",
    "            \n",
    "            # Create subplot grid\n",
    "            grid = fig.add_gridspec(1, n_channels + 1)\n",
    "            \n",
    "            # Plot segmentation mask (first panel) with enhanced contrast\n",
    "            if debug:\n",
    "                print(\"Rendering segmentation mask...\")\n",
    "            \n",
    "            ax = fig.add_subplot(grid[0, 0])\n",
    "            \n",
    "            # Convert mask to float for better visualization\n",
    "            mask_display = (masks > 0).astype(float)\n",
    "            # Apply contrast enhancement to make it more visible\n",
    "            mask_display = exposure.equalize_adapthist(mask_display)\n",
    "            ax.imshow(mask_display, cmap='viridis')  # Use viridis for better contrast\n",
    "            ax.set_title('Cell Segmentation (Enhanced)')\n",
    "            ax.axis('off')  # Turn off axes to save memory\n",
    "            \n",
    "            # Only add labels for a subset of cells\n",
    "            if len(measurements) > 0:\n",
    "                if debug:\n",
    "                    print(\"Adding cell labels...\")\n",
    "                # Select a random subset of 50 cells or fewer if there are less than 50\n",
    "                num_labels = min(50, len(measurements))\n",
    "                # Use numpy's random choice if measurements is a list, otherwise select first num_labels\n",
    "                if isinstance(measurements, list):\n",
    "                    indices = np.random.choice(len(measurements), num_labels, replace=False)\n",
    "                    label_subset = [measurements[i] for i in indices]\n",
    "                else:\n",
    "                    label_subset = measurements[:num_labels]\n",
    "                    \n",
    "                for cell in label_subset:\n",
    "                    y, x = cell['centroid']\n",
    "                    ax.text(x, y, str(cell['label']), color='red', fontsize=5)\n",
    "            \n",
    "            # Process channels with progress tracking\n",
    "            channel_range = range(n_channels)\n",
    "            if debug:\n",
    "                from tqdm import tqdm\n",
    "                channel_range = tqdm(channel_range, desc=\"Processing channels\")\n",
    "            \n",
    "            for ch_idx, ch in enumerate(channel_range):\n",
    "                if debug:\n",
    "                    ch_start = time.time()\n",
    "                    \n",
    "                # Create subplot for this channel\n",
    "                ax = fig.add_subplot(grid[0, ch_idx + 1])\n",
    "                \n",
    "                # Get channel data and apply adaptive contrast enhancement\n",
    "                channel_data = image[:,:,ch].copy()  # Make a copy to avoid modifying original\n",
    "                \n",
    "                # Adaptive histogram equalization - best for visualizing local features\n",
    "                enhanced_data = exposure.equalize_adapthist(channel_data, clip_limit=0.03)\n",
    "                \n",
    "                # Display the image\n",
    "                ax.imshow(enhanced_data, cmap='hot')\n",
    "                ax.set_title(f'Channel {ch+1} (Enhanced)')\n",
    "                ax.axis('off')  # Turn off axes to save memory\n",
    "                \n",
    "                # Show cell boundaries efficiently\n",
    "                boundaries = find_boundaries(masks > 0)\n",
    "                ax.imshow(boundaries, alpha=0.3, cmap='cool')\n",
    "                \n",
    "                # Free memory\n",
    "                del channel_data\n",
    "                del enhanced_data\n",
    "                del boundaries\n",
    "                \n",
    "                if debug:\n",
    "                    print(f\"  Channel {ch+1} rendered in {time.time() - ch_start:.2f}s\")\n",
    "        \n",
    "        # Adjust layout and save\n",
    "        if debug:\n",
    "            print(\"Saving figure...\")\n",
    "            save_start = time.time()\n",
    "            \n",
    "        fig.tight_layout()\n",
    "        fig.savefig(output_path, bbox_inches='tight')\n",
    "        \n",
    "        # Clean up matplotlib resources explicitly\n",
    "        fig.clf()\n",
    "        canvas.renderer.clear()\n",
    "        del fig\n",
    "        del canvas\n",
    "        \n",
    "        # Force garbage collection\n",
    "        gc.collect()\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Visualization saved in {time.time() - save_start:.2f}s\")\n",
    "            print(f\"Total visualization time: {time.time() - start_time:.2f}s\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in visualization: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        # Ensure cleanup even on error\n",
    "        if 'fig' in locals():\n",
    "            fig.clf()\n",
    "            del fig\n",
    "        if 'canvas' in locals():\n",
    "            canvas.renderer.clear()\n",
    "            del canvas\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_image(image, scale_factor=0.5, downsample_z=False):\n",
    "    \"\"\"Resample image by the given scale factor with optional Z-downsampling\"\"\"\n",
    "    \n",
    "    # Check if this is 3D data with channels\n",
    "    is_3d = len(image.shape) == 4 and image.shape[0] > 1\n",
    "    \n",
    "    if is_3d:\n",
    "        z_depth, h, w, c = image.shape\n",
    "        \n",
    "        if downsample_z:\n",
    "            # Downsample in all dimensions including Z\n",
    "            new_z = int(z_depth * scale_factor)\n",
    "            new_h, new_w = int(h * scale_factor), int(w * scale_factor)\n",
    "            resized = resize(image, (new_z, new_h, new_w, c), \n",
    "                            preserve_range=True, anti_aliasing=True)\n",
    "        else:\n",
    "            # Downsample only in X and Y, preserving Z resolution\n",
    "            new_h, new_w = int(h * scale_factor), int(w * scale_factor)\n",
    "            resized = np.zeros((z_depth, new_h, new_w, c), dtype=image.dtype)\n",
    "            \n",
    "            # Process each Z-slice\n",
    "            for z in range(z_depth):\n",
    "                resized[z] = resize(image[z], (new_h, new_w, c), \n",
    "                                    preserve_range=True, anti_aliasing=True)\n",
    "    else:\n",
    "        # Original 2D case\n",
    "        h, w, c = image.shape\n",
    "        new_h, new_w = int(h * scale_factor), int(w * scale_factor)\n",
    "        resized = resize(image, (new_h, new_w, c), preserve_range=True, anti_aliasing=True)\n",
    "    \n",
    "    return resized.astype(image.dtype)\n",
    "\n",
    "def create_composite_image(image, method='max', config=None):\n",
    "    \"\"\"Create composite image from multi-channel data\"\"\"\n",
    "\n",
    "    # Work with a copy to avoid modifying original\n",
    "    normalized_img = image.copy().astype(np.float32)\n",
    "\n",
    "    # Normalize each channel for equal contribution to composite\n",
    "    for ch in range(normalized_img.shape[-1]):\n",
    "        channel = normalized_img[..., ch]\n",
    "        \n",
    "        # Percentile normalization (1st-99th percentile) for robustness\n",
    "        low_p = np.percentile(channel, 1)\n",
    "        high_p = np.percentile(channel, 99)\n",
    "        \n",
    "        if high_p > low_p:\n",
    "            channel = np.clip(channel, low_p, high_p)\n",
    "            channel = (channel - low_p) / (high_p - low_p)\n",
    "        else:\n",
    "            channel = np.zeros_like(channel)\n",
    "            \n",
    "        normalized_img[..., ch] = channel\n",
    "\n",
    "    # Create composite from normalized channels\n",
    "    if method == 'mean':\n",
    "        composite = np.mean(normalized_img, axis=-1)\n",
    "    elif method == 'max':\n",
    "        composite = np.max(normalized_img, axis=-1)\n",
    "    elif method == 'weighted':\n",
    "        weights = config.get('channel_weights', None) if config else None\n",
    "        if weights is None:\n",
    "            # Weight by channel variance in normalized space\n",
    "            weights = []\n",
    "            for ch in range(normalized_img.shape[-1]):\n",
    "                channel_var = np.var(normalized_img[..., ch])\n",
    "                weights.append(channel_var)\n",
    "            weights = np.array(weights)\n",
    "            weights = weights / np.sum(weights) if np.sum(weights) > 0 else np.ones_like(weights)\n",
    "\n",
    "        composite = np.zeros(normalized_img.shape[:-1])\n",
    "        for ch in range(normalized_img.shape[-1]):\n",
    "            composite += weights[ch] * normalized_img[..., ch]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown composite method: {method}\")\n",
    "\n",
    "    return composite, normalized_img\n",
    "\n",
    "def check_gpu_availability():\n",
    "    \"\"\"Check if GPU is available for processing\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background Substraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_background_gmm(image, config = None, n_components=2, sample_ratio=0.05, \n",
    "                                max_iter=100, max_components=6):\n",
    "    \n",
    "    use_composite = config.get('use_bg_composite', False)\n",
    "    bg_models = {}\n",
    "\n",
    "    if use_composite and image.shape[-1] > 1:\n",
    "        # Create composite image for background estimation using ORIGINAL values\n",
    "        composite_image, normalized_channels = create_composite_image(image, method='max', config=config)\n",
    "        \n",
    "        # Get composite background model\n",
    "        composite_bg_model, gmm_model = estimate_background_gmm_single(composite_image, config, n_components=n_components, \n",
    "                                                           sample_ratio=sample_ratio, max_iter=max_iter, \n",
    "                                                           max_components=max_components)\n",
    "\n",
    "        for ch in tqdm(range(image.shape[-1]), desc=\"Estimating Background Masks (composite)\"):\n",
    "            # Get normalized channel data for prediction\n",
    "            normalized_channel = normalized_channels[..., ch]\n",
    "            original_channel = image[..., ch]\n",
    "            \n",
    "            # Predict background using the composite GMM on normalized channel data\n",
    "            bg_mask_ch = predict_background_mask(\n",
    "                normalized_channel, gmm_model, composite_bg_model['bg_component']\n",
    "            )\n",
    "            \n",
    "            # Calculate channel-specific statistics using original data and predicted mask\n",
    "            bg_pixels = original_channel[bg_mask_ch]\n",
    "            \n",
    "            if len(bg_pixels) > 0:\n",
    "                ch_bg_mean = np.mean(bg_pixels)\n",
    "                ch_bg_std = np.std(bg_pixels)\n",
    "                bg_percentage = np.sum(bg_mask_ch) / bg_mask_ch.size * 100\n",
    "            else:\n",
    "                # Fallback if no background pixels found\n",
    "                print(f\"Warning: No background pixels found for channel {ch+1}, using global statistics\")\n",
    "                ch_bg_mean = np.mean(original_channel)\n",
    "                ch_bg_std = np.std(original_channel)\n",
    "                bg_percentage = 0\n",
    "            \n",
    "            # Create channel-specific background model\n",
    "            bg_models[ch] = {\n",
    "                'mean': ch_bg_mean,\n",
    "                'std': ch_bg_std,\n",
    "                'mask': bg_mask_ch,  # Channel-specific mask\n",
    "                'bg_percentage': bg_percentage,\n",
    "                'component_means': composite_bg_model['component_means'],  # From composite\n",
    "                'component_weights': composite_bg_model['component_weights'],  # From composite\n",
    "                'component_covs': composite_bg_model['component_covs'],  # From composite\n",
    "                'n_components': composite_bg_model['n_components'],\n",
    "                'bg_component': composite_bg_model['bg_component'],\n",
    "                'method': 'composite_enhanced'  # Flag for enhanced method\n",
    "            }\n",
    "            \n",
    "    elif image.shape[-1] == 1:\n",
    "        # Single channel case\n",
    "        bg_models[0] = estimate_background_gmm_single(image, config, n_components=n_components, \n",
    "                                                      sample_ratio=sample_ratio, max_iter=max_iter, \n",
    "                                                      max_components=max_components)\n",
    "    else:\n",
    "        # Individual channel processing (original behavior)\n",
    "        for ch in tqdm(range(image.shape[-1]), desc=\"Estimating Background GMM\"):\n",
    "            channel_data = image[..., ch].copy() # Avoid modifying original data\n",
    "            bg_models[ch] = estimate_background_gmm_single(channel_data, config, n_components=n_components, \n",
    "                                                           sample_ratio=sample_ratio, max_iter=max_iter, \n",
    "                                                           max_components=max_components)\n",
    "\n",
    "    return bg_models\n",
    "\n",
    "def predict_background_mask(normalized_channel, gmm_model, bg_component):\n",
    "    \"\"\"\n",
    "    Predict background mask for a normalized channel using composite GMM model\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Predict background for this normalized channel\n",
    "        flat_channel = normalized_channel.flatten().reshape(-1, 1)\n",
    "        pixel_labels = gmm_model.predict(flat_channel)\n",
    "\n",
    "        bg_mask = (pixel_labels == bg_component).reshape(normalized_channel.shape)\n",
    "        \n",
    "        return bg_mask\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in background prediction: {str(e)}\")\n",
    "        # Fallback: return a conservative background mask\n",
    "        return np.zeros_like(normalized_channel, dtype=bool)\n",
    "\n",
    "def estimate_background_gmm_single(image, config = None, n_components=2, sample_ratio=0.05, \n",
    "                                max_iter=100, max_components=6):\n",
    "    \"\"\"\n",
    "    Fast background estimation using GMM with optional adaptive component selection\n",
    "    Parameters:\n",
    "    - image: 2D or 3D image array (H,W or Z,H,W)\n",
    "    - config: Configuration dictionary with options like 'use_3d', 'adaptive_gmm'\n",
    "    - n_components: Number of GMM components to use (default 2)\n",
    "    - sample_ratio: Fraction of pixels to sample for GMM fitting (default 0.05)\n",
    "    - max_iter: Maximum iterations for GMM fitting (default 100)\n",
    "    - max_components: Maximum number of components to try in adaptive mode (default 6)\n",
    "    Returns:\n",
    "    - Dictionary with background mean, std, mask, and GMM parameters\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if 3D and change sample size\n",
    "    use_3d = config.get('use_3d', False) if config else False\n",
    "\n",
    "    if use_3d:\n",
    "        sample_ratio = sample_ratio * 0.5  # Reduce sample size for 3D images\n",
    "        min_sample_nr = 50000  # Minimum sample size for 3D images\n",
    "    else:\n",
    "        min_sample_nr = 5000  # Minimum sample size for 2D images\n",
    "\n",
    "    try:\n",
    "        adaptive = config.get('adaptive_gmm', False) if config else False\n",
    "\n",
    "        # Flatten and sample\n",
    "        flat_img = image.flatten()\n",
    "        n_samples = max(min_sample_nr, int(sample_ratio * flat_img.size))\n",
    "        \n",
    "        # Use systematic sampling for speed (every nth pixel)\n",
    "        step = max(1, flat_img.size // n_samples)\n",
    "        sample_data = flat_img[::step].reshape(-1, 1)\n",
    "        \n",
    "        # Select GMM model - adaptive or fixed\n",
    "        if adaptive:\n",
    "            bic_scores = []\n",
    "            models = []\n",
    "            \n",
    "            # Try different numbers of components\n",
    "            for n in range(1, max_components + 1):\n",
    "                # Initialize with K-means for faster convergence\n",
    "                kmeans = KMeans(n_clusters=n, n_init=1, max_iter=100)\n",
    "                kmeans.fit(sample_data)\n",
    "                \n",
    "                # Configure and fit GMM\n",
    "                gmm = GaussianMixture(\n",
    "                    n_components=n, \n",
    "                    random_state=42,\n",
    "                    n_init=1, \n",
    "                    max_iter=max_iter,\n",
    "                    tol=1e-3,\n",
    "                    means_init=kmeans.cluster_centers_\n",
    "                )\n",
    "                \n",
    "                gmm.fit(sample_data)\n",
    "                bic_scores.append(gmm.bic(sample_data))\n",
    "                models.append(gmm)\n",
    "                \n",
    "                del kmeans\n",
    "                \n",
    "            # Select model with lowest BIC score\n",
    "            best_idx = np.argmin(bic_scores)\n",
    "            gmm = models[best_idx]\n",
    "            n_components = models[best_idx].n_components\n",
    "            print(f\"Adaptive GMM selected {n_components} components with BIC: {bic_scores[best_idx]:.2f}\")\n",
    "            \n",
    "            # Clean up unused models\n",
    "            for i, model in enumerate(models):\n",
    "                if i != best_idx:\n",
    "                    del model\n",
    "            models = None\n",
    "        else:\n",
    "            # Non-adaptive - just use specified components\n",
    "            # Initialize with K-means for faster convergence\n",
    "            kmeans = KMeans(n_clusters=n_components, n_init=1, max_iter=100)\n",
    "            kmeans.fit(sample_data)\n",
    "            \n",
    "            # Configure GMM and fit\n",
    "            gmm = GaussianMixture(\n",
    "                n_components=n_components,\n",
    "                random_state=42,\n",
    "                n_init=1,\n",
    "                max_iter=max_iter,\n",
    "                tol=1e-3,\n",
    "                means_init=kmeans.cluster_centers_\n",
    "            )\n",
    "            gmm.fit(sample_data)\n",
    "            del kmeans\n",
    "        \n",
    "        # Extract model parameters\n",
    "        means = gmm.means_.flatten()\n",
    "        covs = np.array([gmm.covariances_[i].flatten()[0] for i in range(gmm.n_components)])\n",
    "        weights = gmm.weights_\n",
    "        \n",
    "        # Identify background component (lowest mean)\n",
    "        bg_component = np.argmin(means)\n",
    "        bg_mean = means[bg_component]\n",
    "        bg_std = np.sqrt(covs[bg_component])\n",
    "        \n",
    "        # Use original model to predict components - more efficient\n",
    "        pixel_labels = gmm.predict(flat_img.reshape(-1, 1))\n",
    "        bg_mask = (pixel_labels == bg_component).reshape(image.shape)\n",
    "        \n",
    "        # Clean up sample data to free memory\n",
    "        del sample_data, flat_img, pixel_labels\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'mean': bg_mean,\n",
    "            'std': bg_std,\n",
    "            'mask': bg_mask,\n",
    "            'bg_percentage': np.sum(bg_mask) / bg_mask.size * 100,\n",
    "            'component_means': means,\n",
    "            'component_weights': weights,\n",
    "            'component_covs': covs,\n",
    "            'n_components': n_components,\n",
    "            'bg_component': bg_component,\n",
    "        }\n",
    "\n",
    "        if config.get('use_bg_composite'):\n",
    "            return result, gmm\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in GMM background estimation: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        # Return fallback values\n",
    "        return {'mean': 0, 'std': 0, 'mask': np.zeros_like(image, dtype=bool)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation and Aligment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_nuclei_threshold(batch_images_nuclei, config):\n",
    "    \"\"\"\n",
    "    Threshold-based nuclei segmentation for batch processing (optimized)\n",
    "    \n",
    "    Parameters:\n",
    "    - batch_images_nuclei: List of nucleus channel images (already background-corrected)\n",
    "    - config: Configuration dictionary\n",
    "    \n",
    "    Returns:\n",
    "    - masks_nuclei: List of integer masks with nuclei labels\n",
    "    \"\"\"\n",
    "    # Get configuration parameters\n",
    "    lower_thresh_factor = config.get('nuclei_thresh_factor', 2.0)\n",
    "    upper_thresh = config.get('upper_thresh', 60000)\n",
    "    min_size = config.get('nuclei_min_size', 5)\n",
    "    max_size = config.get('nuclei_max_size', 1000)\n",
    "    use_gpu = config.get('use_gpu', True) and check_gpu_availability()\n",
    "    \n",
    "    print(f\"Processing {len(batch_images_nuclei)} nuclei images using {'GPU' if use_gpu else 'CPU'}...\")\n",
    "    \n",
    "    if use_gpu:\n",
    "        return _segment_nuclei_threshold_gpu(\n",
    "            batch_images_nuclei, lower_thresh_factor, upper_thresh, \n",
    "            min_size, max_size\n",
    "        )\n",
    "    else:\n",
    "        return _segment_nuclei_threshold_cpu_parallel(\n",
    "            batch_images_nuclei, lower_thresh_factor, upper_thresh, \n",
    "            min_size, max_size, config\n",
    "        )\n",
    "\n",
    "def _segment_nuclei_threshold_gpu(batch_images_nuclei, lower_thresh_factor, upper_thresh, \n",
    "                                 min_size, max_size):\n",
    "    \"\"\"GPU-accelerated batch nuclei segmentation\"\"\"\n",
    "    \n",
    "    device = torch.device('cuda')\n",
    "    masks_nuclei = []\n",
    "    \n",
    "    try:\n",
    "        # Check if all images have the same size\n",
    "        shapes = [img.shape for img in batch_images_nuclei]\n",
    "        if len(set(shapes)) > 1:\n",
    "            print(f\"Images have different sizes: {shapes}. Processing individually on GPU.\")\n",
    "            # Process each image individually instead of batching\n",
    "            for img in batch_images_nuclei:\n",
    "                # Convert single image to tensor\n",
    "                img_tensor = torch.from_numpy(img).float().to(device).unsqueeze(0)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    # Calculate threshold for this image\n",
    "                    img_mean = torch.mean(img_tensor)\n",
    "                    img_std = torch.std(img_tensor)\n",
    "                    threshold = img_mean + (lower_thresh_factor * img_std)\n",
    "                    \n",
    "                    # Apply threshold\n",
    "                    binary_mask = (img_tensor > threshold) & (img_tensor < upper_thresh)\n",
    "                \n",
    "                # Convert back to CPU for morphological operations\n",
    "                binary_mask_cpu = binary_mask.squeeze(0).cpu().numpy()\n",
    "                \n",
    "                # Morphological operations (CPU-based)\n",
    "                from skimage.morphology import binary_closing, disk, remove_small_objects\n",
    "                \n",
    "                binary_mask_cpu = binary_closing(binary_mask_cpu, disk(2))\n",
    "                binary_mask_cpu = remove_small_objects(binary_mask_cpu, min_size=min_size)\n",
    "                \n",
    "                # Label connected components\n",
    "                nuclei_labels = measure.label(binary_mask_cpu)\n",
    "                \n",
    "                # Filter by size\n",
    "                props = measure.regionprops(nuclei_labels)\n",
    "                filtered_labels = np.zeros_like(nuclei_labels)\n",
    "                new_label = 1\n",
    "                \n",
    "                for prop in props:\n",
    "                    if min_size <= prop.area <= max_size:\n",
    "                        mask = nuclei_labels == prop.label\n",
    "                        filtered_labels[mask] = new_label\n",
    "                        new_label += 1\n",
    "                \n",
    "                masks_nuclei.append(filtered_labels)\n",
    "                \n",
    "                # Clear GPU memory\n",
    "                del img_tensor, binary_mask\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            return masks_nuclei\n",
    "        \n",
    "        # Original batching code for same-sized images\n",
    "        # Process in smaller GPU batches to avoid memory issues\n",
    "        gpu_batch_size = min(4, len(batch_images_nuclei))\n",
    "        \n",
    "        for batch_start in range(0, len(batch_images_nuclei), gpu_batch_size):\n",
    "            batch_end = min(batch_start + gpu_batch_size, len(batch_images_nuclei))\n",
    "            gpu_batch = batch_images_nuclei[batch_start:batch_end]\n",
    "            \n",
    "            # Convert batch to tensor (now we know they're the same size)\n",
    "            batch_tensor = torch.stack([\n",
    "                torch.from_numpy(img).float() for img in gpu_batch\n",
    "            ]).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # Vectorized threshold calculation\n",
    "                batch_means = torch.mean(batch_tensor.view(batch_tensor.shape[0], -1), dim=1)\n",
    "                batch_stds = torch.std(batch_tensor.view(batch_tensor.shape[0], -1), dim=1)\n",
    "                thresholds = batch_means + (lower_thresh_factor * batch_stds)\n",
    "                \n",
    "                # Apply thresholds (vectorized)\n",
    "                thresholds = thresholds.view(-1, 1, 1)  # Broadcast shape\n",
    "                if len(batch_tensor.shape) == 4:  # 3D case\n",
    "                    thresholds = thresholds.view(-1, 1, 1, 1)\n",
    "                \n",
    "                binary_masks = (batch_tensor > thresholds) & (batch_tensor < upper_thresh)\n",
    "            \n",
    "            # Convert back to CPU for morphological operations and labeling\n",
    "            binary_masks_cpu = binary_masks.cpu().numpy()\n",
    "            \n",
    "            # Process each mask individually for morphological operations\n",
    "            for i, binary_mask in enumerate(binary_masks_cpu):\n",
    "                # Morphological operations (CPU-based)\n",
    "                \n",
    "                binary_mask = binary_closing(binary_mask, disk(2))\n",
    "                binary_mask = remove_small_objects(binary_mask, min_size=min_size)\n",
    "                \n",
    "                # Label connected components\n",
    "                nuclei_labels = measure.label(binary_mask)\n",
    "                \n",
    "                # Filter by size\n",
    "                props = measure.regionprops(nuclei_labels)\n",
    "                filtered_labels = np.zeros_like(nuclei_labels)\n",
    "                new_label = 1\n",
    "                \n",
    "                for prop in props:\n",
    "                    if min_size <= prop.area <= max_size:\n",
    "                        mask = nuclei_labels == prop.label\n",
    "                        filtered_labels[mask] = new_label\n",
    "                        new_label += 1\n",
    "                \n",
    "                masks_nuclei.append(filtered_labels)\n",
    "            \n",
    "            # Clear GPU memory\n",
    "            del batch_tensor, binary_masks\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"GPU nuclei segmentation failed: {e}. Falling back to CPU.\")\n",
    "        return _segment_nuclei_threshold_cpu_parallel(\n",
    "            batch_images_nuclei, lower_thresh_factor, upper_thresh, \n",
    "            min_size, max_size, {'max_workers': 2}  # Reduce workers to avoid crashes\n",
    "        )\n",
    "    \n",
    "    return masks_nuclei\n",
    "\n",
    "def _segment_nuclei_threshold_cpu_parallel(batch_images_nuclei, lower_thresh_factor, \n",
    "                                          upper_thresh, min_size, max_size, config=None):\n",
    "    \"\"\"CPU parallelized batch nuclei segmentation with error handling\"\"\"\n",
    "    \n",
    "    # Prepare arguments for parallel processing\n",
    "    process_func = partial(\n",
    "        _process_single_nucleus_image,\n",
    "        lower_thresh_factor=lower_thresh_factor,\n",
    "        upper_thresh=upper_thresh,\n",
    "        min_size=min_size,\n",
    "        max_size=max_size\n",
    "    )\n",
    "    \n",
    "    # Reduce max_workers and add error handling\n",
    "    max_workers = min(2, config.get('max_workers', 2)) if config else 2\n",
    "    masks_nuclei = []\n",
    "    \n",
    "    try:\n",
    "        with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "            # Submit all tasks\n",
    "            future_to_idx = {\n",
    "                executor.submit(process_func, img): idx \n",
    "                for idx, img in enumerate(batch_images_nuclei)\n",
    "            }\n",
    "            \n",
    "            # Initialize results list with proper size\n",
    "            results = [None] * len(batch_images_nuclei)\n",
    "            \n",
    "            # Collect results as they complete\n",
    "            for future in concurrent.futures.as_completed(future_to_idx):\n",
    "                idx = future_to_idx[future]\n",
    "                try:\n",
    "                    result = future.result(timeout=60)  # 60 second timeout per image\n",
    "                    results[idx] = result\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing nuclei image {idx}: {str(e)}\")\n",
    "                    # Create empty mask for failed processing\n",
    "                    img_shape = batch_images_nuclei[idx].shape\n",
    "                    results[idx] = np.zeros(img_shape, dtype=np.int32)\n",
    "            \n",
    "            masks_nuclei = results\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Parallel processing failed: {str(e)}. Processing sequentially.\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        # Fallback to sequential processing\n",
    "        masks_nuclei = []\n",
    "        for i, img in enumerate(batch_images_nuclei):\n",
    "            try:\n",
    "                mask = process_func(img)\n",
    "                masks_nuclei.append(mask)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing nuclei image {i} sequentially: {str(e)}\")\n",
    "                masks_nuclei.append(np.zeros(img.shape, dtype=np.int32))\n",
    "    \n",
    "    return masks_nuclei\n",
    "\n",
    "def _process_single_nucleus_image(nucleus_image, lower_thresh_factor, upper_thresh, min_size, max_size):\n",
    "    \"\"\"Process a single nucleus image (for parallel processing) - no background subtraction needed\"\"\"\n",
    "    \n",
    "    # Calculate threshold\n",
    "    mean_val = np.mean(nucleus_image)\n",
    "    std_val = np.std(nucleus_image)\n",
    "    threshold = mean_val + (lower_thresh_factor * std_val)\n",
    "    \n",
    "    # Apply threshold with upper limit\n",
    "    binary_mask = (nucleus_image > threshold) & (nucleus_image < upper_thresh)\n",
    "    \n",
    "    # Morphological operations\n",
    "    binary_mask = binary_closing(binary_mask, disk(2))\n",
    "    binary_mask = remove_small_objects(binary_mask, min_size=min_size)\n",
    "    \n",
    "    # Label connected components\n",
    "    nuclei_labels = measure.label(binary_mask)\n",
    "    \n",
    "    # Filter by size\n",
    "    props = measure.regionprops(nuclei_labels)\n",
    "    filtered_labels = np.zeros_like(nuclei_labels)\n",
    "    new_label = 1\n",
    "    \n",
    "    for prop in props:\n",
    "        if min_size <= prop.area <= max_size:\n",
    "            mask = nuclei_labels == prop.label\n",
    "            filtered_labels[mask] = new_label\n",
    "            new_label += 1\n",
    "    \n",
    "    return filtered_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_nuclei_from_background_mask(bg_models_nuclei, config):\n",
    "    \"\"\"\n",
    "    Fast nuclei segmentation using pre-computed background masks - CPU optimized\n",
    "    \n",
    "    Parameters:\n",
    "    - bg_models_nuclei: List of background models for each nucleus image\n",
    "    - config: Configuration dictionary\n",
    "    \n",
    "    Returns:\n",
    "    - masks_nuclei: List of integer masks with nuclei labels\n",
    "    \"\"\"\n",
    "    # Get configuration parameters\n",
    "    min_size = config.get('nuclei_min_size', 5)\n",
    "    max_size = config.get('nuclei_max_size', 1000)\n",
    "    morphology_radius = config.get('nuclei_morphology_radius', 1)\n",
    "    \n",
    "    print(f\"Processing {len(bg_models_nuclei)} nuclei images using background masks (CPU optimized)...\")\n",
    "    \n",
    "    # Use ThreadPoolExecutor for I/O bound tasks\n",
    "    max_workers = min(8, config.get('max_workers', 8))\n",
    "    \n",
    "    # Prepare processing function with fixed parameters\n",
    "    process_func = partial(\n",
    "        _process_single_nucleus_bg_mask,\n",
    "        min_size=min_size,\n",
    "        max_size=max_size,\n",
    "        morphology_radius=morphology_radius\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Use ThreadPoolExecutor - much faster for this type of task\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            # Only pass background models - no need for images!\n",
    "            masks_nuclei = list(executor.map(process_func, bg_models_nuclei))\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Parallel processing failed: {str(e)}. Processing sequentially.\")\n",
    "        \n",
    "        # Fallback to sequential processing\n",
    "        masks_nuclei = []\n",
    "        for bg_model in bg_models_nuclei:\n",
    "            try:\n",
    "                mask = process_func(bg_model)\n",
    "                masks_nuclei.append(mask)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing nuclei image: {str(e)}\")\n",
    "                # Create empty mask - we need to get shape from bg_model['mask']\n",
    "                masks_nuclei.append(np.zeros(bg_model['mask'].shape, dtype=np.int32))\n",
    "    \n",
    "    return masks_nuclei\n",
    "\n",
    "def _process_single_nucleus_bg_mask(bg_model, min_size=5, max_size=1000, morphology_radius=1):\n",
    "    \"\"\"\n",
    "    Optimized single nucleus processing using only background mask\n",
    "    \n",
    "    Parameters:\n",
    "    - bg_model: Background model containing the mask\n",
    "    - min_size: Minimum object size\n",
    "    - max_size: Maximum object size  \n",
    "    - morphology_radius: Radius for morphological operations\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get foreground mask (inverse of background) - this is the key insight!\n",
    "    foreground_mask = ~bg_model['mask']\n",
    "    \n",
    "    # Skip morphological operations if radius is 0 or very small\n",
    "    if morphology_radius > 0:\n",
    "        # Apply minimal morphological operations\n",
    "        if morphology_radius == 1:\n",
    "            foreground_mask = binary_closing(foreground_mask, disk(1))\n",
    "        else:\n",
    "            foreground_mask = binary_closing(foreground_mask, disk(morphology_radius))\n",
    "        \n",
    "        # Remove tiny objects efficiently\n",
    "        foreground_mask = remove_small_objects(foreground_mask, min_size=max(1, min_size//3))\n",
    "    \n",
    "    # Label connected components efficiently\n",
    "    nuclei_labels = measure.label(foreground_mask)\n",
    "    \n",
    "    # Quick size filtering using vectorized operations\n",
    "    if np.max(nuclei_labels) > 0:\n",
    "        # Get region properties for size filtering\n",
    "        props = measure.regionprops(nuclei_labels)\n",
    "        \n",
    "        # Create a mapping array for relabeling\n",
    "        label_mapping = np.zeros(np.max(nuclei_labels) + 1, dtype=np.int32)\n",
    "        new_label = 1\n",
    "        \n",
    "        for prop in props:\n",
    "            if min_size <= prop.area <= max_size:\n",
    "                label_mapping[prop.label] = new_label\n",
    "                new_label += 1\n",
    "        \n",
    "        # Apply mapping efficiently using fancy indexing\n",
    "        filtered_labels = label_mapping[nuclei_labels]\n",
    "    else:\n",
    "        filtered_labels = nuclei_labels\n",
    "    \n",
    "    return filtered_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_cells_cellpose(image, config, bg_models=None):\n",
    "\n",
    "    \"\"\"Cell segmentation using CellPose with optimized memory usage\"\"\"\n",
    "    \n",
    "    # Extract 3D configuration\n",
    "    use_3d = config.get('use_3d', False)\n",
    "\n",
    "    model = models.CellposeModel(gpu=config.get('use_gpu', True))\n",
    "        \n",
    "    segmentation_channels = config.get('segmentation_channels', list(range(image.shape[-1])))\n",
    "    print(f\"Using custom segmentation with channels: {[ch+1 for ch in segmentation_channels]}\")\n",
    "\n",
    "    # Create a multi-channel image with the channels of interest\n",
    "    img_to_segment = np.stack([image[...,ch].copy() for ch in segmentation_channels], axis=-1)\n",
    "\n",
    "    # Apply background subtraction if available\n",
    "    for i, ch in enumerate(segmentation_channels):\n",
    "        if ch in bg_models:\n",
    "            ch_mean = bg_models[ch]['mean']\n",
    "            img_to_segment[...,i] = np.clip(img_to_segment[...,i] - ch_mean, 0, None)\n",
    "            print(f\"Applied background subtraction to channel {ch+1} (mean: {ch_mean:.2f})\")\n",
    "\n",
    "    print(f\"Running Cellpose with channels: {ch+1}\" for ch in segmentation_channels)\n",
    "    print(f\"Image shape for segmentation: {img_to_segment.shape}\")\n",
    "    \n",
    "    # Run segmentation with debug info\n",
    "    try:\n",
    "        masks, flows, styles = model.eval(\n",
    "            img_to_segment, \n",
    "            anisotropy=config.get('anisotropy', 3.0),\n",
    "            flow_threshold=config.get('flow_threshold', 0.4),\n",
    "            cellprob_threshold=config.get('cellprob_threshold', 0.0),\n",
    "            normalize=True,\n",
    "            progress=True,\n",
    "            do_3D=use_3d\n",
    "        )\n",
    "        \n",
    "        # Free memory\n",
    "        del img_to_segment, model\n",
    "        if 'flows' in locals() and flows is not None:\n",
    "            del flows\n",
    "        if 'styles' in locals() and styles is not None:\n",
    "            del styles\n",
    "\n",
    "        gc.collect()\n",
    "        \n",
    "        print(f\"Segmentation complete! Found {len(np.unique(masks))-1} objects\")\n",
    "        return masks\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR in Cellpose: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        return np.zeros(image.shape[:2], dtype=np.int32)\n",
    "\n",
    "def segment_cells_with_downsampling(image, config, bg_models=None):\n",
    "    \"\"\"Segment cells with better memory management\"\"\"\n",
    "    # Get downsampling factor from config\n",
    "    downsample_factor = config.get('downsample_factor', 1.0)\n",
    "    \n",
    "    try:\n",
    "        if downsample_factor >= 1.0:\n",
    "            # Process at original resolution\n",
    "            masks = segment_cells_cellpose(image, config, bg_models)\n",
    "            return masks\n",
    "        \n",
    "        # Downsample image for processing\n",
    "        small_image = resample_image(image, downsample_factor)\n",
    "        \n",
    "        # Adjust cell diameter for downsampled image\n",
    "        small_config = config.copy()\n",
    "        small_config['cell_diameter'] = config.get('cell_diameter', 20.0) * downsample_factor\n",
    "        \n",
    "        # Run segmentation on smaller image\n",
    "        small_masks = segment_cells_cellpose(small_image, small_config, bg_models)\n",
    "        \n",
    "        # Free memory before upsampling\n",
    "        del small_image\n",
    "        gc.collect()\n",
    "        \n",
    "        # Upsample masks to original size\n",
    "        masks_upscaled = resize(small_masks, image.shape[0:2], order=0, preserve_range=True)\n",
    "        masks_upscaled = masks_upscaled.astype(np.int32)\n",
    "        \n",
    "        # Free memory\n",
    "        del small_masks\n",
    "        \n",
    "        return masks_upscaled\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in segmentation: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        # Return empty mask in case of error\n",
    "        return np.zeros(image.shape[:2], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_cell_masks_to_nuclei(nuclei_masks, cell_masks, is_3d=False):\n",
    "    \"\"\"\n",
    "    Highly optimized alignment of cell and nuclei masks.\n",
    "    \n",
    "    Parameters:\n",
    "    - nuclei_masks: Integer mask with nuclei labels\n",
    "    - cell_masks: Integer mask with cell labels\n",
    "    - is_3d: Boolean indicating if masks are 3D\n",
    "    - config: Optional configuration dictionary\n",
    "    \n",
    "    Returns:\n",
    "    - combined_masks: Final mask with consistent labeling based on nuclei\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Quick early exit if no nuclei\n",
    "    if np.max(nuclei_masks) == 0:\n",
    "        print(\"No nuclei detected for alignment\")\n",
    "        return cell_masks\n",
    "    \n",
    "    # Get unique labels more efficiently (single pass)\n",
    "    nuclei_labels = np.unique(nuclei_masks)[1:]  # Skip background 0\n",
    "    cell_labels = np.unique(cell_masks)[1:]      # Skip background 0\n",
    "    \n",
    "    # Initialize output with nuclei\n",
    "    combined_masks = nuclei_masks.copy()\n",
    "    \n",
    "    # Create sparse matrices\n",
    "    flat_nuclei = nuclei_masks.ravel()\n",
    "    flat_cells = cell_masks.ravel()\n",
    "    \n",
    "    # Only consider pixels where both masks have labels\n",
    "    valid_pixels = (flat_nuclei > 0) & (flat_cells > 0)\n",
    "    \n",
    "    # If there's no overlap at all, just return cell masks\n",
    "    if not np.any(valid_pixels):\n",
    "        print(\"No overlap between nuclei and cells\")\n",
    "        return cell_masks\n",
    "    \n",
    "    # Get overlapping pixel coordinates and create sparse matrix in one step\n",
    "    rows = flat_nuclei[valid_pixels]\n",
    "    cols = flat_cells[valid_pixels]\n",
    "    data = np.ones(len(rows), dtype=np.int32)\n",
    "    \n",
    "    # Create sparse matrix of shape (max_nucleus+1, max_cell+1)\n",
    "    n_max = np.max(nuclei_labels) + 1\n",
    "    c_max = np.max(cell_labels) + 1\n",
    "    \n",
    "    # Create overlap matrix with optimized memory usage\n",
    "    overlap_matrix = sparse.csr_matrix((data, (rows, cols)), \n",
    "                                      shape=(n_max, c_max))\n",
    "    \n",
    "    # Extract maximum overlap info in parallel\n",
    "    nucleus_to_cell_map = {}\n",
    "    \n",
    "    # For each nucleus, find the cell with maximum overlap \n",
    "    for _, nucleus_label in enumerate(nuclei_labels):\n",
    "        # Get overlaps for this nucleus efficiently \n",
    "        row = overlap_matrix[nucleus_label]\n",
    "        \n",
    "        # Skip if no overlaps\n",
    "        if row.nnz == 0:\n",
    "            continue\n",
    "            \n",
    "        # Get max overlap cell\n",
    "        max_idx = row.indices[np.argmax(row.data)]\n",
    "        if max_idx > 0:  # Ensure not mapping to background\n",
    "            nucleus_to_cell_map[nucleus_label] = max_idx\n",
    "    \n",
    "    # Get binary mask of all nuclei (just once)\n",
    "    all_nuclei_mask = nuclei_masks > 0\n",
    "    \n",
    "    # Create a mapping array from cell labels to nucleus labels\n",
    "    cell_to_nuc_array = np.zeros(c_max, dtype=np.int32)\n",
    "    \n",
    "    # Set up the mapping\n",
    "    for nuc_label, cell_label in nucleus_to_cell_map.items():\n",
    "        cell_to_nuc_array[cell_label] = nuc_label\n",
    "    \n",
    "    # OPTIMIZATION 6: Only loop through cells that have a mapping\n",
    "    mapped_cells = set(nucleus_to_cell_map.values())\n",
    "    if mapped_cells:\n",
    "        # Process cells in batches for better performance\n",
    "        batch_size = min(50, len(mapped_cells))\n",
    "        mapped_cell_list = list(mapped_cells)\n",
    "        \n",
    "        for i in range(0, len(mapped_cell_list), batch_size):\n",
    "            batch_cells = mapped_cell_list[i:i+batch_size]\n",
    "            \n",
    "            # Create mask for this batch of cells\n",
    "            batch_mask = np.isin(cell_masks, batch_cells)\n",
    "            \n",
    "            # Only keep cell regions not already covered by nuclei\n",
    "            cell_regions = batch_mask & ~all_nuclei_mask\n",
    "            \n",
    "            # Apply mapping with vectorized operation\n",
    "            if np.any(cell_regions):\n",
    "                # Get indices where we need to update\n",
    "                y_idx, x_idx = np.where(cell_regions) if not is_3d else np.where(cell_regions)\n",
    "                \n",
    "                # Get the original cell labels at these positions\n",
    "                orig_cell_labels = cell_masks[y_idx, x_idx] if not is_3d else cell_masks[y_idx]\n",
    "                \n",
    "                # Map cell labels to nucleus labels using our mapping array\n",
    "                mapped_nucleus_labels = np.array([cell_to_nuc_array[cl] for cl in orig_cell_labels])\n",
    "                \n",
    "                # Update the output mask\n",
    "                if not is_3d:\n",
    "                    combined_masks[y_idx, x_idx] = mapped_nucleus_labels\n",
    "                else:\n",
    "                    combined_masks[y_idx] = mapped_nucleus_labels\n",
    "        \n",
    "    \n",
    "    return combined_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_masks_by_size(masks, min_size=None, max_size=None, config=None):\n",
    "    \"\"\"\n",
    "    Optimized filtering of cell masks by size (area or maximum extension radius)\n",
    "    \n",
    "    Parameters:\n",
    "    - masks: Integer mask with cell labels\n",
    "    - min_size: Minimum size (pixels or radius)\n",
    "    - max_size: Maximum size (pixels or radius) \n",
    "    - config: Configuration dictionary\n",
    "    \n",
    "    Returns:\n",
    "    - filtered_masks: Filtered mask with consecutive labeling\n",
    "    \"\"\"\n",
    "    if config is None:\n",
    "        config = {}\n",
    "    \n",
    "    # Get filtering parameters\n",
    "    filter_by_radius = config.get('filter_by_radius', False)\n",
    "    min_filter = min_size if min_size is not None else config.get('cell_min_size', 5)\n",
    "    max_filter = max_size if max_size is not None else config.get('cell_max_size', 200)\n",
    "    \n",
    "    # Get region properties - compute only what we need\n",
    "    if filter_by_radius:\n",
    "        props = measure.regionprops(masks, extra_properties=[])  # No extra properties\n",
    "    else:\n",
    "        props = measure.regionprops(masks, extra_properties=[])\n",
    "    \n",
    "    if len(props) == 0:\n",
    "        return np.zeros_like(masks)\n",
    "    \n",
    "    # Vectorized size calculation and filtering\n",
    "    if filter_by_radius:\n",
    "        # Extract major_axis_length for all props at once\n",
    "        sizes = np.array([prop.major_axis_length / 2.0 for prop in props])\n",
    "    else:\n",
    "        # Extract areas for all props at once\n",
    "        sizes = np.array([prop.area for prop in props])\n",
    "    \n",
    "    # Get original labels\n",
    "    original_labels = np.array([prop.label for prop in props])\n",
    "    \n",
    "    # Vectorized filtering - much faster than individual checks\n",
    "    valid_mask = (sizes >= min_filter) & (sizes <= max_filter)\n",
    "    valid_labels = original_labels[valid_mask]\n",
    "    \n",
    "    if len(valid_labels) == 0:\n",
    "        return np.zeros_like(masks)\n",
    "    \n",
    "    # Create label mapping array for efficient relabeling\n",
    "    max_label = np.max(original_labels)\n",
    "    label_mapping = np.zeros(max_label + 1, dtype=np.int32)\n",
    "    \n",
    "    # Map valid labels to consecutive new labels\n",
    "    new_labels = np.arange(1, len(valid_labels) + 1, dtype=np.int32)\n",
    "    label_mapping[valid_labels] = new_labels\n",
    "    \n",
    "    # Apply mapping efficiently using fancy indexing\n",
    "    filtered_masks = label_mapping[masks]\n",
    "    \n",
    "    # print(f\"Size filtering: kept {len(valid_labels)}/{len(props)} objects\")\n",
    "    return filtered_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell Measurement and counting\n",
    "These functions measure the cells fluorescence and count the positive cells per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold_value(channel_data, bg_mean, bg_std, config, ch):\n",
    "    \"\"\"Helper function to calculate threshold value for positive cell counting\"\"\"\n",
    "    if config is None:\n",
    "        config = {}\n",
    "        \n",
    "    threshold_method = config.get('positive_threshold_method', 'bg_plus_std')\n",
    "    \n",
    "    if threshold_method == 'bg_plus_std':\n",
    "        n_std = config.get('positive_threshold_std_multiplier', 2.0)\n",
    "        threshold = bg_mean + (n_std * bg_std)\n",
    "    \n",
    "    elif threshold_method == 'percentile':\n",
    "        percentile = config.get('positive_threshold_percentile', 75)\n",
    "        if isinstance(channel_data, torch.Tensor):\n",
    "            threshold = torch.quantile(channel_data, percentile/100.0).item()\n",
    "        else:\n",
    "            threshold = np.percentile(channel_data, percentile)\n",
    "    \n",
    "    elif threshold_method == 'otsu':\n",
    "        if isinstance(channel_data, torch.Tensor):\n",
    "            channel_np = channel_data.cpu().numpy()\n",
    "            threshold = threshold_otsu(channel_np)\n",
    "        else:\n",
    "            threshold = threshold_otsu(channel_data)\n",
    "    \n",
    "    else:  # 'manual'\n",
    "        threshold = config.get(f'channel_{ch+1}_threshold', bg_mean + 2*bg_std)\n",
    "    \n",
    "    return threshold\n",
    "\n",
    "def measure_cells(image, cell_masks, bg_models, config=None):\n",
    "    \"\"\"\n",
    "    Unified CTCF measurement function that handles both 2D and 3D data\n",
    "    \n",
    "    Parameters:\n",
    "    - image: Multi-channel image array (Y,X,C) for 2D or (Z,Y,X,C) for 3D\n",
    "    - cell_masks: Integer mask with cell labels (Y,X) for 2D or (Z,Y,X) for 3D\n",
    "    - bg_models: Background models for each channel\n",
    "    - config: Configuration dictionary\n",
    "    \n",
    "    Returns:\n",
    "    - List of cell measurements\n",
    "    \"\"\"\n",
    "    # Detect if data is 3D\n",
    "    is_3d = config.get('use_3d', False) or (len(image.shape) == 4 and len(cell_masks.shape) == 3)\n",
    "    \n",
    "    # Check if GPU should be used\n",
    "    use_gpu = config.get('use_gpu', True)\n",
    "    if use_gpu and config.get('auto_detect_gpu', True):\n",
    "        use_gpu = check_gpu_availability()\n",
    "    \n",
    "    # Select appropriate implementation\n",
    "    if is_3d:\n",
    "        print(\"Using 3D CTCF measurement...\")\n",
    "        if use_gpu:\n",
    "            try:\n",
    "                return measure_cells_ctcf_3d_gpu(image, cell_masks, bg_models, config)\n",
    "            except Exception as e:\n",
    "                print(f\"3D GPU CTCF measurement failed: {str(e)}. Falling back to CPU.\")\n",
    "                return measure_cells_ctcf_3d_cpu(image, cell_masks, bg_models, config)\n",
    "        else:\n",
    "            return measure_cells_ctcf_3d_cpu(image, cell_masks, bg_models, config)\n",
    "    else:\n",
    "        # Use existing 2D implementations\n",
    "        if use_gpu:\n",
    "            try:\n",
    "                return measure_cells_ctcf_gpu(image, cell_masks, bg_models, config)\n",
    "            except Exception as e:\n",
    "                print(f\"GPU CTCF measurement failed: {str(e)}. Falling back to CPU.\")\n",
    "                return measure_cells_ctcf_cpu(image, cell_masks, bg_models, config)\n",
    "        else:\n",
    "            return measure_cells_ctcf_cpu(image, cell_masks, bg_models, config)\n",
    "    \n",
    "def measure_cells_ctcf_cpu(image, cell_masks, bg_models, config=None):\n",
    "    \"\"\"\n",
    "    Measure CTCF for all cells and channels with integrated positive cell counting\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Get unique cell labels\n",
    "    unique_labels = np.unique(cell_masks)\n",
    "    unique_labels = unique_labels[unique_labels > 0]  # Skip background (0)\n",
    "    total_cells = len(unique_labels)\n",
    "    \n",
    "    if total_cells == 0:\n",
    "        print(\"No cells found in mask.\")\n",
    "        return [], {}\n",
    "    \n",
    "    print(f\"Measuring CTCF for {total_cells} cells using parallel CPU processing...\")\n",
    "    \n",
    "    # Pre-compute thresholds for positive cell counting\n",
    "    thresholds = {}\n",
    "    for ch in range(image.shape[-1]):\n",
    "        bg_mean = bg_models[ch]['mean'] if ch in bg_models else 0\n",
    "        bg_std = bg_models[ch]['std'] if ch in bg_models else np.std(image[..., ch])\n",
    "        thresholds[ch] = get_threshold_value(image[..., ch], bg_mean, bg_std, config, ch)\n",
    "    \n",
    "    # Determine optimal batch size and number of workers\n",
    "    max_workers = config.get('max_workers', min(os.cpu_count(), 8))\n",
    "    batch_size = config.get('batch_size', max(10, total_cells // (max_workers * 2)))\n",
    "    \n",
    "    # Create batches of cell labels\n",
    "    label_batches = [unique_labels[i:i + batch_size] for i in range(0, len(unique_labels), batch_size)]\n",
    "    print(f\"Processing {len(label_batches)} batches with up to {max_workers} workers\")\n",
    "    \n",
    "    # Prepare partial function with fixed arguments including thresholds\n",
    "    process_batch_func = partial(\n",
    "        process_cell_batch,\n",
    "        image=image,\n",
    "        cell_masks=cell_masks,\n",
    "        bg_models=bg_models,\n",
    "        thresholds=thresholds\n",
    "    )\n",
    "    \n",
    "    # Process batches in parallel\n",
    "    results = []\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        batch_results = list(\n",
    "            tqdm(\n",
    "                executor.map(process_batch_func, label_batches), \n",
    "                total=len(label_batches),\n",
    "                desc=\"Processing batches\"\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Combine batch results\n",
    "        for batch_result in batch_results:\n",
    "            results.extend(batch_result)\n",
    "    \n",
    "    # Final timing\n",
    "    total_time = time.time() - start_time\n",
    "    cells_per_sec = total_cells / (total_time + 1e-6)\n",
    "    print(f\"Parallel CTCF measurement complete: {total_cells} cells in {total_time:.2f}s ({cells_per_sec:.2f} cells/sec)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def process_cell_batch(cell_labels, image, cell_masks, bg_models, thresholds = None):\n",
    "    \"\"\"\n",
    "    Process a batch of cells for CTCF measurement (called by parallel worker).\n",
    "    \"\"\"\n",
    "    # Process-safe matplotlib configuration (avoid conflicts)\n",
    "    \n",
    "    batch_results = []\n",
    "    \n",
    "    for label in cell_labels:\n",
    "        # Create mask for this cell only\n",
    "        cell_mask = cell_masks == label\n",
    "        \n",
    "        # Get cell properties\n",
    "        y_indices, x_indices = np.where(cell_mask)\n",
    "        if len(y_indices) == 0:\n",
    "            continue\n",
    "            \n",
    "        area = len(y_indices)\n",
    "        y_centroid = np.mean(y_indices)\n",
    "        x_centroid = np.mean(x_indices)\n",
    "        \n",
    "        # Initialize cell data\n",
    "        cell_data = {\n",
    "            'label': int(label),\n",
    "            'area': int(area),\n",
    "            'centroid': (float(y_centroid), float(x_centroid)),\n",
    "            'ctcf': {},\n",
    "            'mean': {},\n",
    "            'total': {},\n",
    "            'bg_value': {},\n",
    "            'c_positive': {} \n",
    "        }\n",
    "        \n",
    "        # Process each channel\n",
    "        for ch in range(image.shape[-1]):\n",
    "            # Extract the channel data\n",
    "            channel = image[:,:,ch]\n",
    "            \n",
    "            # Use efficient boolean indexing\n",
    "            cell_pixels = channel[cell_mask]\n",
    "            \n",
    "            # Get background value\n",
    "            bg_value = bg_models[ch]['mean'] if ch in bg_models else 0\n",
    "            cell_data['bg_value'][ch] = float(bg_value)\n",
    "            \n",
    "            # Calculate measurements\n",
    "            total_intensity = np.sum(cell_pixels)\n",
    "            mean_intensity = np.mean(cell_pixels)\n",
    "            ctcf = total_intensity - (area * bg_value)\n",
    "            \n",
    "            # Store results\n",
    "            cell_data['total'][ch] = float(total_intensity)\n",
    "            cell_data['mean'][ch] = float(mean_intensity)\n",
    "            cell_data['ctcf'][ch] = float(ctcf)\n",
    "            \n",
    "            # Determine if cell is positive for this channel\n",
    "            threshold = thresholds[ch]\n",
    "            cell_data['c_positive'][ch] = bool(mean_intensity > threshold)\n",
    "            \n",
    "        batch_results.append(cell_data)\n",
    "    \n",
    "    return batch_results\n",
    "\n",
    "def measure_cells_ctcf_gpu(image, cell_masks, bg_models, config=None, debug=False):\n",
    "    \"\"\"GPU-accelerated CTCF measurement with integrated positive cell counting\"\"\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Convert arrays to PyTorch tensors on GPU\n",
    "    device = torch.device('cuda')\n",
    "    try:    \n",
    "        image_tensor = torch.from_numpy(image).to(device).float()\n",
    "        mask_tensor = torch.from_numpy(cell_masks).to(device)\n",
    "        \n",
    "        # Get unique cell IDs for processing\n",
    "        cell_ids = torch.unique(mask_tensor)[1:]  # Skip 0 (background)\n",
    "        total_cells = len(cell_ids)\n",
    "        print(f\"Measuring CTCF for {total_cells} cells across {image.shape[-1]} channels on GPU...\")\n",
    "        \n",
    "        # Pre-compute thresholds for positive cell counting\n",
    "        thresholds = {}\n",
    "        for ch in range(image.shape[-1]):\n",
    "            bg_mean = bg_models[ch]['mean'] if ch in bg_models else 0\n",
    "            bg_std = bg_models[ch]['std'] if ch in bg_models else torch.std(image_tensor[..., ch]).item()\n",
    "            thresholds[ch] = get_threshold_value(image_tensor[..., ch], bg_mean, bg_std, config, ch)\n",
    "        \n",
    "        # Prepare results container\n",
    "        measurements = []\n",
    "        \n",
    "        # Process in batches\n",
    "        batch_size = config.get('gpu_batch_size', min(500, total_cells))\n",
    "\n",
    "        for batch_start in tqdm(range(0, total_cells, batch_size), desc=\"Processing cell batches\"):\n",
    "            batch_end = min(batch_start + batch_size, total_cells)\n",
    "            batch_ids = cell_ids[batch_start:batch_end]\n",
    "            \n",
    "            # Process each cell in the batch\n",
    "            for cell_idx in range(len(batch_ids)):\n",
    "                cell_id = batch_ids[cell_idx].item()\n",
    "                \n",
    "                # Create binary mask for this cell\n",
    "                with torch.no_grad():\n",
    "                    cell_mask = (mask_tensor == cell_id).bool()\n",
    "                    cell_area = torch.sum(cell_mask).item()\n",
    "                    \n",
    "                    if cell_area == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    # Calculate centroid\n",
    "                    y_indices, x_indices = torch.where(cell_mask)\n",
    "                    centroid_y = torch.mean(y_indices.float()).item()\n",
    "                    centroid_x = torch.mean(x_indices.float()).item()\n",
    "                \n",
    "                cell_data = {\n",
    "                    'label': int(cell_id),\n",
    "                    'area': int(cell_area),\n",
    "                    'centroid': (float(centroid_y), float(centroid_x)),\n",
    "                    'ctcf': {},\n",
    "                    'mean': {},\n",
    "                    'total': {},\n",
    "                    'bg_value': {},\n",
    "                    'c_positive': {}  \n",
    "                }\n",
    "                \n",
    "                # Process all channels\n",
    "                for ch in range(image_tensor.shape[2]):\n",
    "                    with torch.no_grad():\n",
    "                        channel_data = image_tensor[:, :, ch]\n",
    "                        bg_value = bg_models[ch]['mean'] if ch in bg_models else 0\n",
    "                        cell_data['bg_value'][ch] = float(bg_value)\n",
    "                        \n",
    "                        # GPU-accelerated measurements\n",
    "                        cell_pixels = torch.masked_select(channel_data, cell_mask)\n",
    "                        total_intensity = torch.sum(cell_pixels).item()\n",
    "                        mean_intensity = torch.mean(cell_pixels).item() if cell_pixels.numel() > 0 else 0\n",
    "                        ctcf = total_intensity - (cell_area * bg_value)\n",
    "                        \n",
    "                        cell_data['total'][ch] = float(total_intensity)\n",
    "                        cell_data['mean'][ch] = float(mean_intensity)\n",
    "                        cell_data['ctcf'][ch] = float(ctcf)\n",
    "                        \n",
    "                        # Determine if cell is positive for this channel\n",
    "                        threshold = thresholds[ch]\n",
    "                        cell_data['c_positive'][ch] = bool(mean_intensity > threshold)\n",
    "                \n",
    "                measurements.append(cell_data)\n",
    "            \n",
    "            # Free GPU memory after each batch\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        cells_per_sec = total_cells / total_time\n",
    "        print(f\"GPU CTCF measurement complete: {total_cells} cells in {total_time:.2f}s ({cells_per_sec:.2f} cells/sec)\")\n",
    "        \n",
    "        return measurements\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU memory error: {str(e)}. Falling back to CPU.\")\n",
    "        traceback.print_exc()\n",
    "        return measure_cells_ctcf_cpu(image, cell_masks, bg_models, config)\n",
    "    \n",
    "\n",
    "def measure_cells_ctcf_3d_cpu(image, cell_masks, bg_models, config=None):\n",
    "    \"\"\"\n",
    "    Measure CTCF for all cells in 3D z-stack data using CPU processing\n",
    "    \n",
    "    Parameters:\n",
    "    - image: 3D multi-channel image array (Z, Y, X, C)\n",
    "    - cell_masks: 3D integer mask with cell labels (Z, Y, X)\n",
    "    - bg_models: Background models for each channel and potentially each z-slice\n",
    "    - config: Configuration dictionary\n",
    "    \n",
    "    Returns:\n",
    "    - List of cell measurements\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Get unique cell labels\n",
    "    unique_labels = np.unique(cell_masks)\n",
    "    unique_labels = unique_labels[unique_labels > 0]  # Skip background (0)\n",
    "    total_cells = len(unique_labels)\n",
    "    \n",
    "    if total_cells == 0:\n",
    "        print(\"No cells found in 3D mask.\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"Measuring 3D CTCF for {total_cells} cells using parallel CPU processing...\")\n",
    "    \n",
    "    # Pre-compute thresholds for positive cell counting\n",
    "    thresholds = {}\n",
    "    for ch in range(image.shape[-1]):\n",
    "        bg_mean = bg_models[ch]['mean'] if ch in bg_models else 0\n",
    "        bg_std = bg_models[ch]['std'] if ch in bg_models else np.std(image[..., ch])\n",
    "        thresholds[ch] = get_threshold_value(image[..., ch], bg_mean, bg_std, config, ch)\n",
    "    \n",
    "    # Determine optimal batch size and number of workers\n",
    "    max_workers = config.get('max_workers', min(os.cpu_count(), 8))\n",
    "    batch_size = config.get('batch_size', max(5, total_cells // (max_workers * 2)))\n",
    "    \n",
    "    # Create batches of cell labels\n",
    "    label_batches = [unique_labels[i:i + batch_size] for i in range(0, len(unique_labels), batch_size)]\n",
    "    print(f\"Processing {len(label_batches)} batches with up to {max_workers} workers\")\n",
    "    \n",
    "    # Prepare partial function with fixed arguments including thresholds\n",
    "    process_batch_func = partial(\n",
    "        process_cell_batch_3d,\n",
    "        image=image,\n",
    "        cell_masks=cell_masks,\n",
    "        bg_models=bg_models,\n",
    "        thresholds=thresholds,\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    # Process batches in parallel\n",
    "    results = []\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        batch_results = list(\n",
    "            tqdm(\n",
    "                executor.map(process_batch_func, label_batches),\n",
    "                total=len(label_batches),\n",
    "                desc=\"Processing 3D cell batches\"\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Combine batch results\n",
    "        for batch_result in batch_results:\n",
    "            results.extend(batch_result)\n",
    "    \n",
    "    # Final timing\n",
    "    total_time = time.time() - start_time\n",
    "    cells_per_sec = total_cells / (total_time + 1e-6)\n",
    "    print(f\"3D CTCF measurement complete: {total_cells} cells in {total_time:.2f}s ({cells_per_sec:.2f} cells/sec)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def process_cell_batch_3d(cell_labels, image, cell_masks, bg_models, thresholds=None, config=None):\n",
    "    \"\"\"\n",
    "    Process a batch of 3D cells for CTCF measurement (called by parallel worker).\n",
    "    \"\"\"\n",
    "    batch_results = []\n",
    "    \n",
    "    # Get dimensions\n",
    "    z_slices, height, width, n_channels = image.shape\n",
    "    \n",
    "    # Get background model type (per slice or global)\n",
    "    bg_model_per_slice = config.get('bg_model_per_slice', False) if config else False\n",
    "    \n",
    "    for label in cell_labels:\n",
    "        # Create mask for this cell only\n",
    "        cell_mask = cell_masks == label\n",
    "        \n",
    "        # Get cell properties in 3D\n",
    "        z_indices, y_indices, x_indices = np.where(cell_mask)\n",
    "        if len(z_indices) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Calculate 3D properties\n",
    "        volume = len(z_indices)  # Total voxels\n",
    "        z_centroid = np.mean(z_indices)\n",
    "        y_centroid = np.mean(y_indices)\n",
    "        x_centroid = np.mean(x_indices)\n",
    "        \n",
    "        # Min and max z-slices for this cell (useful for visualization)\n",
    "        min_z = np.min(z_indices)\n",
    "        max_z = np.max(z_indices)\n",
    "        \n",
    "        # Initialize cell data with 3D structure matching 2D format\n",
    "        cell_data = {\n",
    "            'label': int(label),  # Ensure label is int for serialization\n",
    "            'area': int(volume),  # Use volume for area to maintain compatibility\n",
    "            'volume': int(volume),  # Also include explicit volume\n",
    "            'centroid': (float(y_centroid), float(x_centroid)),  # 2D-style centroid for compatibility\n",
    "            'centroid_3d': (float(z_centroid), float(y_centroid), float(x_centroid)),  # Full 3D centroid\n",
    "            'z_range': (int(min_z), int(max_z)),  # z-range spanned by this cell\n",
    "            'ctcf': {},\n",
    "            'mean': {},\n",
    "            'total': {},\n",
    "            'bg_value': {},\n",
    "            'c_positive': {}  # Add positive cell counting\n",
    "        }\n",
    "        \n",
    "        # Process each channel\n",
    "        for ch in range(n_channels):\n",
    "            # Extract the channel data - access the entire channel data at once\n",
    "            channel_data = image[:, :, :, ch]\n",
    "            \n",
    "            # Use efficient boolean indexing for the whole 3D cell\n",
    "            cell_voxels = channel_data[cell_mask]\n",
    "            \n",
    "            bg_value = bg_models[ch]['mean'] if ch in bg_models else 0\n",
    "            \n",
    "            cell_data['bg_value'][ch] = float(bg_value)\n",
    "            \n",
    "            # Calculate 3D measurements\n",
    "            total_intensity = np.sum(cell_voxels)\n",
    "            mean_intensity = np.mean(cell_voxels) if len(cell_voxels) > 0 else 0\n",
    "            ctcf = total_intensity - (volume * bg_value)  # Apply background correction using volume\n",
    "            \n",
    "            # Store results (convert to Python types for serialization)\n",
    "            cell_data['total'][ch] = float(total_intensity)\n",
    "            cell_data['mean'][ch] = float(mean_intensity)\n",
    "            cell_data['ctcf'][ch] = float(ctcf)\n",
    "            \n",
    "            # Determine if cell is positive for this channel\n",
    "            if thresholds and ch in thresholds:\n",
    "                threshold = thresholds[ch]\n",
    "                cell_data['c_positive'][ch] = bool(mean_intensity > threshold)\n",
    "            else:\n",
    "                # Fallback if no thresholds provided\n",
    "                cell_data['c_positive'][ch] = False\n",
    "            \n",
    "        batch_results.append(cell_data)\n",
    "    \n",
    "    return batch_results\n",
    "\n",
    "def measure_cells_ctcf_3d_gpu(image, cell_masks, bg_models, config=None, debug=False):\n",
    "    \"\"\"\n",
    "    GPU-accelerated 3D CTCF measurement for improved performance\n",
    "    \n",
    "    Parameters:\n",
    "    - image: 3D multi-channel image array (Z, Y, X, C)\n",
    "    - cell_masks: 3D integer mask with cell labels (Z, Y, X)\n",
    "    - bg_models: Background models for each channel\n",
    "    - config: Configuration dictionary\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Convert arrays to PyTorch tensors on GPU with explicit data type conversion\n",
    "    device = torch.device('cuda')\n",
    "    try:\n",
    "        # Handle 3D data - rearrange to (Z, Y, X, C)\n",
    "        if len(image.shape) == 4:\n",
    "            z_slices, height, width, channels = image.shape\n",
    "        else:\n",
    "            raise ValueError(\"Expected 4D input for 3D data (Z, Y, X, C)\")\n",
    "\n",
    "        # Convert to float32 since uint16 is not supported by all operations\n",
    "        image_tensor = torch.from_numpy(image).to(device).float()\n",
    "        mask_tensor = torch.from_numpy(cell_masks).to(device)\n",
    "        \n",
    "        # Get unique cell IDs for processing\n",
    "        cell_ids = torch.unique(mask_tensor)[1:]  # Skip 0 (background)\n",
    "        total_cells = len(cell_ids)\n",
    "        print(f\"Measuring 3D CTCF for {total_cells} cells across {channels} channels on GPU...\")\n",
    "        \n",
    "        # Pre-compute thresholds for positive cell counting\n",
    "        thresholds = {}\n",
    "        for ch in range(image.shape[-1]):\n",
    "            bg_mean = bg_models[ch]['mean'] if ch in bg_models else 0\n",
    "            bg_std = bg_models[ch]['std'] if ch in bg_models else torch.std(image_tensor[..., ch]).item()\n",
    "            thresholds[ch] = get_threshold_value(image_tensor[..., ch], bg_mean, bg_std, config, ch)\n",
    "        \n",
    "        # Process in smaller batches for 3D data to avoid GPU memory issues\n",
    "        batch_size = config.get('gpu_batch_size_3d', min(100, total_cells))\n",
    "        measurements = []\n",
    "        \n",
    "        for batch_start in tqdm(range(0, total_cells, batch_size), desc=\"Processing 3D cell batches\"):\n",
    "            batch_end = min(batch_start + batch_size, total_cells)\n",
    "            batch_ids = cell_ids[batch_start:batch_end]\n",
    "            \n",
    "            # Process each cell in the batch\n",
    "            for cell_idx in range(len(batch_ids)):\n",
    "                cell_id = batch_ids[cell_idx].item()\n",
    "                \n",
    "                # Create binary mask for this cell\n",
    "                with torch.no_grad():  # Reduce memory usage\n",
    "                    cell_mask = (mask_tensor == cell_id).bool()\n",
    "                    cell_volume = torch.sum(cell_mask).item()\n",
    "                    \n",
    "                    if cell_volume == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    # Calculate 3D centroid\n",
    "                    z_indices, y_indices, x_indices = torch.where(cell_mask)\n",
    "                    centroid_z = torch.mean(z_indices.float()).item()\n",
    "                    centroid_y = torch.mean(y_indices.float()).item()\n",
    "                    centroid_x = torch.mean(x_indices.float()).item()\n",
    "                    \n",
    "                    # Get z-range\n",
    "                    min_z = torch.min(z_indices).item()\n",
    "                    max_z = torch.max(z_indices).item()\n",
    "                \n",
    "                cell_data = {\n",
    "                    'label': int(cell_id),\n",
    "                    'area': int(cell_volume),  # Use volume for area to maintain compatibility\n",
    "                    'volume': int(cell_volume),  # Also include explicit volume\n",
    "                    'centroid': (float(centroid_y), float(centroid_x)),  # 2D-style centroid for compatibility\n",
    "                    'centroid_3d': (float(centroid_z), float(centroid_y), float(centroid_x)),\n",
    "                    'z_range': (int(min_z), int(max_z)),\n",
    "                    'ctcf': {},\n",
    "                    'mean': {},\n",
    "                    'total': {},\n",
    "                    'bg_value': {},\n",
    "                    'c_positive': {}  # Add positive cell counting\n",
    "                }\n",
    "                \n",
    "                # Process all channels\n",
    "                for ch in range(image_tensor.shape[3]):\n",
    "                    with torch.no_grad():  # Reduce memory usage\n",
    "                        # Handle background calculation for 3D data\n",
    "                        channel_data = image_tensor[:, :, :, ch]\n",
    "                        \n",
    "                        # Calculate bg_value for this channel\n",
    "                        bg_value = bg_models[ch]['mean'] if ch in bg_models else 0                            \n",
    "                        cell_data['bg_value'][ch] = float(bg_value)\n",
    "                        \n",
    "                        # GPU-accelerated measurements for 3D data\n",
    "                        cell_voxels = torch.masked_select(channel_data, cell_mask)\n",
    "                        total_intensity = torch.sum(cell_voxels).item()\n",
    "                        mean_intensity = torch.mean(cell_voxels).item() if cell_voxels.numel() > 0 else 0\n",
    "                        ctcf = total_intensity - (cell_volume * bg_value)\n",
    "                        \n",
    "                        cell_data['total'][ch] = float(total_intensity)\n",
    "                        cell_data['mean'][ch] = float(mean_intensity)\n",
    "                        cell_data['ctcf'][ch] = float(ctcf)\n",
    "                        \n",
    "                        # Determine if cell is positive for this channel\n",
    "                        threshold = thresholds[ch]\n",
    "                        cell_data['c_positive'][ch] = bool(mean_intensity > threshold)\n",
    "                \n",
    "                measurements.append(cell_data)\n",
    "            \n",
    "            # Free GPU memory after each batch\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        cells_per_sec = total_cells / (total_time + 1e-6)\n",
    "        print(f\"GPU 3D CTCF measurement complete: {total_cells} cells in {total_time:.2f}s ({cells_per_sec:.2f} cells/sec)\")\n",
    "        \n",
    "        return measurements\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU memory error for 3D data: {str(e)}. Falling back to CPU.\")\n",
    "        traceback.print_exc()\n",
    "        return measure_cells_ctcf_3d_cpu(image, cell_masks, bg_models, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder-Wise Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image_for_cellpose(image, config, bg_models):\n",
    "    \"\"\"Prepare image for CellPose segmentation with background subtraction\"\"\"\n",
    "    if config.get('cellpose_model') == 'nuclei_only':\n",
    "        nuc_channel_idx = config.get('nucleus_channel', 1) - 1\n",
    "        img_to_segment = image[...,nuc_channel_idx].copy()\n",
    "        \n",
    "        # Apply background subtraction if available\n",
    "        if nuc_channel_idx in bg_models:\n",
    "            ch_mean = bg_models[nuc_channel_idx]['mean']\n",
    "            img_to_segment = np.clip(img_to_segment - ch_mean, 0, None)\n",
    "            \n",
    "        return img_to_segment\n",
    "    \n",
    "    elif config.get('cellpose_model') == 'cyto3':\n",
    "        # Use cytoplasm and nucleus channels\n",
    "        cyto_channel_idx = config.get('cytoplasm_channel', 4) - 1\n",
    "        nuc_channel_idx = config.get('nucleus_channel', 1) - 1\n",
    "        \n",
    "        # Create a 2-channel image for CellPose\n",
    "        img_to_segment = np.stack([\n",
    "            image[...,nuc_channel_idx].copy(), \n",
    "            image[...,cyto_channel_idx].copy()\n",
    "        ], axis=-1)\n",
    "        \n",
    "        # Apply background subtraction if available\n",
    "        if nuc_channel_idx in bg_models:\n",
    "            ch_mean = bg_models[nuc_channel_idx]['mean']\n",
    "            img_to_segment[...,0] = np.clip(img_to_segment[...,0] - ch_mean, 0, None)\n",
    "            \n",
    "        if cyto_channel_idx in bg_models:\n",
    "            ch_mean = bg_models[cyto_channel_idx]['mean']\n",
    "            img_to_segment[...,1] = np.clip(img_to_segment[...,1] - ch_mean, 0, None)\n",
    "            \n",
    "        return img_to_segment\n",
    "    \n",
    "    elif config.get('cellpose_model') == 'cpsam':\n",
    "        # Default case: use all channels of interest\n",
    "        segmentation_channels = config.get('segmentation_channels', list(range(image.shape[-1])))\n",
    "        # print(f\"Using custom segmentation with channels: {[ch+1 for ch in segmentation_channels]}\")\n",
    "\n",
    "        # Create a multi-channel image with the channels of interest\n",
    "        img_to_segment = np.stack([image[...,ch].copy() for ch in segmentation_channels], axis=-1)\n",
    "\n",
    "        # Apply background subtraction if available\n",
    "        for i, ch in enumerate(segmentation_channels):\n",
    "            if ch in bg_models:\n",
    "                ch_mean = bg_models[ch]['mean']\n",
    "                img_to_segment[...,i] = np.clip(img_to_segment[...,i] - ch_mean, 0, None)\n",
    "                # print(f\"Applied background subtraction to channel {ch+1} (mean: {ch_mean:.2f})\")\n",
    "\n",
    "        return img_to_segment\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported CellPose model: {config.get('cellpose_model')}. \"\n",
    "                         \"Please specify 'nuclei_only', 'cyto3', or 'cpsam'.\")\n",
    "    \n",
    "def process_experiment_folder(experiment_folder, config, results_dir=None):\n",
    "    \"\"\"\n",
    "    Process a single experiment folder containing TIF/TIFF files\n",
    "    \n",
    "    Parameters:\n",
    "    - experiment_folder: Path to folder containing TIF/TIFF files\n",
    "    - config: Configuration dictionary\n",
    "    - results_dir: Optional custom results directory (if None, one will be created)\n",
    "    \n",
    "    Returns:\n",
    "    - Path to results directory\n",
    "    \"\"\"\n",
    "    # Create results directory if not provided\n",
    "    if results_dir is None:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        exp_name = os.path.basename(experiment_folder)\n",
    "        results_dir = os.path.join(experiment_folder, f\"{exp_name}_Analysis_{timestamp}\")\n",
    "    \n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Get all TIFF images in experiment folder (no CZI handling)\n",
    "    image_files = [f for f in os.listdir(experiment_folder) \n",
    "                  if f.endswith(('.tif', '.tiff')) and not f.startswith('.')]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"No TIF/TIFF files found in {experiment_folder}\")\n",
    "        print(\"Note: If you have CZI files, please extract them to TIFF first using external tools\")\n",
    "        return results_dir\n",
    "        \n",
    "    print(f\"Found {len(image_files)} TIFF files to process in {experiment_folder}\")\n",
    "    \n",
    "    # Create list of image paths\n",
    "    all_image_paths = [os.path.join(experiment_folder, f) for f in image_files]\n",
    "        \n",
    "    print(f\"Total images to process: {len(all_image_paths)}\")\n",
    "\n",
    "    cp_model = config.get('cellpose_model', 'cpsam')  # Default to 'cpsam' if not specified\n",
    "    print(f\"Initializing CellPose model {cp_model}...\")\n",
    "    cellpose_model = models.CellposeModel(gpu=config.get('use_gpu', True), pretrained_model= cp_model)\n",
    "\n",
    "    # Extract configuration\n",
    "    is_3d = config.get('use_3d', False)\n",
    "    # Check if quick filtering is enabled instead of alignment\n",
    "    b_quick_filtering = config.get('quick_size_filtering', False)\n",
    "    # Check the nuclei_segmentation method\n",
    "    nuclei_method = config.get('nuclei_segmentation_method', 'background_mask')  # 'background_mask','threshold', 'cellpose'\n",
    "    print(f\"Using {nuclei_method} method for nuclei segmentation...(CellPose will be used for cells)\")\n",
    "\n",
    "    # Process in batches\n",
    "    batch_size = config.get('batch_size', 4)\n",
    "    all_results = []\n",
    "    \n",
    "    for batch_idx in range(0, len(all_image_paths), batch_size):\n",
    "        batch_paths = all_image_paths[batch_idx:batch_idx + batch_size]\n",
    "        \n",
    "        print(f\"Processing batch {batch_idx//batch_size + 1}/{(len(all_image_paths) + batch_size - 1)//batch_size} \"\n",
    "             f\"({len(batch_paths)} images)\")\n",
    "        \n",
    "        # Force cleanup before each batch\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # 1. LOAD BATCH IMAGES\n",
    "        loaded_images = []\n",
    "        for path in tqdm(batch_paths, desc=\"Loading images\", leave=False):\n",
    "            try:\n",
    "                image = tiff.imread(path)\n",
    "                img_name = os.path.basename(path)\n",
    "                \n",
    "                # Move the shortest axis (channels) to the last index\n",
    "                if is_3d:\n",
    "                    # For 3D, image shape should be (Z, Y, X, C)\n",
    "                    dims = list(image.shape)\n",
    "                    if min(dims) < 5:  # Likely channel dimension if small\n",
    "                        channel_axis = dims.index(min(dims))\n",
    "                        image = np.moveaxis(image, channel_axis, -1)\n",
    "                    else:\n",
    "                        # Assume standard ordering Z,Y,X and add channel dimension if needed\n",
    "                        if len(image.shape) == 3:\n",
    "                            image = image[..., np.newaxis]  # Add channel dimension\n",
    "                else:\n",
    "                    # Standard 2D case\n",
    "                    shortest_axis = np.argmin(image.shape)\n",
    "                    image = np.moveaxis(image, shortest_axis, -1)\n",
    "                \n",
    "                loaded_images.append({\n",
    "                    'path': path,\n",
    "                    'name': img_name,\n",
    "                    'image': image\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {os.path.basename(path)}: {str(e)}\")\n",
    "        \n",
    "        if not loaded_images:\n",
    "            continue\n",
    "        \n",
    "        # For very large 3D volumes, use more aggressive garbage collection\n",
    "        if is_3d and config.get('aggressive_gc', False):\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        # 2. PREPARE FOR BATCH PROCESSING\n",
    "        cellpose_inputs = []\n",
    "        bg_models_by_image = {}\n",
    "        \n",
    "        # Process background sequentially for each image\n",
    "        for img_data in loaded_images:\n",
    "            path = img_data['path']\n",
    "            image = img_data['image']\n",
    "            img_name = img_data['name']\n",
    "            img_base = os.path.splitext(img_name)[0]\n",
    "            \n",
    "            # Calculate background using GMM fitting\n",
    "            bg_models = estimate_background_gmm(image, config, n_components=2, sample_ratio=0.05, \n",
    "                                max_iter=100, max_components=6)\n",
    "\n",
    "            if config.get('visualize_bg', True):\n",
    "                for ch_idx in range(image.shape[-1]):\n",
    "                    visualize_background_mask(\n",
    "                        image[..., ch_idx], \n",
    "                        bg_models[ch_idx],\n",
    "                        os.path.join(results_dir, f\"{img_base}_bg_mask_ch{ch_idx+1}.png\")\n",
    "                    )\n",
    "                       \n",
    "            # Store background models\n",
    "            bg_models_by_image[path] = bg_models\n",
    "            \n",
    "            # Prepare image for CellPose and track channel mapping\n",
    "            prepared_img = prepare_image_for_cellpose(image, config, bg_models)\n",
    "            \n",
    "            # Determine the nuclei channel index in the prepared image\n",
    "            nuclei_channel_idx_original = config.get('nucleus_channel', 1) - 1\n",
    "            \n",
    "            # Get the channel mapping from prepare_image_for_cellpose\n",
    "            if config.get('cellpose_model') == 'nuclei_only':\n",
    "                nuclei_channel_idx_prepared = 0  # Single channel, nuclei is at index 0\n",
    "            elif config.get('cellpose_model') == 'cyto3':\n",
    "                nuclei_channel_idx_prepared = 0  # First channel is nuclei in cyto3 format\n",
    "            else:\n",
    "                # For custom segmentation_channels, find where the original nuclei channel ended up\n",
    "                segmentation_channels = config.get('segmentation_channels', list(range(image.shape[-1])))\n",
    "                try:\n",
    "                    nuclei_channel_idx_prepared = segmentation_channels.index(nuclei_channel_idx_original)\n",
    "                except ValueError:\n",
    "                    # Nuclei channel not in segmentation channels, use first channel as fallback\n",
    "                    print(f\"Warning: Nuclei channel {nuclei_channel_idx_original+1} not in segmentation channels. Using first channel.\")\n",
    "                    nuclei_channel_idx_prepared = 0\n",
    "            \n",
    "            # Apply downsampling if needed\n",
    "            if config.get('downsample_factor', 1.0) < 1.0:\n",
    "                original_shape = prepared_img.shape[:3] if is_3d else prepared_img.shape[:2]\n",
    "                prepared_img = resample_image(\n",
    "                    prepared_img,\n",
    "                    config.get('downsample_factor')\n",
    "                )\n",
    "                \n",
    "                cellpose_inputs.append({\n",
    "                    'image': prepared_img,\n",
    "                    'orig_path': path,\n",
    "                    'orig_shape': original_shape,\n",
    "                    'nuclei_channel_idx': nuclei_channel_idx_prepared  # Store the correct index\n",
    "                })\n",
    "            else:\n",
    "                cellpose_inputs.append({\n",
    "                    'image': prepared_img,\n",
    "                    'orig_path': path,\n",
    "                    'orig_shape': image.shape[:3] if is_3d else image.shape[:2],\n",
    "                    'nuclei_channel_idx': nuclei_channel_idx_prepared  # Store the correct index\n",
    "                })\n",
    "        \n",
    "        # 3. BATCH SEGMENTATION WITH CELLPOSE\n",
    "        print(\"Running CellPose segmentation in batch mode...\")\n",
    "        cell_masks = {}\n",
    "        nuclei_masks = {}\n",
    "        \n",
    "        # Process batch group with CellPose\n",
    "        ## Stack images for batch processing\n",
    "        ## Note: Cellpose expects images in (Y,X,C) format for 2D or (Z,Y,X,C) for 3D\n",
    "        batch_images = [item['image'] for item in cellpose_inputs]\n",
    "        batch_paths = [item['orig_path'] for item in cellpose_inputs]\n",
    "        \n",
    "        # Extract nuclei images using the correct channel indices\n",
    "        batch_images_nuclei = []\n",
    "        if not b_quick_filtering:\n",
    "            for item in cellpose_inputs:\n",
    "                nuclei_idx = item['nuclei_channel_idx']\n",
    "                if nuclei_idx < item['image'].shape[-1]:\n",
    "                    batch_images_nuclei.append(item['image'][..., nuclei_idx])\n",
    "                else:\n",
    "                    # Fallback to first channel if index is out of range\n",
    "                    print(f\"Warning: Nuclei channel index {nuclei_idx} out of range, using channel 0\")\n",
    "                    batch_images_nuclei.append(item['image'][..., 0])\n",
    "            \n",
    "        try:\n",
    "            # Run batch segmentation for cells\n",
    "            print(f\"Segmenting cells... with channels {config.get('segmentation_channels', 'all')}\")\n",
    "            masks, _, _ = cellpose_model.eval(\n",
    "                batch_images,\n",
    "                normalize=True,\n",
    "                do_3D=is_3d,\n",
    "                flow_threshold=config.get('flow_threshold', 0.4),\n",
    "                cellprob_threshold=config.get('cellprob_threshold', 0.0),\n",
    "                anisotropy=config.get('anisotropy', 3.0),\n",
    "            )\n",
    "            \n",
    "            if b_quick_filtering:\n",
    "                # Create empty nuclei masks for consistency\n",
    "                masks_nuclei = []\n",
    "                for i,item in enumerate(batch_paths):\n",
    "                    masks_nuclei.append(np.zeros_like(masks[i]))\n",
    "            else:\n",
    "                # Segment nuclei using selected method\n",
    "                if nuclei_method == 'background_mask':\n",
    "                    print(\"Segmenting nuclei using background masks inversion...\")\n",
    "                    # Extract background models for nuclei channel\n",
    "                    bg_models_nuclei = []\n",
    "                    nuclei_channel_idx = config.get('nucleus_channel', 1) - 1\n",
    "                    \n",
    "                    for img_data in loaded_images:\n",
    "                        path = img_data['path']\n",
    "                        bg_models = bg_models_by_image[path]\n",
    "                        bg_models_nuclei.append(bg_models[nuclei_channel_idx])\n",
    "                    \n",
    "                    masks_nuclei = segment_nuclei_from_background_mask(bg_models_nuclei, config )\n",
    "                    \n",
    "                elif nuclei_method == 'threshold':\n",
    "                    print(\"Segmenting nuclei using thresholding method...\")\n",
    "                    masks_nuclei = segment_nuclei_threshold(batch_images_nuclei, config)\n",
    "                else:\n",
    "                    print(f\"Segmenting nuclei... with index {cellpose_inputs[0]['nuclei_channel_idx']}\")\n",
    "                    masks_nuclei, _ , _ = cellpose_model.eval(\n",
    "                        batch_images_nuclei,\n",
    "                        normalize=True,\n",
    "                        do_3D=is_3d,\n",
    "                        flow_threshold=config.get('flow_threshold', 0.4),\n",
    "                        cellprob_threshold=config.get('cellprob_threshold', 0.0),\n",
    "                        anisotropy=config.get('anisotropy', 3.0),\n",
    "                    )\n",
    "            \n",
    "            # Handle upscaling if needed\n",
    "            for i, path in enumerate(batch_paths):\n",
    "                # Get original shape for this image\n",
    "                for input_data in cellpose_inputs:\n",
    "                    if input_data['orig_path'] == path:\n",
    "                        orig_shape = input_data['orig_shape']\n",
    "                        \n",
    "                        # Upscale mask if downsampled\n",
    "                        if config.get('downsample_factor', 1.0) < 1.0:\n",
    "                            cell_masks[path] = resize(masks[i], orig_shape, \n",
    "                                                    order=0, preserve_range=True).astype(np.int32)\n",
    "                            nuclei_masks[path] = resize(masks_nuclei[i], orig_shape,\n",
    "                                                        order=0, preserve_range=True).astype(np.int32)\n",
    "                        else:\n",
    "                            cell_masks[path] = masks[i]\n",
    "                            nuclei_masks[path] = masks_nuclei[i]\n",
    "                        break\n",
    "            \n",
    "            # Clean up memory\n",
    "            del masks, masks_nuclei\n",
    "            gc.collect()\n",
    "            \n",
    "            if b_quick_filtering:\n",
    "                print(\"Using quick size filtering instead of nuclei alignment...\")\n",
    "                # Apply size filtering to cell masks\n",
    "                filtered_masks = {}\n",
    "                for path in tqdm(batch_paths, desc=\"Filtering masks by size\"):\n",
    "                    if path in cell_masks:\n",
    "                        filtered_masks[path] = filter_masks_by_size(\n",
    "                            cell_masks[path], \n",
    "                            config=config\n",
    "                        )\n",
    "                    else:\n",
    "                        # Get original shape for creating empty mask\n",
    "                        for input_data in cellpose_inputs:\n",
    "                            if input_data['orig_path'] == path:\n",
    "                                orig_shape = input_data['orig_shape']\n",
    "                                filtered_masks[path] = np.zeros(orig_shape, dtype=np.int32)\n",
    "                                break\n",
    "                \n",
    "                # Store original cell masks and use filtered masks for measurements\n",
    "                cell_masks_orig = cell_masks.copy()\n",
    "                cell_masks = filtered_masks\n",
    "\n",
    "            else:\n",
    "                # Align cell masks with nuclei masks to create combined segmentation\n",
    "                print(\"Aligning cell masks with nuclei masks (nucleus-based approach)...\")\n",
    "                aligned_masks = {}\n",
    "\n",
    "                for path in tqdm(batch_paths, desc = \"Aligning masks\"):\n",
    "                    if path in cell_masks and path in nuclei_masks:\n",
    "                        aligned_masks[path] = align_cell_masks_to_nuclei(\n",
    "                            nuclei_masks[path],\n",
    "                            cell_masks[path], \n",
    "                            is_3d=is_3d\n",
    "                        )\n",
    "                    else:\n",
    "                        # If one of the masks is missing, use nuclei masks as foundation\n",
    "                        aligned_masks[path] = nuclei_masks.get(path, np.zeros_like(cell_masks.get(path, None)))\n",
    "\n",
    "                # Store the original cell masks for later use                    \n",
    "                cell_masks_orig = cell_masks.copy() \n",
    "                # Use the aligned masks for measurements\n",
    "                cell_masks = aligned_masks\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Batch segmentation error: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "            \n",
    "            # Create empty masks for failures\n",
    "            for input_data in cellpose_inputs:\n",
    "                path = input_data['orig_path']\n",
    "                orig_shape = input_data['orig_shape']\n",
    "                cell_masks[path] = np.zeros(orig_shape, dtype=np.int32)\n",
    "\n",
    "        print(\"Batch segmentation complete!\")\n",
    "    \n",
    "        # 4. PARALLEL CTCF MEASUREMENT AND RESULT GENERATION\n",
    "        batch_results = []\n",
    "        \n",
    "        # Process each image (CTCF calculation can be parallel)\n",
    "        for img_data in loaded_images:\n",
    "            path = img_data['path']\n",
    "            img_name = img_data['name']\n",
    "            img_base = os.path.splitext(img_name)[0]\n",
    "            \n",
    "            if path in cell_masks:\n",
    "                # Get mask and background models\n",
    "                masks = cell_masks[path]\n",
    "                masks_nuclei = nuclei_masks[path]\n",
    "                masks_cells_orig = cell_masks_orig[path]  # Original cell masks before alignment\n",
    "                bg_models = bg_models_by_image.get(path, {})\n",
    "                \n",
    "                # Count original objects before alignment\n",
    "                original_nuclei_count = len(np.unique(masks_nuclei)) - 1  # Subtract background\n",
    "                original_cells_count = len(np.unique(masks_cells_orig)) - 1  # Subtract background\n",
    "                \n",
    "                try:\n",
    "\n",
    "                    # Measure cells with GPU or CPU\n",
    "                    cell_measurements = measure_cells(\n",
    "                        img_data['image'], masks, bg_models, config\n",
    "                    )\n",
    "\n",
    "                    # Define channels of interest from config\n",
    "                    channels_of_interest = config.get('channels_of_interest', list(range(img_data['image'].shape[-1])))\n",
    "\n",
    "                    # Save cell measurements to CSV with additional metadata\n",
    "                    cell_df = pd.DataFrame([\n",
    "                        {\n",
    "                            'image': img_name,\n",
    "                            'cell_id': i,\n",
    "                            'area': cell['area'] if 'area' in cell else cell.get('volume', 0),\n",
    "                            **{f'channel_{ch+1}_ctcf': cell['ctcf'][ch] for ch in channels_of_interest},\n",
    "                            **{f'channel_{ch+1}_mean': cell['mean'][ch] for ch in channels_of_interest},\n",
    "                            'centroid_x': cell['centroid'][1] if 'centroid' in cell else cell.get('centroid_3d', [0, 0, 0])[2],\n",
    "                            'centroid_y': cell['centroid'][0] if 'centroid' in cell else cell.get('centroid_3d', [0, 0, 0])[1],\n",
    "                            **{f'positive': cell['c_positive'][ch] for ch in channels_of_interest} \n",
    "                        }\n",
    "                        for i, cell in enumerate(cell_measurements)\n",
    "                    ])\n",
    "                    cell_df.to_csv(os.path.join(results_dir, f\"{img_base}_cells.csv\"), index=False)\n",
    "                            \n",
    "                    # Create visualization if configured\n",
    "                    if config.get('visualize_segmentation', True):\n",
    "                        create_visualization(\n",
    "                            img_data['image'],\n",
    "                            masks,\n",
    "                            cell_measurements,\n",
    "                            os.path.join(results_dir, f\"{img_name}_analysis.png\"),\n",
    "                            debug=config.get('debug', False)\n",
    "                        )\n",
    "                    \n",
    "                    # Create QC region images if configured\n",
    "                    if config.get('save_qc_regions', True):\n",
    "                        save_segmentation_qc_images(\n",
    "                            img_data['image'],\n",
    "                            masks,\n",
    "                            results_dir,\n",
    "                            img_name,\n",
    "                            config\n",
    "                        )\n",
    "\n",
    "                    # Create nuclei visualization if configured\n",
    "                    if config.get('visualize_nuclei', True):\n",
    "                        create_visualization(\n",
    "                            img_data['image'],\n",
    "                            masks_nuclei,\n",
    "                            cell_measurements,\n",
    "                            os.path.join(results_dir, f\"{img_name}_nuclei.png\"),\n",
    "                            debug=config.get('debug', False)\n",
    "                        )\n",
    "\n",
    "                    # Cerate nuclei QC region images if configured\n",
    "                    if config.get('save_nuclei_qc_regions', True):\n",
    "                        nuclei_qc_dir = os.path.join(results_dir, \"nuclei_qc\")\n",
    "                        os.makedirs(nuclei_qc_dir, exist_ok=True)\n",
    "                        save_segmentation_qc_images(\n",
    "                            img_data['image'],\n",
    "                            masks_nuclei,\n",
    "                            nuclei_qc_dir,\n",
    "                            img_name,\n",
    "                            config,\n",
    "                        )\n",
    "\n",
    "                    if config.get('save_cellpose_masks', True):\n",
    "                        # Save cellpose masks\n",
    "                        mask_cells_path = os.path.join(results_dir, f\"{img_base}_cell_masks.tif\")\n",
    "                        mask_nuclei_path = os.path.join(results_dir, f\"{img_base}_nuclei_masks.tif\")\n",
    "                        mask_cells_orig_path = os.path.join(results_dir, f\"{img_base}_cell_masks_orig.tif\")\n",
    "\n",
    "                        save_mask_as_tiff(masks, mask_cells_path)\n",
    "                        save_mask_as_tiff(masks_nuclei, mask_nuclei_path)\n",
    "                        save_mask_as_tiff(cell_masks_orig[path], mask_cells_orig_path)\n",
    "                    \n",
    "                    # Summarize results\n",
    "                    channels_of_interest = config.get('channels_of_interest', \n",
    "                                                   list(range(img_data['image'].shape[-1])))\n",
    "                    summary = {\n",
    "                        'image_name': img_name,\n",
    "                        'total_cells_aligned': len(cell_measurements),\n",
    "                        'original_nuclei_detected': original_nuclei_count,\n",
    "                        'original_cells_detected': original_cells_count,\n",
    "                        'nuclei_cell_ratio': original_cells_count / original_nuclei_count if original_nuclei_count > 0 else 0,\n",
    "                    }\n",
    "                    \n",
    "                    # Add channel statistics with outlier robustness (1st-99th percentile)\n",
    "                    for ch in channels_of_interest:\n",
    "                        if ch < img_data['image'].shape[-1]:\n",
    "                            ch_ctcf = [cell['ctcf'][ch] for cell in cell_measurements]\n",
    "                            positive_counts_ch = np.sum([cell['c_positive'][ch] for cell in cell_measurements])\n",
    "                            if ch_ctcf:\n",
    "                                # Calculate percentiles for trimming outliers\n",
    "                                p1 = np.percentile(ch_ctcf, 1)\n",
    "                                p99 = np.percentile(ch_ctcf, 99)\n",
    "                                \n",
    "                                # Clip values to 1st and 99th percentiles instead of filtering\n",
    "                                trimmed_ctcf = np.clip(ch_ctcf, p1, p99)\n",
    "                                \n",
    "                                summary[f'channel_{ch+1}_n_pos'] = positive_counts_ch\n",
    "                                summary[f'channel_{ch+1}_mean_ctcf'] = np.mean(trimmed_ctcf)\n",
    "                                summary[f'channel_{ch+1}_median_ctcf'] = np.median(trimmed_ctcf)\n",
    "                                summary[f'channel_{ch+1}_std_ctcf'] = np.std(trimmed_ctcf)\n",
    "\n",
    "                            else:\n",
    "                                summary[f'channel_{ch+1}_n_pos'] = 0\n",
    "                                summary[f'channel_{ch+1}_mean_ctcf'] = 0\n",
    "                                summary[f'channel_{ch+1}_median_ctcf'] = 0\n",
    "                                summary[f'channel_{ch+1}_std_ctcf'] = 0\n",
    "\n",
    "                    batch_results.append(summary)\n",
    "                    \n",
    "                    # Clean up memory\n",
    "                    del cell_measurements, cell_df\n",
    "                    gc.collect()\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {img_name}: {str(e)}\")\n",
    "                    batch_results.append({\n",
    "                        'image_name': img_name,\n",
    "                        'error': str(e),\n",
    "                        'total_cells': 0\n",
    "                    })\n",
    "            else:\n",
    "                batch_results.append({\n",
    "                    'image_name': img_name,\n",
    "                    'error': \"No mask generated\",\n",
    "                    'total_cells': 0\n",
    "                })\n",
    "        \n",
    "        # Append batch results to all results\n",
    "        all_results.extend(batch_results)\n",
    "        \n",
    "        # Clean up batch memory\n",
    "        del loaded_images, cellpose_inputs, cell_masks, bg_models_by_image, batch_results\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache() if config.get('use_gpu', True) else None\n",
    "    \n",
    "    # Save experiment results\n",
    "    if all_results:\n",
    "        exp_df = pd.DataFrame(all_results)\n",
    "        exp_df.to_csv(os.path.join(results_dir, \"experiment_results.csv\"), index=False)\n",
    "    \n",
    "    print(f\"Experiment processing complete. Results saved to: {results_dir}\")\n",
    "    return results_dir\n",
    "\n",
    "def process_experiments_optimized(main_directory, config):\n",
    "    \"\"\"\n",
    "    Process experiments in a main directory or a single experiment folder\n",
    "    \n",
    "    Parameters:\n",
    "    - main_directory: Path to main directory with multiple experiment folders\n",
    "                     OR path to a single experiment folder with TIF/TIFF files\n",
    "    - config: Configuration dictionary\n",
    "    \n",
    "    Returns:\n",
    "    - Path to results directory\n",
    "    \"\"\"\n",
    "    # Check if the main_directory contains TIF/TIFF files directly\n",
    "    tif_files = [f for f in os.listdir(main_directory) \n",
    "                if f.endswith(('.tif', '.tiff')) and not f.startswith('.')]\n",
    "    \n",
    "    if tif_files:\n",
    "        # This is a single experiment folder - process it directly\n",
    "        print(f\"Processing single experiment folder: {main_directory}\")\n",
    "        return process_experiment_folder(main_directory, config)\n",
    "    \n",
    "    # Create results directory for multiple experiments\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_dir = os.path.join(main_directory, f\"CTCF_Analysis_{timestamp}\")\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Find all experiment folders\n",
    "    experiment_folders = [f.path for f in os.scandir(main_directory) if f.is_dir() \n",
    "                         and not f.name.startswith('.') and not \"CTCF_Analysis\" in f.name]\n",
    "    \n",
    "    # Process each experiment folder\n",
    "    for experiment_folder in experiment_folders:\n",
    "        exp_name = os.path.basename(experiment_folder)\n",
    "        print(f\"\\nProcessing experiment: {exp_name}\")\n",
    "        \n",
    "        # Create experiment results folder\n",
    "        exp_results_dir = os.path.join(results_dir, exp_name)\n",
    "        try:\n",
    "            # Process this experiment folder\n",
    "            process_experiment_folder(experiment_folder, config, results_dir=exp_results_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing experiment {exp_name}: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "            # Continue with next experiment\n",
    "            continue\n",
    "        \n",
    "    print(f\"All experiments processed. Results saved to: {results_dir}\")\n",
    "    return results_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop Section testing \n",
    "In this section the functions for testing on a small cropped picture of the image are dealigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_central_region(image, crop_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Crop the central region of an image for quick segmentation testing\n",
    "    \n",
    "    Parameters:\n",
    "    - image: The input image (H, W, C)\n",
    "    - crop_ratio: Size of the crop relative to original image (0.1 = 10%)\n",
    "    \n",
    "    Returns:\n",
    "    - cropped_image: The central cropped region\n",
    "    - crop_coords: (y_start, y_end, x_start, x_end) for reference\n",
    "    \"\"\"\n",
    "    # Get image dimensions\n",
    "    h, w, c = image.shape\n",
    "    \n",
    "    # Calculate crop size\n",
    "    crop_h = int(h * crop_ratio)\n",
    "    crop_w = int(w * crop_ratio)\n",
    "    \n",
    "    # Calculate central coordinates\n",
    "    center_y, center_x = h // 2, w // 2\n",
    "    \n",
    "    # Calculate crop boundaries\n",
    "    y_start = center_y - (crop_h // 2)\n",
    "    y_end = center_y + (crop_h // 2)\n",
    "    x_start = center_x - (crop_w // 2)\n",
    "    x_end = center_x + (crop_w // 2)\n",
    "    \n",
    "    # Ensure coordinates are within image bounds\n",
    "    y_start = max(0, y_start)\n",
    "    y_end = min(h, y_end)\n",
    "    x_start = max(0, x_start)\n",
    "    x_end = min(w, x_end)\n",
    "    \n",
    "    # Extract crop\n",
    "    cropped_image = image[y_start:y_end, x_start:x_end, :]\n",
    "    \n",
    "    return cropped_image, (y_start, y_end, x_start, x_end)    \n",
    "\n",
    "def test_segmentation_on_crop(image_path, output_dir, config, crop_ratio=0.1):\n",
    "        \"\"\"\n",
    "        Test segmentation on a central crop of an image\n",
    "        \n",
    "        Parameters:\n",
    "        - image_path: Path to the input image\n",
    "        - output_dir: Directory to save results\n",
    "        - config: Configuration dictionary\n",
    "        - crop_ratio: Size of the crop relative to original image (0.1 = 10%)\n",
    "        \n",
    "        Returns:\n",
    "        - Dictionary with segmentation results and parameters\n",
    "        \"\"\"\n",
    "        # Load image and normalize channels\n",
    "        image = tiff.imread(image_path)\n",
    "        img_name = os.path.basename(image_path)\n",
    "        img_base = os.path.splitext(img_name)[0]\n",
    "        \n",
    "        print(f\"\\nTesting segmentation on cropped region of: {img_name}\")\n",
    "        \n",
    "        # Move the shortest axis (channels) to the last index if needed\n",
    "        shortest_axis = np.argmin(image.shape)\n",
    "        image = np.moveaxis(image, shortest_axis, -1)\n",
    "        \n",
    "        # Crop central region\n",
    "        cropped_image, crop_coords = crop_central_region(image, crop_ratio)\n",
    "        y_start, y_end, x_start, x_end = crop_coords\n",
    "        \n",
    "        print(f\"Original image shape: {image.shape}\")\n",
    "        print(f\"Cropped region shape: {cropped_image.shape}\")\n",
    "        print(f\"Crop coordinates: (y={y_start}:{y_end}, x={x_start}:{x_end})\")\n",
    "        \n",
    "        # Create output directory for this test if it doesn't exist\n",
    "        crop_output_dir = os.path.join(output_dir, f\"{img_base}_crop_test\")\n",
    "        os.makedirs(crop_output_dir, exist_ok=True)\n",
    "        \n",
    "        # 1. Estimate background for the cropped region\n",
    "        print(\"Estimating background using GMM...\")\n",
    "        bg_models = {}\n",
    "        for ch in range(cropped_image.shape[-1]):\n",
    "            channel_data = cropped_image[:,:,ch].copy()\n",
    "            bg_models[ch] = estimate_background_gmm(channel_data)\n",
    "            \n",
    "            # Save background mask visualization\n",
    "            visualize_background_mask(channel_data, bg_models[ch], \n",
    "                                     os.path.join(crop_output_dir, f\"crop_bg_mask_ch{ch+1}.png\"))\n",
    "        \n",
    "        # 2. Segment cells on the cropped region\n",
    "        cell_masks = segment_cells_with_downsampling(cropped_image, config, bg_models)\n",
    "        \n",
    "        # 3. Measure CTCF for each cell in the cropped region\n",
    "        cell_measurements = measure_cells(cropped_image, cell_masks, bg_models)\n",
    "        \n",
    "        # Save visualization of the segmentation results\n",
    "        create_visualization(cropped_image, cell_masks, cell_measurements, \n",
    "                            os.path.join(crop_output_dir, f\"{img_base}_crop_segmentation.png\"), \n",
    "                            debug=True)\n",
    "        \n",
    "        # Create a comparison visualization showing where the crop is from\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Show original with crop region highlighted\n",
    "        plt.subplot(1, 2, 1)\n",
    "        # Use first channel for display or create a composite\n",
    "        if image.shape[-1] >= 3:\n",
    "            display_img = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "            for i in range(min(3, image.shape[-1])):\n",
    "                ch_data = exposure.equalize_adapthist(image[:,:,i])\n",
    "                display_img[:,:,i] = ch_data\n",
    "        else:\n",
    "            display_img = exposure.equalize_adapthist(image[:,:,0])\n",
    "        \n",
    "        plt.imshow(display_img)\n",
    "        plt.gca().add_patch(plt.Rectangle((x_start, y_start), \n",
    "                                         x_end - x_start, \n",
    "                                         y_end - y_start, \n",
    "                                         fill=False, \n",
    "                                         edgecolor='red', \n",
    "                                         linewidth=2))\n",
    "        plt.title('Original Image with Crop Region')\n",
    "        \n",
    "        # Show the cropped region with segmentation overlay\n",
    "        plt.subplot(1, 2, 2)\n",
    "        # Create overlay of segmentation on image\n",
    "        if cropped_image.shape[-1] >= 3:\n",
    "            crop_display = np.zeros((cropped_image.shape[0], cropped_image.shape[1], 3))\n",
    "            for i in range(min(3, cropped_image.shape[-1])):\n",
    "                ch_data = exposure.equalize_adapthist(cropped_image[:,:,i])\n",
    "                crop_display[:,:,i] = ch_data\n",
    "        else:\n",
    "            crop_display = exposure.equalize_adapthist(cropped_image[:,:,0])\n",
    "        \n",
    "        plt.imshow(crop_display)\n",
    "        # Add cell mask overlay\n",
    "        plt.imshow(cell_masks > 0, alpha=0.7, cmap='cool')\n",
    "        plt.title(f'Segmentation on Cropped Region ({len(cell_measurements)} cells)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(crop_output_dir, f\"{img_base}_crop_location.png\"), dpi=150)\n",
    "        plt.close()\n",
    "        \n",
    "        # Save cell measurements to CSV\n",
    "        cell_df = pd.DataFrame([\n",
    "            {\n",
    "                'cell_id': cell['label'],\n",
    "                'area': cell['area'],\n",
    "                **{f'channel_{ch+1}_ctcf': cell['ctcf'][ch] for ch in range(cropped_image.shape[-1])},\n",
    "                **{f'channel_{ch+1}_mean': cell['mean'][ch] for ch in range(cropped_image.shape[-1])},\n",
    "                'centroid_x': cell['centroid'][1],\n",
    "                'centroid_y': cell['centroid'][0]\n",
    "            }\n",
    "            for cell in cell_measurements\n",
    "        ])\n",
    "        cell_df.to_csv(os.path.join(crop_output_dir, f\"{img_base}_crop_cells.csv\"), index=False)\n",
    "        \n",
    "        # Return info about the test\n",
    "        return {\n",
    "            'image_name': img_name,\n",
    "            'crop_region': crop_coords,\n",
    "            'cell_count': len(cell_measurements),\n",
    "            'output_dir': crop_output_dir\n",
    "        }\n",
    "\n",
    "# Test segmentation on a cropped region before full processing\n",
    "def test_segmentation_parameters(image_path, config, crop_ratio=0.1):\n",
    "    \"\"\"Test segmentation parameters on a cropped region of an image\"\"\"\n",
    "    # Create a temporary output directory\n",
    "    output_dir = os.path.join(os.path.dirname(image_path), \"segmentation_tests\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Run the crop test\n",
    "    test_result = test_segmentation_on_crop(\n",
    "        image_path=image_path,\n",
    "        output_dir=output_dir,\n",
    "        config=config,\n",
    "        crop_ratio=crop_ratio\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n✓ Segmentation test complete!\")\n",
    "    print(f\"  - Found {test_result['cell_count']} cells in the cropped region\")\n",
    "    print(f\"  - Results saved to: {test_result['output_dir']}\")\n",
    "    print(\"\\nTIP: Review the results and adjust segmentation parameters in config as needed\")\n",
    "    \n",
    "    return test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Images\n",
    "In this section firstly the configuratin will be set for the segmentation, and a test can be done for an individual file. On the second part, a batch processing of multiple files can be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the configuration for the pipeline\n",
    "config = {\n",
    "    # Hardware settings\n",
    "    'use_gpu': True,  # Set to False to force CPU processing\n",
    "    'auto_detect_gpu': True,  # Auto-detect and use GPU if available\n",
    "\n",
    "    # Background Estimation settings\n",
    "    'use_bg_composite': True,  # Use a composite image for background estimation (faster)\n",
    "\n",
    "    # CellPose settings\n",
    "    'cellpose_model': 'cpsam',  # CellPose model to use ('cpsam', 'cyto2', 'cyto3', 'nuclei_only')\n",
    "    'segmentation_channels': [0, 1, 3],  # Channels for CellPose-SAM (cpsam) segmentation (Max 3)\n",
    "    'cytoplasm_channel': 4,  # Far Red channel for cytoplasm/membrane (Cyto3 - Model)\n",
    "    'nucleus_channel': 1,    # Blue channel (DAPI) for nuclei         (Cyto3 - Model)\n",
    "    'cell_diameter': 50.0,     # Approximate diameter in pixels       (Cyto3 - Model)\n",
    "    'flow_threshold': 0.4,   # Flow error threshold (all cells with errors below threshold are kept) (not used for 3D). Defaults to 0.4.\n",
    "    'cellprob_threshold': 0.0,  # All pixels with value above threshold kept for masks, decrease to find more and larger masks. Defaults to 0.0.\n",
    "    'downsample_factor': 2.0,  # Downsample factor for speed (1.0 = no downsampling)\n",
    "\n",
    "    # Alignment (Nuclei - Cell Setting)\n",
    "    'quick_size_filtering': True,       # Set to True to use size filtering instead of nuclei alignment\n",
    "    'filter_by_radius': True,           # True: filter by max extension radius, False: filter by pixel area\n",
    "    'cell_min_size': 4,                 # Minimum size (radius or area depending on filter_by_radius)\n",
    "    'cell_max_size': 100,                # Maximum size (radius or area depending on filter_by_radius)\n",
    "\n",
    "    # Nuclei segmentation settings\n",
    "    'nuclei_min_size': 5,  # Minimum size for nuclei segmentation\n",
    "    'nuclei_max_size': 1000,  # Maximum size for nuclei segmentation\n",
    "    'nuclei_gaussian_sigma': 1.0,  # Gaussian sigma for nuclei segmentation\n",
    "    'nuclei_segmentation_method' : 'cellpose' , # Method for nuclei segmentation ('threshold' or 'cellpose')\n",
    "    'nuclei_thresh_factor' : 1.0, # Adjust sensitivity\n",
    "    \n",
    "    # Visualization settings\n",
    "    'visualize_bg': False,  # Set to False if you don't want intermediate visualizations\n",
    "    'visualize_segmentation': False,  # Show segmentation results\n",
    "    'save_qc_regions': True,  # Save QC regions for review\n",
    "    'qc_region_size': 300,  # Size of the QC region in pixels\n",
    "    'visualize_nuclei': False,  # Show nuclei segmentation results\n",
    "    'save_nuclei_qc_regions': False,  # Save QC regions for nuclei segmentation\n",
    "    'save_cellpose_masks': False,  # Save CellPose masks as TIFF files\n",
    "    \n",
    "    # Analysis settings\n",
    "    'channels_of_interest': [0, 1, 2, 3],  # All channels to measure\n",
    "    'positive_threshold_method': 'bg_plus_std', # Method for positive thresholding ('bg_plus_std', 'percentile', 'otsu')\n",
    "    'positive_threshold_std_multiplier': 2.0, # Multiplier for background std in 'bg_plus_std' method\n",
    "    'positive_threshold_percentile': 95,  # Percentile for positive thresholding in 'percentile' method\n",
    "    \n",
    "    # Parallelization settings\n",
    "    'max_workers': min(os.cpu_count(), 16),  # Maximum number of parallel workers\n",
    "    'batch_size': 8,                         # Number of images to process in a batch\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_3d_params = {\n",
    "    # 3D specific parameters\n",
    "    'anisotropy': 3.0,  # Z-to-XY resolution ratio (common in microscopy)\n",
    "    'cell_diameter_3d': 30.0,  # Diameter in 3D (usually larger than 2D)\n",
    "    'use_3d': True,         # Flag to enable 3D processing (lowercase 'd')\n",
    "    'gpu_batch_size_3d': 2,  # Process fewer 3D images at once\n",
    "    \n",
    "    'z_downsampling': False,      # Whether to downsample in Z dimension \n",
    "    'aggressive_gc': True,        # More aggressive garbage collection for 3D\n",
    "}\n",
    "# Update your existing config\n",
    "config.update(config_3d_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropped segmentation and background substraction testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_test = select_folder()\n",
    "print(f'>>> Selected folder: {folder_path_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage in your script\n",
    "image_paths = glob.glob(os.path.join(folder_path_test, \"*.tiff\"))\n",
    "if len(image_paths) > 0:\n",
    "    # Test segmentation on first image before batch processing\n",
    "    test_result = test_segmentation_parameters(image_paths[0], config, crop_ratio=0.1)\n",
    "    \n",
    "else:\n",
    "    print(f\"No TIFF images found in {folder_path_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_folder = select_folder()\n",
    "print(f'>>> Selected folder: {exp_folder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process single experiment folder  \n",
    "results_dir = process_experiment_folder(exp_folder, config)\n",
    "print(f'>>> Experiment processing complete. Results saved to: {results_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".auto_img",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
