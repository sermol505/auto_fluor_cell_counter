{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideal Processing Pipeline for Consistent CTCF in Fluorescence Microscopy\n",
    "\n",
    "Here's a comprehensive pipeline for analyzing fluorescence microscopy images with consistent CTCF measurement across different conditions and microscopes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import necessary libraries\n",
    "import time, os, sys\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "import tifffile as tiff\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import measure, draw, exposure\n",
    "from skimage.transform import resize\n",
    "from skimage.segmentation import find_boundaries\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "import scipy.stats\n",
    "\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "from functools import partial\n",
    "from filelock import FileLock\n",
    "import torch\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 200\n",
    "mpl.use('Agg')  # Set non-interactive backend globally\n",
    "\n",
    "from AutoImgUtils import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version\n",
    "!nvidia-smi\n",
    "\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import core, utils, io, models, metrics, denoise\n",
    "from glob import glob\n",
    "\n",
    "use_GPU = core.use_gpu()\n",
    "yn = ['NO', 'YES']\n",
    "print(f'>>> GPU activated? {yn[use_GPU]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization functions\n",
    "Here the visualization functions are defined, that can be used to save plots regarding the background substraction as well as the segmentation results for quality control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_background_mask(channel_image, bg_model, output_path, n_components=3, enhance_contrast=True):\n",
    "    \"\"\"Visualize background mask from GMM model with distribution plots\"\"\"\n",
    "\n",
    "    # Detect if we're working with 3D data\n",
    "    is_3d = len(channel_image.shape) == 3 and channel_image.shape[0] > 1\n",
    "\n",
    "    if is_3d:\n",
    "        # 3D visualization setup (3x3 grid)\n",
    "        fig, axes = plt.subplots(3, 3, figsize=(18, 15), gridspec_kw={'height_ratios': [3, 3, 1]})\n",
    "        \n",
    "        # Get dimensions\n",
    "        z_depth, height, width = channel_image.shape\n",
    "        \n",
    "        # Show representative Z-slices\n",
    "        z_positions = [z_depth // 4, z_depth // 2, 3 * z_depth // 4]\n",
    "        slice_titles = [\"25% Z-Depth\", \"50% Z-Depth\", \"75% Z-Depth\"]\n",
    "        \n",
    "        # Row 1: Z-slices with background highlighted\n",
    "        for i, (z_pos, title) in enumerate(zip(z_positions, slice_titles)):\n",
    "            slice_img = channel_image[z_pos]\n",
    "            slice_mask = bg_model['mask'][z_pos] if len(bg_model['mask'].shape) == 3 else None\n",
    "\n",
    "            \n",
    "            # Enhance contrast for visualization if requested\n",
    "            if enhance_contrast:\n",
    "                p_low, p_high = 2, 98  # Percentiles for contrast stretching\n",
    "                display_img = exposure.rescale_intensity(\n",
    "                    slice_img,\n",
    "                    in_range=tuple(np.percentile(slice_img, (p_low, p_high))),\n",
    "                    out_range='dtype'\n",
    "                )\n",
    "            else:\n",
    "                display_img = slice_img\n",
    "            \n",
    "            # Display image slice\n",
    "            axes[0, i].imshow(display_img, cmap='gray')\n",
    "            axes[0, i].set_title(f'Original - {title}')\n",
    "            \n",
    "            # If we have a 3D mask, overlay it on the slice\n",
    "            if slice_mask is not None:\n",
    "                # Create RGB image for overlay\n",
    "                norm_img = (display_img - np.min(display_img)) / (np.max(display_img) - np.min(display_img))\n",
    "                rgb_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
    "                \n",
    "                # Highlight background in red\n",
    "                rgb_img[:,:,0][slice_mask] = 1.0  # Red\n",
    "                rgb_img[:,:,1][slice_mask] = 0.0  # Green\n",
    "                rgb_img[:,:,2][slice_mask] = 0.0  # Blue\n",
    "                \n",
    "                axes[0, i].imshow(rgb_img)\n",
    "            \n",
    "            axes[0, i].axis('off')\n",
    "        \n",
    "        # Row 2: Maximum Intensity Projections with background mask overlay\n",
    "        # XY projection (top view)\n",
    "        mip_xy = np.max(channel_image, axis=0)\n",
    "        mip_bg_xy = np.max(bg_model['mask'], axis=0) if len(bg_model['mask'].shape) == 3 else bg_model['mask']\n",
    "        \n",
    "        if enhance_contrast:\n",
    "            mip_xy = exposure.equalize_adapthist(mip_xy)\n",
    "        \n",
    "        axes[1, 0].imshow(mip_xy, cmap='gray')\n",
    "        axes[1, 0].set_title('XY Maximum Projection')\n",
    "        axes[1, 0].axis('off')\n",
    "        \n",
    "        # Create a red overlay for the background on XY projection\n",
    "        norm_img = np.zeros_like(mip_xy)\n",
    "        if mip_xy.max() > 0:\n",
    "            norm_img = (mip_xy - np.min(mip_xy)) / (np.max(mip_xy) - np.min(mip_xy))\n",
    "        rgb_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
    "        rgb_img[:,:,0][mip_bg_xy > 0.5] = 1.0  # Red\n",
    "        rgb_img[:,:,1][mip_bg_xy > 0.5] = 0.0  # Green\n",
    "        rgb_img[:,:,2][mip_bg_xy > 0.5] = 0.0  # Blue\n",
    "        axes[1, 0].imshow(rgb_img)\n",
    "        \n",
    "        # YZ projection (side view)\n",
    "        mip_yz = np.max(channel_image, axis=2)\n",
    "        mip_bg_yz = np.max(bg_model['mask'], axis=2) if len(bg_model['mask'].shape) == 3 else np.zeros_like(mip_yz)\n",
    "        \n",
    "        if enhance_contrast:\n",
    "            mip_yz = exposure.equalize_adapthist(mip_yz)\n",
    "        \n",
    "        axes[1, 1].imshow(mip_yz, cmap='gray')\n",
    "        axes[1, 1].set_title('YZ Maximum Projection')\n",
    "        axes[1, 1].axis('off')\n",
    "        \n",
    "        # Overlay for YZ\n",
    "        norm_img = np.zeros_like(mip_yz)\n",
    "        if mip_yz.max() > 0:\n",
    "            norm_img = (mip_yz - np.min(mip_yz)) / (np.max(mip_yz) - np.min(mip_yz))\n",
    "        rgb_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
    "        rgb_img[:,:,0][mip_bg_yz > 0.5] = 1.0\n",
    "        rgb_img[:,:,1][mip_bg_yz > 0.5] = 0.0\n",
    "        rgb_img[:,:,2][mip_bg_yz > 0.5] = 0.0\n",
    "        axes[1, 1].imshow(rgb_img)\n",
    "        \n",
    "        # XZ projection (front view)\n",
    "        mip_xz = np.max(channel_image, axis=1)\n",
    "        mip_bg_xz = np.max(bg_model['mask'], axis=1) if len(bg_model['mask'].shape) == 3 else np.zeros_like(mip_xz)\n",
    "        \n",
    "        if enhance_contrast:\n",
    "            mip_xz = exposure.equalize_adapthist(mip_xz)\n",
    "        \n",
    "        axes[1, 2].imshow(mip_xz, cmap='gray')\n",
    "        axes[1, 2].set_title('XZ Maximum Projection')\n",
    "        axes[1, 2].axis('off')\n",
    "        \n",
    "        # Overlay for XZ\n",
    "        norm_img = np.zeros_like(mip_xz)\n",
    "        if mip_xz.max() > 0:\n",
    "            norm_img = (mip_xz - np.min(mip_xz)) / (np.max(mip_xz) - np.min(mip_xz))\n",
    "        rgb_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
    "        rgb_img[:,:,0][mip_bg_xz > 0.5] = 1.0\n",
    "        rgb_img[:,:,1][mip_bg_xz > 0.5] = 0.0\n",
    "        rgb_img[:,:,2][mip_bg_xz > 0.5] = 0.0\n",
    "        axes[1, 2].imshow(rgb_img)\n",
    "        \n",
    "    else:\n",
    "        # Create figure with 4 subplots (2x2 grid)\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12), gridspec_kw={'height_ratios': [3, 1]})\n",
    "        \n",
    "        # Enhance contrast for visualization if requested\n",
    "        if enhance_contrast:\n",
    "            # Use percentile-based contrast stretching (robust to outliers)\n",
    "            p_low, p_high = 2, 98  # Percentiles for contrast stretching\n",
    "            display_img = exposure.rescale_intensity(\n",
    "                channel_image, \n",
    "                in_range=tuple(np.percentile(channel_image, (p_low, p_high))),\n",
    "                out_range='dtype'\n",
    "            )\n",
    "        else:\n",
    "            display_img = channel_image\n",
    "        \n",
    "        # Original image with enhanced contrast\n",
    "        axes[0, 0].imshow(display_img, cmap='gray')\n",
    "        axes[0, 0].set_title('Original Channel' + (' (Contrast Enhanced)' if enhance_contrast else ''))\n",
    "        plt.colorbar(axes[0, 0].get_images()[0], ax=axes[0, 0])\n",
    "        \n",
    "        # Background mask\n",
    "        axes[0, 1].imshow(bg_model['mask'], cmap='hot')\n",
    "        axes[0, 1].set_title(f'Background Mask\\nMean: {bg_model[\"mean\"]:.2f}, Std: {bg_model[\"std\"]:.2f}')\n",
    "        plt.colorbar(axes[0, 1].get_images()[0], ax=axes[0, 1])\n",
    "        \n",
    "        # Original with background highlighted\n",
    "        norm_img = (channel_image - np.min(channel_image)) / (np.max(channel_image) - np.min(channel_image))\n",
    "        rgb_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
    "        \n",
    "        # Highlight background in red\n",
    "        rgb_img[:,:,0][bg_model['mask']] = 1.0  # Set red high for background\n",
    "        rgb_img[:,:,1][bg_model['mask']] = 0.0  # Set green low for background\n",
    "        rgb_img[:,:,2][bg_model['mask']] = 0.0  # Set blue low for background\n",
    "        \n",
    "        axes[1, 0].imshow(rgb_img)\n",
    "        axes[1, 0].set_title('Background Regions (Red)')\n",
    "    \n",
    "    # Plot intensity histogram with GMM distributions\n",
    "    # Modified to use component parameters instead of GMM object\n",
    "    if 'component_weights' in bg_model and 'component_means' in bg_model and 'component_covs' in bg_model:\n",
    "        \n",
    "        # Create histogram - use the appropriate axes depending on 2D/3D\n",
    "        hist_ax = axes[2, 1] if is_3d else axes[1, 1]\n",
    "\n",
    "        flat_img = channel_image.flatten()\n",
    "        \n",
    "        # Plot histogram\n",
    "        hist_range = (np.min(flat_img), np.max(flat_img))\n",
    "        n_bins = 100\n",
    "        hist_ax.hist(flat_img, bins=n_bins, range=hist_range, density=True, \n",
    "                       alpha=0.6, color='gray', label='Pixel Intensity')\n",
    "        \n",
    "        # Create x values for plotting GMM curves\n",
    "        x = np.linspace(hist_range[0], hist_range[1], 1000)\n",
    "        \n",
    "        # Plot the individual components\n",
    "        colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "        bg_component = bg_model['bg_component']\n",
    "        \n",
    "        for i in range(len(bg_model['component_means'])):\n",
    "            # Calculate component density\n",
    "            weight = bg_model['component_weights'][i]\n",
    "            mean = bg_model['component_means'][i]\n",
    "            std = np.sqrt(bg_model['component_covs'][i])\n",
    "            \n",
    "            # Create a normal distribution for this component\n",
    "            y = weight * scipy.stats.norm.pdf(x, mean, std)\n",
    "            \n",
    "            # Plot with higher alpha for background component\n",
    "            alpha = 0.8 if i == bg_component else 0.5\n",
    "            label = f\"Background (μ={mean:.1f})\" if i == bg_component else f\"Component {i+1} (μ={mean:.1f})\"\n",
    "            hist_ax.plot(x, y, color=colors[i % len(colors)], \n",
    "                         alpha=alpha, linewidth=2, label=label)\n",
    "            \n",
    "        hist_ax.set_title('Pixel Intensity Distribution')\n",
    "        hist_ax.set_xlabel('Pixel Value')\n",
    "        hist_ax.set_xscale('log')\n",
    "        hist_ax.set_ylabel('Density')\n",
    "        hist_ax.legend()\n",
    "        \n",
    "        del flat_img, hist_range, n_bins, x\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=200)\n",
    "    plt.close('all')\n",
    "\n",
    "    del display_img, rgb_img\n",
    "\n",
    "def save_segmentation_qc_images(image, cell_masks, output_dir, img_name, config=None):\n",
    "    \"\"\"\n",
    "    Save quality control images showing zoomed-in regions of segmentation results,\n",
    "    with enhanced support for 3D data visualization\n",
    "    \n",
    "    Parameters:\n",
    "    - image: Multi-channel image array (H,W,C for 2D or Z,H,W,C for 3D)\n",
    "    - cell_masks: Integer mask with cell labels (H,W for 2D or Z,H,W for 3D)\n",
    "    - output_dir: Directory to save output images\n",
    "    - img_name: Base name of the image being processed\n",
    "    - config: Configuration dictionary with QC settings\n",
    "    \"\"\"\n",
    "    if config is None:\n",
    "        config = {}\n",
    "        # Check if 3D data is used\n",
    "        is_3d = len(image.shape) == 4 and image.shape[0] > 1\n",
    "    else:\n",
    "        is_3d = config.get('use_3d', False) or (len(image.shape) == 4 and image.shape[0] > 1)\n",
    "    \n",
    "    # Extract configuration\n",
    "    num_regions = config.get('qc_num_regions', 3)\n",
    "    region_size = config.get('qc_region_size', 400)\n",
    "    channels_to_show = config.get('qc_channels', list(range(image.shape[-1])))\n",
    "    \n",
    "    # Get cell properties and centroids\n",
    "    if is_3d:\n",
    "        # For 3D data, specify coordinates accordingly\n",
    "        props = measure.regionprops(cell_masks)\n",
    "    else:\n",
    "        props = measure.regionprops(cell_masks)\n",
    "    \n",
    "    if len(props) == 0:\n",
    "        print(\"No cells detected for QC visualization\")\n",
    "        return\n",
    "    \n",
    "    # Create QC directory\n",
    "    qc_dir = os.path.join(output_dir, \"qc_regions\")\n",
    "    os.makedirs(qc_dir, exist_ok=True)\n",
    "    \n",
    "    # Select cell regions to display\n",
    "    props_sorted_by_area = sorted(props, key=lambda x: x.area, reverse=True)\n",
    "    \n",
    "    # Select some large cells and some random cells for diversity\n",
    "    selected_props = props_sorted_by_area[:min(num_regions, len(props))]\n",
    "    \n",
    "    # Add some random cells from the remaining population if available\n",
    "    remaining_props = props_sorted_by_area[min(num_regions, len(props)):]\n",
    "    if remaining_props and len(remaining_props) > num_regions:\n",
    "        random_indices = np.random.choice(len(remaining_props), \n",
    "                                         min(num_regions, len(remaining_props)), \n",
    "                                         replace=False)\n",
    "        selected_props.extend([remaining_props[i] for i in random_indices])\n",
    "    \n",
    "    # Process each selected region\n",
    "    for i, prop in enumerate(selected_props):\n",
    "        if is_3d:\n",
    "            # For 3D data, handle differently\n",
    "            z_depth, h, w, _ = image.shape\n",
    "            \n",
    "            # Extract centroid coordinates correctly\n",
    "            z, y, x = prop.centroid\n",
    "            z, y, x = int(z), int(y), int(x)\n",
    "            \n",
    "            # Calculate region boundaries\n",
    "            half_size = region_size // 2\n",
    "            \n",
    "            # Define region in X and Y dimensions\n",
    "            y1 = max(0, y - half_size)\n",
    "            y2 = min(h, y + half_size)\n",
    "            x1 = max(0, x - half_size)\n",
    "            x2 = min(w, x + half_size)\n",
    "            \n",
    "            # Define Z range for visualization (use a portion of the cell's Z extent)\n",
    "            z_min, z_max = prop.bbox[0], prop.bbox[3]\n",
    "            z_center = (z_min + z_max) // 2\n",
    "            z_half_range = min(5, (z_max - z_min) // 2)  # Show at most 11 z-slices\n",
    "            z_start = max(0, z_center - z_half_range)\n",
    "            z_end = min(z_depth, z_center + z_half_range + 1)\n",
    "            \n",
    "            # Extract region masks for all Z-slices of interest\n",
    "            region_masks = cell_masks[z_start:z_end, y1:y2, x1:x2]\n",
    "            \n",
    "            # Calculate z-slice indices to visualize\n",
    "            z_indices = list(range(z_start, z_end))\n",
    "            \n",
    "            # Create figure with a grid: rows for channels, columns for z-slices\n",
    "            num_channels = len(channels_to_show)\n",
    "            num_z_slices = len(z_indices)\n",
    "            \n",
    "            # Create figure with 3 rows: original image slices, mask overlays, MIP projection\n",
    "            fig_width = min(20, num_z_slices * 3)  # Cap width at 20 inches\n",
    "            fig, axes = plt.subplots(num_channels, 3, figsize=(fig_width, 4*num_channels))\n",
    "            \n",
    "            if num_channels == 1:\n",
    "                axes = np.array([axes])  # Make 2D for consistent indexing\n",
    "                \n",
    "            region_name = f\"region_{i+1}_cell_{prop.label}\"\n",
    "            fig.suptitle(f\"3D Region {i+1}: Cell {prop.label} (Volume: {prop.area}px, Z-range: {z_min}-{z_max})\")\n",
    "            \n",
    "            # Process each channel\n",
    "            for ch_idx, ch in enumerate(channels_to_show):\n",
    "                if ch < image.shape[-1]:  # Ensure channel exists\n",
    "                    # First column: Middle Z-slice\n",
    "                    middle_z_idx = len(z_indices) // 2\n",
    "                    middle_z = z_indices[middle_z_idx]\n",
    "                    \n",
    "                    # Extract middle slice for this channel\n",
    "                    mid_slice = image[middle_z, y1:y2, x1:x2, ch]\n",
    "                    \n",
    "                    # Normalize for display\n",
    "                    p2, p98 = np.percentile(mid_slice, (2, 98))\n",
    "                    mid_slice_norm = np.clip((mid_slice - p2) / (p98 - p2) * 255, 0, 255).astype(np.uint8)\n",
    "                    \n",
    "                    # Display middle slice\n",
    "                    axes[ch_idx, 0].imshow(mid_slice_norm, cmap='gray')\n",
    "                    axes[ch_idx, 0].set_title(f\"Channel {ch+1} (Z={middle_z})\")\n",
    "                    axes[ch_idx, 0].axis('off')\n",
    "                    \n",
    "                    # Create mask overlay for middle slice\n",
    "                    mid_mask = region_masks[middle_z_idx]\n",
    "                    \n",
    "                    # Second column: Middle Z-slice with mask overlay\n",
    "                    mask_overlay = np.zeros((*mid_slice.shape, 4), dtype=np.uint8)\n",
    "                    \n",
    "                    # Unique colors for each cell in the region\n",
    "                    unique_labels = np.unique(mid_mask)\n",
    "                    unique_labels = unique_labels[unique_labels > 0]  # Skip background\n",
    "                    \n",
    "                    # Create colorful mask overlay\n",
    "                    for label in unique_labels:\n",
    "                        color = np.array(plt.cm.tab10(label % 10)) * 255\n",
    "                        mask_overlay[mid_mask == label] = [*color[:3], 128]  # Semi-transparent\n",
    "                    \n",
    "                    # Show mask overlaid on middle slice\n",
    "                    axes[ch_idx, 1].imshow(mid_slice_norm, cmap='gray')\n",
    "                    axes[ch_idx, 1].imshow(mask_overlay)\n",
    "                    axes[ch_idx, 1].set_title(f\"Channel {ch+1} with segmentation\")\n",
    "                    axes[ch_idx, 1].axis('off')\n",
    "                    \n",
    "                    # Third column: Maximum Intensity Projection\n",
    "                    # Extract full region for this channel and create MIP\n",
    "                    region_vol = image[z_start:z_end, y1:y2, x1:x2, ch]\n",
    "                    mip = np.max(region_vol, axis=0)\n",
    "                    \n",
    "                    # Normalize MIP for display\n",
    "                    p2, p98 = np.percentile(mip, (2, 98))\n",
    "                    mip_norm = np.clip((mip - p2) / (p98 - p2) * 255, 0, 255).astype(np.uint8)\n",
    "                    \n",
    "                    # Create mask MIP\n",
    "                    mask_mip = np.max(region_masks > 0, axis=0).astype(np.uint8)\n",
    "                    \n",
    "                    # Create overlay for MIP\n",
    "                    mask_overlay_mip = np.zeros((*mip.shape, 4), dtype=np.uint8)\n",
    "                    mask_overlay_mip[mask_mip > 0] = [255, 0, 0, 128]  # Red semi-transparent\n",
    "                    \n",
    "                    # Display MIP with overlay\n",
    "                    axes[ch_idx, 2].imshow(mip_norm, cmap='gray')\n",
    "                    axes[ch_idx, 2].imshow(mask_overlay_mip)\n",
    "                    axes[ch_idx, 2].set_title(f\"Channel {ch+1} MIP\")\n",
    "                    axes[ch_idx, 2].axis('off')\n",
    "            \n",
    "        else:\n",
    "            # 2D processing (existing code)\n",
    "            # Get centroid and bounds for region extraction\n",
    "            y, x = int(prop.centroid[0]), int(prop.centroid[1])\n",
    "            \n",
    "            # Define boundaries ensuring they're within image bounds\n",
    "            h, w = image.shape[0:2]\n",
    "            half_size = region_size // 2\n",
    "            \n",
    "            y1 = max(0, y - half_size)\n",
    "            y2 = min(h, y + half_size)\n",
    "            x1 = max(0, x - half_size)\n",
    "            x2 = min(w, x + half_size)\n",
    "            \n",
    "            # Extract region masks\n",
    "            region_mask = cell_masks[y1:y2, x1:x2]\n",
    "            \n",
    "            # Create figure with rows for each channel and columns for (original, mask overlay)\n",
    "            num_channels = len(channels_to_show)\n",
    "            fig, axes = plt.subplots(num_channels, 2, figsize=(12, 4*num_channels))\n",
    "            \n",
    "            if num_channels == 1:\n",
    "                axes = np.array([axes])  # Make it 2D for consistent indexing\n",
    "                \n",
    "            region_name = f\"region_{i+1}_cell_{prop.label}\"\n",
    "            fig.suptitle(f\"Region {i+1}: Cell {prop.label} (Area: {prop.area}px)\")\n",
    "            \n",
    "            # Process each channel\n",
    "            for ch_idx, ch in enumerate(channels_to_show):\n",
    "                if ch < image.shape[-1]:  # Ensure channel exists\n",
    "                    # Extract region for this channel\n",
    "                    region_img = image[y1:y2, x1:x2, ch]\n",
    "                    \n",
    "                    # Normalize for display\n",
    "                    p2, p98 = np.percentile(region_img, (2, 98))\n",
    "                    region_img_norm = np.clip((region_img - p2) / (p98 - p2) * 255, 0, 255).astype(np.uint8)\n",
    "                    \n",
    "                    # Display original channel\n",
    "                    axes[ch_idx, 0].imshow(region_img_norm, cmap='gray')\n",
    "                    axes[ch_idx, 0].set_title(f\"Channel {ch+1}\")\n",
    "                    axes[ch_idx, 0].axis('off')\n",
    "                    \n",
    "                    # Create mask overlay\n",
    "                    mask_overlay = np.zeros((*region_img.shape, 4), dtype=np.uint8)\n",
    "                    \n",
    "                    # Unique colors for each cell in the region\n",
    "                    unique_labels = np.unique(region_mask)\n",
    "                    unique_labels = unique_labels[unique_labels > 0]  # Skip background\n",
    "                    \n",
    "                    # Create colorful mask overlay\n",
    "                    for label in unique_labels:\n",
    "                        color = np.array(plt.cm.tab10(label % 10)) * 255\n",
    "                        mask_overlay[region_mask == label] = [*color[:3], 128]  # Semi-transparent\n",
    "                        \n",
    "                    # Show mask overlaid on original image\n",
    "                    axes[ch_idx, 1].imshow(region_img_norm, cmap='gray')\n",
    "                    axes[ch_idx, 1].imshow(mask_overlay)\n",
    "                    axes[ch_idx, 1].set_title(f\"Channel {ch+1} with segmentation\")\n",
    "                    axes[ch_idx, 1].axis('off')\n",
    "        \n",
    "        # Adjust layout and save\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.95)  # Make room for suptitle\n",
    "        region_filename = os.path.join(qc_dir, f\"{os.path.splitext(img_name)[0]}_{region_name}.png\")\n",
    "        plt.savefig(region_filename, dpi=150)\n",
    "        plt.close(fig)\n",
    "    \n",
    "    print(f\"Saved {len(selected_props)} QC region visualizations to {qc_dir}\")\n",
    "\n",
    "def create_visualization(image, masks, measurements, output_path, debug=False):\n",
    "    \"\"\"\n",
    "    Create multi-panel visualization for QC with 2D/3D support and optimized memory usage\n",
    "    \n",
    "    Parameters:\n",
    "    - image: Multi-channel image (H,W,C for 2D or Z,H,W,C for 3D)\n",
    "    - masks: Cell segmentation masks\n",
    "    - measurements: Cell measurements\n",
    "    - output_path: Where to save the visualization\n",
    "    - debug: Enable detailed timing and progress tracking\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if debug:\n",
    "            start_time = time.time()\n",
    "            print(f\"Starting visualization for {output_path}...\")\n",
    "        \n",
    "        # Force garbage collection before starting\n",
    "        gc.collect()\n",
    "\n",
    "        # Check if we're working with 3D data\n",
    "        is_3d = len(image.shape) == 4 and image.shape[0] > 1\n",
    "        \n",
    "        if is_3d:\n",
    "            # 3D visualization\n",
    "            z_depth, h, w, n_channels = image.shape\n",
    "            \n",
    "            # Calculate representative z-slices to display\n",
    "            z_positions = [z_depth // 4, z_depth // 2, 3 * z_depth // 4]\n",
    "            \n",
    "            # Create figure for 3D data - we'll use 2 rows:\n",
    "            # Row 1: Z-slices of representative planes\n",
    "            # Row 2: Maximum intensity projections (XY, YZ, XZ)\n",
    "            fig_width = max(15, n_channels * 3)  # Scale width based on channel count\n",
    "            fig = Figure(figsize=(fig_width, 10), dpi=200)\n",
    "            canvas = FigureCanvasAgg(fig)\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"Created 3D visualization figure with size {fig_width}x10 inches\")\n",
    "                \n",
    "            # Create grid with 2 rows\n",
    "            grid = fig.add_gridspec(2, n_channels + 1)\n",
    "            \n",
    "            # Row 1, Col 1: Show segmentation masks at middle z-slice\n",
    "            ax = fig.add_subplot(grid[0, 0])\n",
    "            middle_z = z_depth // 2\n",
    "            mask_slice = masks[middle_z]\n",
    "            ax.imshow(mask_slice > 0, cmap='viridis')\n",
    "            ax.set_title(f'Segmentation (Z={middle_z})')\n",
    "            ax.axis('off')\n",
    "\n",
    "            # Add cell labels to middle slice\n",
    "            if len(measurements) > 0:\n",
    "                # For 3D, filter cells that are present in this z-slice\n",
    "                if 'z_range' in measurements[0]:\n",
    "                    # Get cells that span this z-slice\n",
    "                    slice_cells = [cell for cell in measurements \n",
    "                                if cell['z_range'][0] <= middle_z <= cell['z_range'][1]]\n",
    "                    \n",
    "                    # Only label a subset of cells\n",
    "                    num_labels = min(30, len(slice_cells))\n",
    "                    if num_labels > 0:\n",
    "                        label_subset = slice_cells[:num_labels]\n",
    "                        \n",
    "                        for cell in label_subset:\n",
    "                            # Use 3D centroid if available, otherwise use 2D\n",
    "                            if 'centroid_3d' in cell:\n",
    "                                z, y, x = cell['centroid_3d']\n",
    "                                # Only add label if close to this z-slice\n",
    "                                if abs(z - middle_z) <= 2:  # Within 2 slices\n",
    "                                    ax.text(x, y, str(cell['label']), color='red', fontsize=5)\n",
    "            \n",
    "            # Row 2, Col 1: XY Maximum Intensity Projection\n",
    "            ax = fig.add_subplot(grid[1, 0])\n",
    "            mip_xy = np.max(masks, axis=0) > 0  # Binary MIP of masks\n",
    "            ax.imshow(mip_xy, cmap='viridis')\n",
    "            ax.set_title('Segmentation MIP (XY)')\n",
    "            ax.axis('off')\n",
    "            \n",
    "            # For each channel, show representative Z-slices and MIPs\n",
    "            for ch_idx in range(n_channels):\n",
    "                # Extract this channel's 3D data\n",
    "                channel_3d = image[:, :, :, ch_idx].copy()\n",
    "                \n",
    "                # Row 1: Middle z-slice of this channel\n",
    "                ax = fig.add_subplot(grid[0, ch_idx + 1])\n",
    "                \n",
    "                # Enhance contrast for better visualization\n",
    "                ch_slice = channel_3d[middle_z]\n",
    "                enhanced_slice = exposure.equalize_adapthist(ch_slice, clip_limit=0.03)\n",
    "                \n",
    "                # Show the channel with segmentation boundaries\n",
    "                ax.imshow(enhanced_slice, cmap='hot')\n",
    "                \n",
    "                # Add cell boundaries overlay\n",
    "                boundaries = find_boundaries(masks[middle_z] > 0)\n",
    "                ax.imshow(boundaries, alpha=0.3, cmap='cool')\n",
    "                \n",
    "                ax.set_title(f'Ch {ch_idx+1} (Z={middle_z})')\n",
    "                ax.axis('off')\n",
    "                \n",
    "                # Row 2: MIP of this channel with segmentation\n",
    "                ax = fig.add_subplot(grid[1, ch_idx + 1])\n",
    "                \n",
    "                # Create channel MIP with contrast enhancement\n",
    "                ch_mip = np.max(channel_3d, axis=0)\n",
    "                enhanced_mip = exposure.equalize_adapthist(ch_mip, clip_limit=0.03)\n",
    "                \n",
    "                # Show MIP with segmentation overlay\n",
    "                ax.imshow(enhanced_mip, cmap='hot')\n",
    "                \n",
    "                # Add MIP of boundaries\n",
    "                boundaries_mip = find_boundaries(mip_xy)\n",
    "                ax.imshow(boundaries_mip, alpha=0.3, cmap='cool')\n",
    "                \n",
    "                ax.set_title(f'Ch {ch_idx+1} MIP')\n",
    "                ax.axis('off')\n",
    "                \n",
    "                # Free memory\n",
    "                del channel_3d, ch_slice, enhanced_slice, enhanced_mip, boundaries\n",
    "                \n",
    "        else:\n",
    "            # Standard 2D visualization (existing code)\n",
    "            h, w, n_channels = image.shape\n",
    "            \n",
    "            # Calculate reasonable figure size to avoid excessive memory usage\n",
    "            max_dim = 2000  # Maximum dimension in pixels\n",
    "            scale_factor = min(1.0, max_dim / max(h, w))\n",
    "            \n",
    "            # Create figure without displaying (reduces memory usage)\n",
    "            dpi = 300  # Maintain good quality\n",
    "            fig_width = (n_channels + 1) * 4  # 4 inches per panel\n",
    "            fig_height = 4  # Fixed height\n",
    "            \n",
    "            # Use Figure directly instead of pyplot to avoid memory leaks\n",
    "            fig = Figure(figsize=(fig_width, fig_height), dpi=dpi)\n",
    "            canvas = FigureCanvasAgg(fig)\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"Created figure with size {fig_width}x{fig_height} inches at {dpi} DPI\")\n",
    "                print(f\"Processing {n_channels} channels and {len(measurements)} cells\")\n",
    "            \n",
    "            # Create subplot grid\n",
    "            grid = fig.add_gridspec(1, n_channels + 1)\n",
    "            \n",
    "            # Plot segmentation mask (first panel) with enhanced contrast\n",
    "            if debug:\n",
    "                print(\"Rendering segmentation mask...\")\n",
    "            \n",
    "            ax = fig.add_subplot(grid[0, 0])\n",
    "            \n",
    "            # Convert mask to float for better visualization\n",
    "            mask_display = (masks > 0).astype(float)\n",
    "            # Apply contrast enhancement to make it more visible\n",
    "            mask_display = exposure.equalize_adapthist(mask_display)\n",
    "            ax.imshow(mask_display, cmap='viridis')  # Use viridis for better contrast\n",
    "            ax.set_title('Cell Segmentation (Enhanced)')\n",
    "            ax.axis('off')  # Turn off axes to save memory\n",
    "            \n",
    "            # Only add labels for a subset of cells\n",
    "            if len(measurements) > 0:\n",
    "                if debug:\n",
    "                    print(\"Adding cell labels...\")\n",
    "                # Select a random subset of 50 cells or fewer if there are less than 50\n",
    "                num_labels = min(50, len(measurements))\n",
    "                # Use numpy's random choice if measurements is a list, otherwise select first num_labels\n",
    "                if isinstance(measurements, list):\n",
    "                    indices = np.random.choice(len(measurements), num_labels, replace=False)\n",
    "                    label_subset = [measurements[i] for i in indices]\n",
    "                else:\n",
    "                    label_subset = measurements[:num_labels]\n",
    "                    \n",
    "                for cell in label_subset:\n",
    "                    y, x = cell['centroid']\n",
    "                    ax.text(x, y, str(cell['label']), color='red', fontsize=5)\n",
    "            \n",
    "            # Process channels with progress tracking\n",
    "            channel_range = range(n_channels)\n",
    "            if debug:\n",
    "                from tqdm import tqdm\n",
    "                channel_range = tqdm(channel_range, desc=\"Processing channels\")\n",
    "            \n",
    "            for ch_idx, ch in enumerate(channel_range):\n",
    "                if debug:\n",
    "                    ch_start = time.time()\n",
    "                    \n",
    "                # Create subplot for this channel\n",
    "                ax = fig.add_subplot(grid[0, ch_idx + 1])\n",
    "                \n",
    "                # Get channel data and apply adaptive contrast enhancement\n",
    "                channel_data = image[:,:,ch].copy()  # Make a copy to avoid modifying original\n",
    "                \n",
    "                # Adaptive histogram equalization - best for visualizing local features\n",
    "                enhanced_data = exposure.equalize_adapthist(channel_data, clip_limit=0.03)\n",
    "                \n",
    "                # Display the image\n",
    "                ax.imshow(enhanced_data, cmap='hot')\n",
    "                ax.set_title(f'Channel {ch+1} (Enhanced)')\n",
    "                ax.axis('off')  # Turn off axes to save memory\n",
    "                \n",
    "                # Show cell boundaries efficiently\n",
    "                boundaries = find_boundaries(masks > 0)\n",
    "                ax.imshow(boundaries, alpha=0.3, cmap='cool')\n",
    "                \n",
    "                # Free memory\n",
    "                del channel_data\n",
    "                del enhanced_data\n",
    "                del boundaries\n",
    "                \n",
    "                if debug:\n",
    "                    print(f\"  Channel {ch+1} rendered in {time.time() - ch_start:.2f}s\")\n",
    "        \n",
    "        # Adjust layout and save\n",
    "        if debug:\n",
    "            print(\"Saving figure...\")\n",
    "            save_start = time.time()\n",
    "            \n",
    "        fig.tight_layout()\n",
    "        fig.savefig(output_path, bbox_inches='tight')\n",
    "        \n",
    "        # Clean up matplotlib resources explicitly\n",
    "        fig.clf()\n",
    "        canvas.renderer.clear()\n",
    "        del fig\n",
    "        del canvas\n",
    "        \n",
    "        # Force garbage collection\n",
    "        gc.collect()\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Visualization saved in {time.time() - save_start:.2f}s\")\n",
    "            print(f\"Total visualization time: {time.time() - start_time:.2f}s\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in visualization: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        # Ensure cleanup even on error\n",
    "        if 'fig' in locals():\n",
    "            fig.clf()\n",
    "            del fig\n",
    "        if 'canvas' in locals():\n",
    "            canvas.renderer.clear()\n",
    "            del canvas\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background substraction and CellPose based Segmentation Functions\n",
    "Here the main functions for background substraction and cell segmentation based on de cyto3 model are defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_image(image_path, output_dir, config):\n",
    "    \"\"\"Process a single fluorescence microscopy image with improved memory management\"\"\"\n",
    "    try:\n",
    "        # Load image and normalize channels\n",
    "        image = tiff.imread(image_path)\n",
    "        img_name = os.path.basename(image_path)\n",
    "        img_base = os.path.splitext(img_name)[0]\n",
    "\n",
    "        print(f\"\\nProcessing image: {img_name} and shape {image.shape}\")\n",
    "        \n",
    "        # Determine if this is 3D data (Z-stack)\n",
    "        is_3d = config.get('use_3d', False)\n",
    "        \n",
    "        # Move the shortest axis (channels) to the last index\n",
    "        if is_3d:\n",
    "            # For 3D, image shape should be (Z, Y, X, C)\n",
    "            # Find the channel dimension (usually the smallest)\n",
    "            dims = list(image.shape)\n",
    "            if min(dims) < 6:  # Likely channel dimension if small\n",
    "                channel_axis = dims.index(min(dims))\n",
    "                image = np.moveaxis(image, channel_axis, -1)\n",
    "            else:\n",
    "                # Assume the standard ordering Z,Y,X and add a channel dimension if needed\n",
    "                if len(image.shape) == 3:\n",
    "                    image = image[..., np.newaxis]  # Add channel dimension\n",
    "        else:\n",
    "            # Standard 2D case\n",
    "            shortest_axis = np.argmin(image.shape)\n",
    "            image = np.moveaxis(image, shortest_axis, -1)\n",
    "\n",
    "        # For very large 3D volumes, use more aggressive garbage collection\n",
    "        if is_3d and config.get('aggressive_gc', False):\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        debug = config.get('debug', False)\n",
    "\n",
    "        # Extract configuration\n",
    "        channels_of_interest = config.get('channels_of_interest', list(range(image.shape[-1])))\n",
    "        \n",
    "        # 1. BACKGROUND ESTIMATION USING GMM\n",
    "        print(\"Estimating background using GMM...\")\n",
    "        bg_models = {}\n",
    "        for ch in tqdm(range(image.shape[-1]), desc=\"Background estimation\", leave=True):\n",
    "            # Process one channel at a time to reduce memory usage\n",
    "            channel_data = image[...,ch].copy()  # Make a copy to avoid reference issues\n",
    "            bg_models[ch] = estimate_background_gmm(channel_data,config)\n",
    "            \n",
    "            # Save background mask visualization if needed\n",
    "            if config.get('visualize_bg', True):\n",
    "                visualize_background_mask(channel_data, bg_models[ch], \n",
    "                                         os.path.join(output_dir, f\"{img_base}_bg_mask_ch{ch+1}.png\"))\n",
    "                plt.close('all')  # Ensure all plots are closed\n",
    "            \n",
    "            # Remove channel data from memory\n",
    "            del channel_data\n",
    "        \n",
    "        print(\"Background estimation complete.\")\n",
    "        \n",
    "        # 2. CELL SEGMENTATION USING CELLPOSE\n",
    "        cell_masks = segment_cells_with_downsampling(image, config, bg_models)\n",
    "        \n",
    "        # 3. MEASURE CTCF FOR EACH CELL AND CHANNEL\n",
    "        cell_measurements = measure_cells(image, cell_masks, bg_models, config)\n",
    "        \n",
    "        # Store key results in a DataFrame and save immediately\n",
    "        cell_df = pd.DataFrame([\n",
    "            {\n",
    "                'image': img_name,\n",
    "                'cell_id': i,\n",
    "                'area': cell['area'],\n",
    "                **{f'channel_{ch+1}_ctcf': cell['ctcf'][ch] for ch in channels_of_interest},\n",
    "                **{f'channel_{ch+1}_mean': cell['mean'][ch] for ch in channels_of_interest},\n",
    "                'centroid_x': cell['centroid'][0],\n",
    "                'centroid_y': cell['centroid'][1]\n",
    "            }\n",
    "            for i, cell in enumerate(cell_measurements)\n",
    "        ])\n",
    "        cell_df.to_csv(os.path.join(output_dir, f\"{img_base}_cells.csv\"), index=False)\n",
    "        \n",
    "        # 4. GENERATE VISUALIZATIONS - do this after saving measurements to free memory\n",
    "        if debug:\n",
    "            print(f\"Starting visualization with debug mode...\")\n",
    "        if config.get('visualize_segmentation', True):\n",
    "            create_visualization(image, cell_masks, cell_measurements, \n",
    "                                os.path.join(output_dir, f\"{img_name}_analysis.png\"),\n",
    "                                debug=debug)\n",
    "            \n",
    "            # Explicitly close all plots and collect garbage\n",
    "            plt.close('all')\n",
    "        \n",
    "        if config.get('save_qc_regions', True):\n",
    "            save_segmentation_qc_images(\n",
    "                image, \n",
    "                cell_masks, \n",
    "                output_dir, \n",
    "                img_name, \n",
    "                config\n",
    "            )\n",
    "            \n",
    "        gc.collect()\n",
    "        \n",
    "        # 5. CLEANUP AND RETURN RESULTS\n",
    "        # Create a minimal results dictionary with just the summary stats\n",
    "        results = {\n",
    "            'image_name': img_name,\n",
    "            'total_cells': len(cell_measurements),\n",
    "            'image_path': image_path,\n",
    "        }\n",
    "        \n",
    "        # Add summarized measurements\n",
    "        for ch in channels_of_interest:\n",
    "            ch_ctcf = [cell['ctcf'][ch] for cell in cell_measurements]\n",
    "            results[f'channel_{ch+1}_mean_ctcf'] = np.mean(ch_ctcf)\n",
    "            results[f'channel_{ch+1}_median_ctcf'] = np.median(ch_ctcf)\n",
    "            results[f'channel_{ch+1}_std_ctcf'] = np.std(ch_ctcf)\n",
    "            \n",
    "        # Clean up large objects\n",
    "        del image, cell_masks, cell_measurements, bg_models, cell_df\n",
    "        gc.collect()\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        gc.collect()\n",
    "        return {'image_name': os.path.basename(image_path), 'error': str(e), 'total_cells': 0}\n",
    "\n",
    "def resample_image(image, scale_factor=0.5, downsample_z=False):\n",
    "    \"\"\"Resample image by the given scale factor with optional Z-downsampling\"\"\"\n",
    "    \n",
    "    # Check if this is 3D data with channels\n",
    "    is_3d = len(image.shape) == 4 and image.shape[0] > 1\n",
    "    \n",
    "    if is_3d:\n",
    "        z_depth, h, w, c = image.shape\n",
    "        \n",
    "        if downsample_z:\n",
    "            # Downsample in all dimensions including Z\n",
    "            new_z = int(z_depth * scale_factor)\n",
    "            new_h, new_w = int(h * scale_factor), int(w * scale_factor)\n",
    "            resized = resize(image, (new_z, new_h, new_w, c), \n",
    "                            preserve_range=True, anti_aliasing=True)\n",
    "        else:\n",
    "            # Downsample only in X and Y, preserving Z resolution\n",
    "            new_h, new_w = int(h * scale_factor), int(w * scale_factor)\n",
    "            resized = np.zeros((z_depth, new_h, new_w, c), dtype=image.dtype)\n",
    "            \n",
    "            # Process each Z-slice\n",
    "            for z in range(z_depth):\n",
    "                resized[z] = resize(image[z], (new_h, new_w, c), \n",
    "                                    preserve_range=True, anti_aliasing=True)\n",
    "    else:\n",
    "        # Original 2D case\n",
    "        h, w, c = image.shape\n",
    "        new_h, new_w = int(h * scale_factor), int(w * scale_factor)\n",
    "        resized = resize(image, (new_h, new_w, c), preserve_range=True, anti_aliasing=True)\n",
    "    \n",
    "    return resized.astype(image.dtype)\n",
    "\n",
    "def check_gpu_availability():\n",
    "    \"\"\"Check if GPU is available for processing\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def estimate_background_gmm(channel_image, config = None, n_components=3, sample_ratio=0.1, \n",
    "                                max_iter=100, max_components=6):\n",
    "    \"\"\"\n",
    "    Fast background estimation using GMM with optional adaptive component selection\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if 3D and change sample size\n",
    "    use_3d = config.get('use_3d', False) if config else False\n",
    "\n",
    "    if use_3d:\n",
    "        sample_ratio = sample_ratio * 0.5  # Reduce sample size for 3D images\n",
    "        min_sample_nr = 100000  # Minimum sample size for 3D images\n",
    "    else:\n",
    "        min_sample_nr = 10000  # Minimum sample size for 2D images\n",
    "\n",
    "    try:\n",
    "        adaptive = config.get('adaptive_gmm', False) if config else False\n",
    "\n",
    "        # Flatten image\n",
    "        flat_img = channel_image.flatten()\n",
    "        \n",
    "        # Downsample by random sampling\n",
    "        n_samples = max(min_sample_nr, int(sample_ratio * flat_img.size))\n",
    "        indices = np.random.choice(flat_img.size, size=n_samples, replace=False)\n",
    "        sample_data = flat_img[indices].reshape(-1, 1)\n",
    "        \n",
    "        # Select GMM model - adaptive or fixed\n",
    "        if adaptive:\n",
    "            bic_scores = []\n",
    "            models = []\n",
    "            \n",
    "            # Try different numbers of components\n",
    "            for n in range(1, max_components + 1):\n",
    "                # Initialize with K-means for faster convergence\n",
    "                kmeans = KMeans(n_clusters=n, n_init=1, max_iter=100)\n",
    "                kmeans.fit(sample_data)\n",
    "                \n",
    "                # Configure and fit GMM\n",
    "                gmm = GaussianMixture(\n",
    "                    n_components=n, \n",
    "                    random_state=42,\n",
    "                    n_init=1, \n",
    "                    max_iter=max_iter,\n",
    "                    tol=1e-3,\n",
    "                    means_init=kmeans.cluster_centers_\n",
    "                )\n",
    "                \n",
    "                gmm.fit(sample_data)\n",
    "                bic_scores.append(gmm.bic(sample_data))\n",
    "                models.append(gmm)\n",
    "                \n",
    "                del kmeans\n",
    "                \n",
    "            # Select model with lowest BIC score\n",
    "            best_idx = np.argmin(bic_scores)\n",
    "            gmm = models[best_idx]\n",
    "            n_components = models[best_idx].n_components\n",
    "            print(f\"Adaptive GMM selected {n_components} components with BIC: {bic_scores[best_idx]:.2f}\")\n",
    "            \n",
    "            # Clean up unused models\n",
    "            for i, model in enumerate(models):\n",
    "                if i != best_idx:\n",
    "                    del model\n",
    "            models = None\n",
    "        else:\n",
    "            # Non-adaptive - just use specified components\n",
    "            # Initialize with K-means for faster convergence\n",
    "            kmeans = KMeans(n_clusters=n_components, n_init=1, max_iter=100)\n",
    "            kmeans.fit(sample_data)\n",
    "            \n",
    "            # Configure GMM and fit\n",
    "            gmm = GaussianMixture(\n",
    "                n_components=n_components,\n",
    "                random_state=42,\n",
    "                n_init=1,\n",
    "                max_iter=max_iter,\n",
    "                tol=1e-3,\n",
    "                means_init=kmeans.cluster_centers_\n",
    "            )\n",
    "            gmm.fit(sample_data)\n",
    "            del kmeans\n",
    "        \n",
    "        # Extract model parameters\n",
    "        means = gmm.means_.flatten()\n",
    "        covs = np.array([gmm.covariances_[i].flatten()[0] for i in range(gmm.n_components)])\n",
    "        weights = gmm.weights_\n",
    "        \n",
    "        # Identify background component (lowest mean)\n",
    "        bg_component = np.argmin(means)\n",
    "        bg_mean = means[bg_component]\n",
    "        bg_std = np.sqrt(covs[bg_component])\n",
    "        \n",
    "        # Use original model to predict components - more efficient\n",
    "        pixel_labels = gmm.predict(flat_img.reshape(-1, 1))\n",
    "        bg_mask = (pixel_labels == bg_component).reshape(channel_image.shape)\n",
    "        \n",
    "        # Clean up sample data to free memory\n",
    "        del sample_data, flat_img, pixel_labels\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'mean': bg_mean,\n",
    "            'std': bg_std,\n",
    "            'mask': bg_mask,\n",
    "            'bg_percentage': np.sum(bg_mask) / bg_mask.size * 100,\n",
    "            'component_means': means,\n",
    "            'component_weights': weights,\n",
    "            'component_covs': covs,\n",
    "            'n_components': n_components,\n",
    "            'bg_component': bg_component,\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in GMM background estimation: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        # Return fallback values\n",
    "        return {'mean': 0, 'std': 0, 'mask': np.zeros_like(channel_image, dtype=bool)}\n",
    "    \n",
    "def segment_cells_cellpose(image, config, bg_models=None):\n",
    "\n",
    "    \"\"\"Cell segmentation using CellPose with optimized memory usage\"\"\"\n",
    "    io.logger_setup()\n",
    "    \n",
    "    # Extract the right channels for segmentation\n",
    "    cyto_channel_idx = config.get('cytoplasm_channel', 4) - 1 \n",
    "    nuc_channel_idx = config.get('nucleus_channel', 1) - 1\n",
    "\n",
    "    # Extract 3D configuration\n",
    "    use_3d = config.get('use_3d', False)\n",
    "    \n",
    "    # Choose model based on segmentation type\n",
    "    if config.get('segmentation_type') == 'nuclei_only':\n",
    "        model = models.Cellpose(gpu=config.get('use_gpu', True), model_type='nuclei')\n",
    "        cellpose_channels = [0, 0]  # Standard for nuclei model\n",
    "        \n",
    "        # For single-channel segmentation\n",
    "        img_to_segment = image[:,:,nuc_channel_idx].copy()\n",
    "        \n",
    "        # Apply background subtraction if needed\n",
    "        if bg_models is not None and nuc_channel_idx in bg_models:\n",
    "            ch_mean = bg_models[nuc_channel_idx]['mean']\n",
    "            img_to_segment = np.clip(img_to_segment - ch_mean, 0, None)\n",
    "            print(f\"Channel {nuc_channel_idx}: Subtracted mean background {ch_mean:.2f}\")\n",
    "            \n",
    "    else:\n",
    "        model = models.Cellpose(gpu=config.get('use_gpu', True), model_type=\"cyto3\")\n",
    "        cellpose_channels = [2, 1]  # Standard for cyto model: 1=nuclei, 2=cyto\n",
    "        \n",
    "        # Create channels array with proper mapping between original and stacked indices\n",
    "        channel_mapping = [cyto_channel_idx, nuc_channel_idx] \n",
    "        \n",
    "        # Create the segmentation image \n",
    "        img_to_segment = np.stack([image[:,:,nuc_channel_idx], image[:,:,cyto_channel_idx]], axis=-1).copy()\n",
    "        \n",
    "        # Apply background subtraction with correct index mapping\n",
    "        if bg_models is not None:\n",
    "            for i, orig_idx in enumerate(channel_mapping):\n",
    "                if orig_idx in bg_models:\n",
    "                    ch_mean = bg_models[orig_idx]['mean']\n",
    "                    img_to_segment[:,:,i] = np.clip(img_to_segment[:,:,i] - ch_mean, 0, None)\n",
    "                    print(f\"Channel {orig_idx} (stack position {i}): Subtracted mean background {ch_mean:.2f}\")\n",
    "    \n",
    "    print(f\"Running Cellpose with channels: {ch+1}\" for ch in cellpose_channels)\n",
    "    print(f\"Image shape for segmentation: {img_to_segment.shape}\")\n",
    "    \n",
    "    # Run segmentation with debug info\n",
    "    try:\n",
    "        masks, flows, styles, diams = model.eval(\n",
    "            img_to_segment, \n",
    "            channels=cellpose_channels,\n",
    "            diameter=config.get('cell_diameter', 20.0),\n",
    "            anisotropy=config.get('anisotropy', 3.0),\n",
    "            flow_threshold=config.get('flow_threshold', 0.4),\n",
    "            cellprob_threshold=config.get('cellprob_threshold', 0.0),\n",
    "            normalize=True,\n",
    "            progress=True,\n",
    "            do_3D=use_3d\n",
    "        )\n",
    "        \n",
    "        # Free memory\n",
    "        del img_to_segment, model\n",
    "        if 'flows' in locals() and flows is not None:\n",
    "            del flows\n",
    "        if 'styles' in locals() and styles is not None:\n",
    "            del styles\n",
    "        if 'diams' in locals() and diams is not None:\n",
    "            del diams\n",
    "\n",
    "        gc.collect()\n",
    "        \n",
    "        print(f\"Segmentation complete! Found {len(np.unique(masks))-1} objects\")\n",
    "        return masks\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR in Cellpose: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        return np.zeros(image.shape[:2], dtype=np.int32)\n",
    "\n",
    "def segment_cells_with_downsampling(image, config, bg_models=None):\n",
    "    \"\"\"Segment cells with better memory management\"\"\"\n",
    "    # Get downsampling factor from config\n",
    "    downsample_factor = config.get('downsample_factor', 1.0)\n",
    "    \n",
    "    try:\n",
    "        if downsample_factor >= 1.0:\n",
    "            # Process at original resolution\n",
    "            masks = segment_cells_cellpose(image, config, bg_models)\n",
    "            return masks\n",
    "        \n",
    "        # Downsample image for processing\n",
    "        small_image = resample_image(image, downsample_factor)\n",
    "        \n",
    "        # Adjust cell diameter for downsampled image\n",
    "        small_config = config.copy()\n",
    "        small_config['cell_diameter'] = config.get('cell_diameter', 20.0) * downsample_factor\n",
    "        \n",
    "        # Run segmentation on smaller image\n",
    "        small_masks = segment_cells_cellpose(small_image, small_config, bg_models)\n",
    "        \n",
    "        # Free memory before upsampling\n",
    "        del small_image\n",
    "        gc.collect()\n",
    "        \n",
    "        # Upsample masks to original size\n",
    "        masks_upscaled = resize(small_masks, image.shape[0:2], order=0, preserve_range=True)\n",
    "        masks_upscaled = masks_upscaled.astype(np.int32)\n",
    "        \n",
    "        # Free memory\n",
    "        del small_masks\n",
    "        \n",
    "        return masks_upscaled\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in segmentation: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        # Return empty mask in case of error\n",
    "        return np.zeros(image.shape[:2], dtype=np.int32)\n",
    "\n",
    "def measure_cells(image, cell_masks, bg_models, config=None):\n",
    "    \"\"\"\n",
    "    Unified CTCF measurement function that handles both 2D and 3D data\n",
    "    \n",
    "    Parameters:\n",
    "    - image: Multi-channel image array (Y,X,C) for 2D or (Z,Y,X,C) for 3D\n",
    "    - cell_masks: Integer mask with cell labels (Y,X) for 2D or (Z,Y,X) for 3D\n",
    "    - bg_models: Background models for each channel\n",
    "    - config: Configuration dictionary\n",
    "    \n",
    "    Returns:\n",
    "    - List of cell measurements\n",
    "    \"\"\"\n",
    "    # Detect if data is 3D\n",
    "    is_3d = config.get('use_3d', False) or (len(image.shape) == 4 and len(cell_masks.shape) == 3)\n",
    "    \n",
    "    # Check if GPU should be used\n",
    "    use_gpu = config.get('use_gpu', True)\n",
    "    if use_gpu and config.get('auto_detect_gpu', True):\n",
    "        use_gpu = check_gpu_availability()\n",
    "    \n",
    "    # Select appropriate implementation\n",
    "    if is_3d:\n",
    "        print(\"Using 3D CTCF measurement...\")\n",
    "        if use_gpu:\n",
    "            try:\n",
    "                return measure_cells_ctcf_3d_gpu(image, cell_masks, bg_models, config)\n",
    "            except Exception as e:\n",
    "                print(f\"3D GPU CTCF measurement failed: {str(e)}. Falling back to CPU.\")\n",
    "                return measure_cells_ctcf_3d_cpu(image, cell_masks, bg_models, config)\n",
    "        else:\n",
    "            return measure_cells_ctcf_3d_cpu(image, cell_masks, bg_models, config)\n",
    "    else:\n",
    "        # Use existing 2D implementations\n",
    "        if use_gpu:\n",
    "            try:\n",
    "                return measure_cells_ctcf_gpu(image, cell_masks, bg_models, config)\n",
    "            except Exception as e:\n",
    "                print(f\"GPU CTCF measurement failed: {str(e)}. Falling back to CPU.\")\n",
    "                return measure_cells_ctcf_cpu(image, cell_masks, bg_models, config)\n",
    "        else:\n",
    "            return measure_cells_ctcf_cpu(image, cell_masks, bg_models, config)\n",
    "    \n",
    "def measure_cells_ctcf_cpu(image, cell_masks, bg_models, config = None):\n",
    "    \"\"\"\n",
    "    Measure CTCF for all cells and channels with progress tracking and debugging\n",
    "    \n",
    "    Parameters:\n",
    "    - image: Multi-channel image array\n",
    "    - cell_masks: Integer mask with cell labels\n",
    "    - bg_models: Background models for each channel\n",
    "    \"\"\"\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Get unique cell labels\n",
    "    unique_labels = np.unique(cell_masks)\n",
    "    unique_labels = unique_labels[unique_labels > 0]  # Skip background (0)\n",
    "    total_cells = len(unique_labels)\n",
    "    \n",
    "    if total_cells == 0:\n",
    "        print(\"No cells found in mask.\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"Measuring CTCF for {total_cells} cells using parallel CPU processing...\")\n",
    "    \n",
    "    # Determine optimal batch size and number of workers\n",
    "    max_workers = config.get('max_workers', min(os.cpu_count(), 8))\n",
    "    batch_size = config.get('batch_size', max(10, total_cells // (max_workers * 2)))\n",
    "    \n",
    "    # Create batches of cell labels\n",
    "    label_batches = [unique_labels[i:i + batch_size] for i in range(0, len(unique_labels), batch_size)]\n",
    "    print(f\"Processing {len(label_batches)} batches with up to {max_workers} workers\")\n",
    "    \n",
    "    # Prepare partial function with fixed arguments\n",
    "    process_batch_func = partial(\n",
    "        process_cell_batch,\n",
    "        image=image,\n",
    "        cell_masks=cell_masks,\n",
    "        bg_models=bg_models\n",
    "    )\n",
    "    \n",
    "    # Process batches in parallel\n",
    "    results = []\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        batch_results = list(\n",
    "            tqdm(\n",
    "                executor.map(process_batch_func, label_batches), \n",
    "                total=len(label_batches),\n",
    "                desc=\"Processing batches\"\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Combine batch results\n",
    "        for batch_result in batch_results:\n",
    "            results.extend(batch_result)\n",
    "    \n",
    "    # Final timing\n",
    "    total_time = time.time() - start_time\n",
    "    cells_per_sec = total_cells / (total_time + 1e-6)\n",
    "    print(f\"Parallel CTCF measurement complete: {total_cells} cells in {total_time:.2f}s ({cells_per_sec:.2f} cells/sec)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def process_cell_batch(cell_labels, image, cell_masks, bg_models):\n",
    "    \"\"\"\n",
    "    Process a batch of cells for CTCF measurement (called by parallel worker).\n",
    "    \"\"\"\n",
    "    # Process-safe matplotlib configuration (avoid conflicts)\n",
    "    \n",
    "    batch_results = []\n",
    "    \n",
    "    for label in cell_labels:\n",
    "        # Create mask for this cell only\n",
    "        cell_mask = cell_masks == label\n",
    "        \n",
    "        # Get cell properties\n",
    "        y_indices, x_indices = np.where(cell_mask)\n",
    "        if len(y_indices) == 0:\n",
    "            continue\n",
    "            \n",
    "        area = len(y_indices)\n",
    "        y_centroid = np.mean(y_indices)\n",
    "        x_centroid = np.mean(x_indices)\n",
    "        \n",
    "        # Initialize cell data\n",
    "        cell_data = {\n",
    "            'label': int(label),  # Ensure label is int for serialization\n",
    "            'area': int(area),\n",
    "            'centroid': (float(y_centroid), float(x_centroid)),\n",
    "            'ctcf': {},\n",
    "            'mean': {},\n",
    "            'total': {},\n",
    "            'bg_value': {}\n",
    "        }\n",
    "        \n",
    "        # Process each channel\n",
    "        for ch in range(image.shape[-1]):\n",
    "            # Extract the channel data\n",
    "            channel = image[:,:,ch]\n",
    "            \n",
    "            # Use efficient boolean indexing\n",
    "            cell_pixels = channel[cell_mask]\n",
    "            \n",
    "            # Get background value\n",
    "            bg_value = bg_models[ch]['mean'] if ch in bg_models else 0\n",
    "            cell_data['bg_value'][ch] = float(bg_value)\n",
    "            \n",
    "            # Calculate measurements\n",
    "            total_intensity = np.sum(cell_pixels)\n",
    "            mean_intensity = np.mean(cell_pixels)\n",
    "            ctcf = total_intensity - (area * bg_value)\n",
    "            \n",
    "            # Store results (convert to Python types for serialization)\n",
    "            cell_data['total'][ch] = float(total_intensity)\n",
    "            cell_data['mean'][ch] = float(mean_intensity)\n",
    "            cell_data['ctcf'][ch] = float(ctcf)\n",
    "            \n",
    "        batch_results.append(cell_data)\n",
    "    \n",
    "    return batch_results\n",
    "\n",
    "def measure_cells_ctcf_gpu(image, cell_masks, bg_models, config = None, debug=False):\n",
    "    \"\"\"GPU-accelerated CTCF measurement for improved performance\"\"\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Convert arrays to PyTorch tensors on GPU with explicit data type conversion\n",
    "    device = torch.device('cuda')\n",
    "    try:    \n",
    "        # Convert to float32 since uint16 is not supported by all operations\n",
    "        image_tensor = torch.from_numpy(image).to(device).float()\n",
    "        mask_tensor = torch.from_numpy(cell_masks).to(device)\n",
    "        \n",
    "        # Get unique cell IDs for processing\n",
    "        cell_ids = torch.unique(mask_tensor)[1:]  # Skip 0 (background)\n",
    "        total_cells = len(cell_ids)\n",
    "        print(f\"Measuring CTCF for {total_cells} cells across {image.shape[-1]} channels on GPU...\")\n",
    "        \n",
    "        # Prepare results container\n",
    "        measurements = []\n",
    "        \n",
    "        # Process in batches if there are many cells\n",
    "        batch_size = config.get('gpu_batch_size', min(500, total_cells))\n",
    "\n",
    "        for batch_start in tqdm(range(0, total_cells, batch_size), desc=\"Processing cell batches\"):\n",
    "            batch_end = min(batch_start + batch_size, total_cells)\n",
    "            batch_ids = cell_ids[batch_start:batch_end]\n",
    "            \n",
    "            # Process each cell in the batch\n",
    "            for cell_idx in range(len(batch_ids)):\n",
    "                cell_id = batch_ids[cell_idx].item()\n",
    "                \n",
    "                # Create binary mask for this cell\n",
    "                with torch.no_grad():  # Reduce memory usage\n",
    "                    cell_mask = (mask_tensor == cell_id).bool()\n",
    "                    cell_area = torch.sum(cell_mask).item()\n",
    "                    \n",
    "                    if cell_area == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    # Calculate centroid\n",
    "                    y_indices, x_indices = torch.where(cell_mask)\n",
    "                    centroid_y = torch.mean(y_indices.float()).item()\n",
    "                    centroid_x = torch.mean(x_indices.float()).item()\n",
    "                \n",
    "                cell_data = {\n",
    "                    'label': int(cell_id),\n",
    "                    'area': int(cell_area),\n",
    "                    'centroid': (float(centroid_y), float(centroid_x)),\n",
    "                    'ctcf': {},\n",
    "                    'mean': {},\n",
    "                    'total': {},\n",
    "                    'bg_value': {}\n",
    "                }\n",
    "                \n",
    "                # Process all channels\n",
    "                for ch in range(image_tensor.shape[2]):\n",
    "                    with torch.no_grad():  # Reduce memory usage\n",
    "                        channel_data = image_tensor[:, :, ch]\n",
    "                        bg_value = bg_models[ch]['mean'] if ch in bg_models else 0\n",
    "                        cell_data['bg_value'][ch] = float(bg_value)\n",
    "                        \n",
    "                        # GPU-accelerated measurements\n",
    "                        cell_pixels = torch.masked_select(channel_data, cell_mask)\n",
    "                        total_intensity = torch.sum(cell_pixels).item()\n",
    "                        mean_intensity = torch.mean(cell_pixels).item() if cell_pixels.numel() > 0 else 0\n",
    "                        ctcf = total_intensity - (cell_area * bg_value)\n",
    "                        \n",
    "                        cell_data['total'][ch] = float(total_intensity)\n",
    "                        cell_data['mean'][ch] = float(mean_intensity)\n",
    "                        cell_data['ctcf'][ch] = float(ctcf)\n",
    "                \n",
    "                measurements.append(cell_data)\n",
    "            \n",
    "            # Free GPU memory after each batch\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        cells_per_sec = total_cells / total_time\n",
    "        print(f\"GPU CTCF measurement complete: {total_cells} cells in {total_time:.2f}s ({cells_per_sec:.2f} cells/sec)\")\n",
    "        \n",
    "        return measurements\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU memory error: {str(e)}. Falling back to chunked GPU processing.\")\n",
    "        traceback.print_exc()\n",
    "        measurements = {}  \n",
    "        return measurements # Return empty list in case of error\n",
    "\n",
    "def measure_cells_ctcf_3d_cpu(image, cell_masks, bg_models, config=None):\n",
    "    \"\"\"\n",
    "    Measure CTCF for all cells in 3D z-stack data using CPU processing\n",
    "    \n",
    "    Parameters:\n",
    "    - image: 3D multi-channel image array (Z, Y, X, C)\n",
    "    - cell_masks: 3D integer mask with cell labels (Z, Y, X)\n",
    "    - bg_models: Background models for each channel and potentially each z-slice\n",
    "    - config: Configuration dictionary\n",
    "    \n",
    "    Returns:\n",
    "    - List of cell measurements\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Get unique cell labels\n",
    "    unique_labels = np.unique(cell_masks)\n",
    "    unique_labels = unique_labels[unique_labels > 0]  # Skip background (0)\n",
    "    total_cells = len(unique_labels)\n",
    "    \n",
    "    if total_cells == 0:\n",
    "        print(\"No cells found in 3D mask.\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"Measuring 3D CTCF for {total_cells} cells using parallel CPU processing...\")\n",
    "    \n",
    "    # Determine optimal batch size and number of workers\n",
    "    max_workers = config.get('max_workers', min(os.cpu_count(), 8))\n",
    "    batch_size = config.get('batch_size', max(5, total_cells // (max_workers * 2)))\n",
    "    \n",
    "    # Create batches of cell labels\n",
    "    label_batches = [unique_labels[i:i + batch_size] for i in range(0, len(unique_labels), batch_size)]\n",
    "    print(f\"Processing {len(label_batches)} batches with up to {max_workers} workers\")\n",
    "    \n",
    "    # Prepare partial function with fixed arguments\n",
    "    process_batch_func = partial(\n",
    "        process_cell_batch_3d,\n",
    "        image=image,\n",
    "        cell_masks=cell_masks,\n",
    "        bg_models=bg_models,\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    # Process batches in parallel\n",
    "    results = []\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        batch_results = list(\n",
    "            tqdm(\n",
    "                executor.map(process_batch_func, label_batches),\n",
    "                total=len(label_batches),\n",
    "                desc=\"Processing 3D cell batches\"\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Combine batch results\n",
    "        for batch_result in batch_results:\n",
    "            results.extend(batch_result)\n",
    "    \n",
    "    # Final timing\n",
    "    total_time = time.time() - start_time\n",
    "    cells_per_sec = total_cells / (total_time + 1e-6)\n",
    "    print(f\"3D CTCF measurement complete: {total_cells} cells in {total_time:.2f}s ({cells_per_sec:.2f} cells/sec)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def process_cell_batch_3d(cell_labels, image, cell_masks, bg_models, config=None):\n",
    "    \"\"\"\n",
    "    Process a batch of 3D cells for CTCF measurement (called by parallel worker).\n",
    "    \"\"\"\n",
    "    batch_results = []\n",
    "    \n",
    "    # Get dimensions\n",
    "    z_slices, height, width, n_channels = image.shape\n",
    "    \n",
    "    # Get background model type (per slice or global)\n",
    "    bg_model_per_slice = config.get('bg_model_per_slice', False)\n",
    "    \n",
    "    for label in cell_labels:\n",
    "        # Create mask for this cell only\n",
    "        cell_mask = cell_masks == label\n",
    "        \n",
    "        # Get cell properties in 3D\n",
    "        z_indices, y_indices, x_indices = np.where(cell_mask)\n",
    "        if len(z_indices) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Calculate 3D properties\n",
    "        volume = len(z_indices)  # Total voxels\n",
    "        z_centroid = np.mean(z_indices)\n",
    "        y_centroid = np.mean(y_indices)\n",
    "        x_centroid = np.mean(x_indices)\n",
    "        \n",
    "        # Min and max z-slices for this cell (useful for visualization)\n",
    "        min_z = np.min(z_indices)\n",
    "        max_z = np.max(z_indices)\n",
    "        \n",
    "        # Initialize cell data\n",
    "        cell_data = {\n",
    "            'label': int(label),  # Ensure label is int for serialization\n",
    "            'volume': int(volume),\n",
    "            'centroid_3d': (float(z_centroid), float(y_centroid), float(x_centroid)),\n",
    "            'z_range': (int(min_z), int(max_z)),  # z-range spanned by this cell\n",
    "            'ctcf': {},\n",
    "            'mean': {},\n",
    "            'total': {},\n",
    "            'bg_value': {}\n",
    "        }\n",
    "        \n",
    "        # Process each channel\n",
    "        for ch in range(n_channels):\n",
    "            # Extract the channel data - access the entire channel data at once\n",
    "            channel_data = image[:, :, :, ch]\n",
    "            \n",
    "            # Use efficient boolean indexing for the whole 3D cell\n",
    "            cell_voxels = channel_data[cell_mask]\n",
    "            \n",
    "            bg_value = bg_models[ch]['mean'] if ch in bg_models else 0\n",
    "            \n",
    "            cell_data['bg_value'][ch] = float(bg_value)\n",
    "            \n",
    "            # Calculate 3D measurements\n",
    "            total_intensity = np.sum(cell_voxels)\n",
    "            mean_intensity = np.mean(cell_voxels) if len(cell_voxels) > 0 else 0\n",
    "            ctcf = total_intensity - (volume * bg_value)  # Apply background correction using volume\n",
    "            \n",
    "            # Store results (convert to Python types for serialization)\n",
    "            cell_data['total'][ch] = float(total_intensity)\n",
    "            cell_data['mean'][ch] = float(mean_intensity)\n",
    "            cell_data['ctcf'][ch] = float(ctcf)\n",
    "            \n",
    "        batch_results.append(cell_data)\n",
    "    \n",
    "    return batch_results\n",
    "\n",
    "def measure_cells_ctcf_3d_gpu(image, cell_masks, bg_models, config=None, debug=False):\n",
    "    \"\"\"\n",
    "    GPU-accelerated 3D CTCF measurement for improved performance\n",
    "    \n",
    "    Parameters:\n",
    "    - image: 3D multi-channel image array (Z, Y, X, C)\n",
    "    - cell_masks: 3D integer mask with cell labels (Z, Y, X)\n",
    "    - bg_models: Background models for each channel\n",
    "    - config: Configuration dictionary\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Convert arrays to PyTorch tensors on GPU with explicit data type conversion\n",
    "    device = torch.device('cuda')\n",
    "    try:\n",
    "        # Handle 3D data - rearrange to (Z, Y, X, C)\n",
    "        if len(image.shape) == 4:\n",
    "            z_slices, height, width, channels = image.shape\n",
    "        else:\n",
    "            raise ValueError(\"Expected 4D input for 3D data (Z, Y, X, C)\")\n",
    "\n",
    "        # Convert to float32 since uint16 is not supported by all operations\n",
    "        image_tensor = torch.from_numpy(image).to(device).float()\n",
    "        mask_tensor = torch.from_numpy(cell_masks).to(device)\n",
    "        \n",
    "        # Get unique cell IDs for processing\n",
    "        cell_ids = torch.unique(mask_tensor)[1:]  # Skip 0 (background)\n",
    "        total_cells = len(cell_ids)\n",
    "        print(f\"Measuring 3D CTCF for {total_cells} cells across {channels} channels on GPU...\")\n",
    "        \n",
    "        # Process in smaller batches for 3D data to avoid GPU memory issues\n",
    "        batch_size = config.get('gpu_batch_size_3d', min(100, total_cells))\n",
    "        measurements = []\n",
    "        \n",
    "        for batch_start in tqdm(range(0, total_cells, batch_size), desc=\"Processing 3D cell batches\"):\n",
    "            batch_end = min(batch_start + batch_size, total_cells)\n",
    "            batch_ids = cell_ids[batch_start:batch_end]\n",
    "            \n",
    "            # Process each cell in the batch\n",
    "            for cell_idx in range(len(batch_ids)):\n",
    "                cell_id = batch_ids[cell_idx].item()\n",
    "                \n",
    "                # Create binary mask for this cell\n",
    "                with torch.no_grad():  # Reduce memory usage\n",
    "                    cell_mask = (mask_tensor == cell_id).bool()\n",
    "                    cell_volume = torch.sum(cell_mask).item()\n",
    "                    \n",
    "                    if cell_volume == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    # Calculate 3D centroid\n",
    "                    z_indices, y_indices, x_indices = torch.where(cell_mask)\n",
    "                    centroid_z = torch.mean(z_indices.float()).item()\n",
    "                    centroid_y = torch.mean(y_indices.float()).item()\n",
    "                    centroid_x = torch.mean(x_indices.float()).item()\n",
    "                    \n",
    "                    # Get z-range\n",
    "                    min_z = torch.min(z_indices).item()\n",
    "                    max_z = torch.max(z_indices).item()\n",
    "                \n",
    "                cell_data = {\n",
    "                    'label': int(cell_id),\n",
    "                    'volume': int(cell_volume),\n",
    "                    'centroid_3d': (float(centroid_z), float(centroid_y), float(centroid_x)),\n",
    "                    'z_range': (int(min_z), int(max_z)),\n",
    "                    'ctcf': {},\n",
    "                    'mean': {},\n",
    "                    'total': {},\n",
    "                    'bg_value': {}\n",
    "                }\n",
    "                \n",
    "                # Process all channels\n",
    "                for ch in range(image_tensor.shape[3]):\n",
    "                    with torch.no_grad():  # Reduce memory usage\n",
    "                        # Handle background calculation for 3D data\n",
    "                        channel_data = image_tensor[:, :, :, ch]\n",
    "                        \n",
    "                        # Calculate bg_value for this channel\n",
    "                        bg_value = bg_models[ch]['mean'] if ch in bg_models else 0                            \n",
    "                        cell_data['bg_value'][ch] = float(bg_value)\n",
    "                        \n",
    "                        # GPU-accelerated measurements for 3D data\n",
    "                        cell_voxels = torch.masked_select(channel_data, cell_mask)\n",
    "                        total_intensity = torch.sum(cell_voxels).item()\n",
    "                        mean_intensity = torch.mean(cell_voxels).item() if cell_voxels.numel() > 0 else 0\n",
    "                        ctcf = total_intensity - (cell_volume * bg_value)\n",
    "                        \n",
    "                        cell_data['total'][ch] = float(total_intensity)\n",
    "                        cell_data['mean'][ch] = float(mean_intensity)\n",
    "                        cell_data['ctcf'][ch] = float(ctcf)\n",
    "                \n",
    "                measurements.append(cell_data)\n",
    "            \n",
    "            # Free GPU memory after each batch\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        cells_per_sec = total_cells / (total_time + 1e-6)\n",
    "        print(f\"GPU 3D CTCF measurement complete: {total_cells} cells in {total_time:.2f}s ({cells_per_sec:.2f} cells/sec)\")\n",
    "        \n",
    "        return measurements\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU memory error for 3D data: {str(e)}. Falling back to CPU.\")\n",
    "        traceback.print_exc()\n",
    "        return measure_cells_ctcf_3d_cpu(image, cell_masks, bg_models, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image_for_cellpose(image, config, bg_models):\n",
    "    \"\"\"Prepare image for CellPose segmentation with background subtraction\"\"\"\n",
    "    if config.get('segmentation_type') == 'nuclei_only':\n",
    "        nuc_channel_idx = config.get('nucleus_channel', 1) - 1\n",
    "        img_to_segment = image[...,nuc_channel_idx].copy()\n",
    "        \n",
    "        # Apply background subtraction if available\n",
    "        if nuc_channel_idx in bg_models:\n",
    "            ch_mean = bg_models[nuc_channel_idx]['mean']\n",
    "            img_to_segment = np.clip(img_to_segment - ch_mean, 0, None)\n",
    "            \n",
    "        return img_to_segment\n",
    "    \n",
    "    elif config.get('segmentation_type') == 'cyto3':\n",
    "        # Use cytoplasm and nucleus channels\n",
    "        cyto_channel_idx = config.get('cytoplasm_channel', 4) - 1\n",
    "        nuc_channel_idx = config.get('nucleus_channel', 1) - 1\n",
    "        \n",
    "        # Create a 2-channel image for CellPose\n",
    "        img_to_segment = np.stack([\n",
    "            image[...,nuc_channel_idx].copy(), \n",
    "            image[...,cyto_channel_idx].copy()\n",
    "        ], axis=-1)\n",
    "        \n",
    "        # Apply background subtraction if available\n",
    "        if nuc_channel_idx in bg_models:\n",
    "            ch_mean = bg_models[nuc_channel_idx]['mean']\n",
    "            img_to_segment[...,0] = np.clip(img_to_segment[...,0] - ch_mean, 0, None)\n",
    "            \n",
    "        if cyto_channel_idx in bg_models:\n",
    "            ch_mean = bg_models[cyto_channel_idx]['mean']\n",
    "            img_to_segment[...,1] = np.clip(img_to_segment[...,1] - ch_mean, 0, None)\n",
    "            \n",
    "        return img_to_segment\n",
    "    \n",
    "    else:\n",
    "        # Default case: use all channels of interest\n",
    "        channels_of_interest = config.get('segmentation_channels', list(range(image.shape[-1])))\n",
    "        print(f\"Using custom segmentation with channels: {[ch+1 for ch in channels_of_interest]}\")\n",
    "\n",
    "        # Create a multi-channel image with the channels of interest\n",
    "        img_to_segment = np.stack([image[...,ch].copy() for ch in channels_of_interest], axis=-1)\n",
    "\n",
    "        # Apply background subtraction if available\n",
    "        for i, ch in enumerate(channels_of_interest):\n",
    "            if ch in bg_models:\n",
    "                ch_mean = bg_models[ch]['mean']\n",
    "                img_to_segment[...,i] = np.clip(img_to_segment[...,i] - ch_mean, 0, None)\n",
    "                print(f\"Applied background subtraction to channel {ch+1} (mean: {ch_mean:.2f})\")\n",
    "\n",
    "        return img_to_segment\n",
    "    \n",
    "def process_experiment_folder(experiment_folder, config, results_dir=None):\n",
    "    \"\"\"\n",
    "    Process a single experiment folder containing TIF/TIFF files\n",
    "    \n",
    "    Parameters:\n",
    "    - experiment_folder: Path to folder containing TIF/TIFF files\n",
    "    - config: Configuration dictionary\n",
    "    - results_dir: Optional custom results directory (if None, one will be created)\n",
    "    \n",
    "    Returns:\n",
    "    - Path to results directory\n",
    "    \"\"\"\n",
    "    # Create results directory if not provided\n",
    "    if results_dir is None:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        exp_name = os.path.basename(experiment_folder)\n",
    "        results_dir = os.path.join(experiment_folder, f\"{exp_name}_Analysis_{timestamp}\")\n",
    "    \n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Get all images in experiment folder\n",
    "    image_files = [f for f in os.listdir(experiment_folder) \n",
    "                  if f.endswith(('.tif', '.tiff')) and not f.startswith('.')]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"No TIF/TIFF files found in {experiment_folder}\")\n",
    "        return results_dir\n",
    "        \n",
    "    print(f\"Found {len(image_files)} images to process in {experiment_folder}\")\n",
    "    \n",
    "    # Initialize CellPose model once\n",
    "    # model_type = \"nuclei\" if config.get('segmentation_type') == 'nuclei_only' else \"cyto3\"\n",
    "    # print(f\"Initializing CellPose model: {model_type}\")\n",
    "    print(\"Initializing CellPose model\")\n",
    "    cellpose_model = models.CellposeModel(gpu=config.get('use_gpu', True))\n",
    "\n",
    "    # Extract configuration\n",
    "    is_3d = config.get('use_3d', False)\n",
    "    \n",
    "    # Process in batches\n",
    "    batch_size = config.get('batch_size', 4)\n",
    "    all_results = []\n",
    "    \n",
    "    for batch_idx in range(0, len(image_files), batch_size):\n",
    "        batch_files = image_files[batch_idx:batch_idx + batch_size]\n",
    "        batch_paths = [os.path.join(experiment_folder, f) for f in batch_files]\n",
    "        \n",
    "        print(f\"Processing batch {batch_idx//batch_size + 1}/{(len(image_files) + batch_size - 1)//batch_size} \"\n",
    "             f\"({len(batch_files)} images)\")\n",
    "        \n",
    "        # 1. LOAD BATCH IMAGES\n",
    "        loaded_images = []\n",
    "        for path in tqdm(batch_paths, desc=\"Loading images\", leave=False):\n",
    "            try:\n",
    "                image = tiff.imread(path)\n",
    "                img_name = os.path.basename(path)\n",
    "                \n",
    "                # Move the shortest axis (channels) to the last index\n",
    "                if is_3d:\n",
    "                    # For 3D, image shape should be (Z, Y, X, C)\n",
    "                    dims = list(image.shape)\n",
    "                    if min(dims) < 5:  # Likely channel dimension if small\n",
    "                        channel_axis = dims.index(min(dims))\n",
    "                        image = np.moveaxis(image, channel_axis, -1)\n",
    "                    else:\n",
    "                        # Assume standard ordering Z,Y,X and add channel dimension if needed\n",
    "                        if len(image.shape) == 3:\n",
    "                            image = image[..., np.newaxis]  # Add channel dimension\n",
    "                else:\n",
    "                    # Standard 2D case\n",
    "                    shortest_axis = np.argmin(image.shape)\n",
    "                    image = np.moveaxis(image, shortest_axis, -1)\n",
    "                \n",
    "                loaded_images.append({\n",
    "                    'path': path,\n",
    "                    'name': img_name,\n",
    "                    'image': image\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {os.path.basename(path)}: {str(e)}\")\n",
    "        \n",
    "        if not loaded_images:\n",
    "            continue\n",
    "        \n",
    "        # For very large 3D volumes, use more aggressive garbage collection\n",
    "        if is_3d and config.get('aggressive_gc', False):\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        # 2. PREPARE FOR BATCH PROCESSING\n",
    "        cellpose_inputs = []\n",
    "        bg_models_by_image = {}\n",
    "        \n",
    "        # Process background sequentially for each image\n",
    "        for img_data in loaded_images:\n",
    "            path = img_data['path']\n",
    "            image = img_data['image']\n",
    "            img_name = img_data['name']\n",
    "            img_base = os.path.splitext(img_name)[0]\n",
    "            \n",
    "            # Calculate background for each channel (SEQUENTIAL)\n",
    "            bg_models = {}\n",
    "            for ch_idx in tqdm(range(image.shape[-1]), desc=\"Background estimation\", leave=False):\n",
    "                channel_data = image[...,ch_idx].copy()  # Make a copy to avoid reference issues\n",
    "                bg_models[ch_idx] = estimate_background_gmm(channel_data, config)\n",
    "                \n",
    "                # Generate background visualization if needed\n",
    "                if config.get('visualize_bg', True):\n",
    "                    visualize_background_mask(\n",
    "                        channel_data, \n",
    "                        bg_models[ch_idx],\n",
    "                        os.path.join(results_dir, f\"{img_base}_bg_mask_ch{ch_idx+1}.png\")\n",
    "                    )\n",
    "            \n",
    "            # Store background models\n",
    "            bg_models_by_image[path] = bg_models\n",
    "            \n",
    "            # Prepare image for CellPose\n",
    "            prepared_img = prepare_image_for_cellpose(image, config, bg_models)\n",
    "            \n",
    "            # Apply downsampling if needed\n",
    "            if config.get('downsample_factor', 1.0) < 1.0:\n",
    "                original_shape = prepared_img.shape[:3] if is_3d else prepared_img.shape[:2]\n",
    "                prepared_img = resample_image(\n",
    "                    prepared_img,\n",
    "                    config.get('downsample_factor')\n",
    "                )\n",
    "                \n",
    "                cellpose_inputs.append({\n",
    "                    'image': prepared_img,\n",
    "                    'orig_path': path,\n",
    "                    'orig_shape': original_shape\n",
    "                })\n",
    "            else:\n",
    "                cellpose_inputs.append({\n",
    "                    'image': prepared_img,\n",
    "                    'orig_path': path,\n",
    "                    'orig_shape': image.shape[:3] if is_3d else image.shape[:2]\n",
    "                })\n",
    "        \n",
    "        # 3. BATCH SEGMENTATION WITH CELLPOSE\n",
    "        print(\"Running CellPose segmentation in batch mode...\")\n",
    "        cell_masks = {}\n",
    "        \n",
    "        # Process batch group with CellPose\n",
    "        # Stack images for batch processing\n",
    "        batch_images = [item['image'] for item in cellpose_inputs]\n",
    "        batch_paths = [item['orig_path'] for item in cellpose_inputs]\n",
    "        \n",
    "        # Configure CellPose parameters\n",
    "        # if config.get('segmentation_type') == 'nuclei_only':\n",
    "        #     channels = [0, 0]  # Standard for nuclei model\n",
    "        # else:\n",
    "        #     channels = [2, 1]  # Standard for cyto model (nuclei, cytoplasm)\n",
    "        \n",
    "\n",
    "        # # # Scale cell diameter based on downsampling\n",
    "        # # if config.get('downsample_factor', 1.0) < 1.0:\n",
    "        # #     cell_diameter = config.get('cell_diameter', 20.0) * config.get('downsample_factor')\n",
    "        # # else:\n",
    "        # #     cell_diameter = config.get('cell_diameter', 20.0)\n",
    "        \n",
    "        try:\n",
    "            # Run batch segmentation\n",
    "            masks, _, _ = cellpose_model.eval(\n",
    "                batch_images,\n",
    "                # channels=channels,\n",
    "                normalize=True,\n",
    "                # diameter=cell_diameter,\n",
    "                do_3D=is_3d,\n",
    "                flow_threshold=config.get('flow_threshold', 0.4),\n",
    "                cellprob_threshold=config.get('cellprob_threshold', 0.0),\n",
    "                anisotropy=config.get('anisotropy', 3.0),\n",
    "            )\n",
    "            \n",
    "            # Handle upscaling if needed\n",
    "            for i, path in enumerate(batch_paths):\n",
    "                # Get original shape for this image\n",
    "                for input_data in cellpose_inputs:\n",
    "                    if input_data['orig_path'] == path:\n",
    "                        orig_shape = input_data['orig_shape']\n",
    "                        \n",
    "                        # Upscale mask if downsampled\n",
    "                        if config.get('downsample_factor', 1.0) < 1.0:\n",
    "                            cell_masks[path] = resize(masks[i], orig_shape, \n",
    "                                                    order=0, preserve_range=True).astype(np.int32)\n",
    "                        else:\n",
    "                            cell_masks[path] = masks[i]\n",
    "                        break\n",
    "            \n",
    "            # Clean up memory\n",
    "            del masks\n",
    "            gc.collect()\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Batch segmentation error: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "            \n",
    "            # Create empty masks for failures\n",
    "            for input_data in cellpose_inputs:\n",
    "                path = input_data['orig_path']\n",
    "                orig_shape = input_data['orig_shape']\n",
    "                cell_masks[path] = np.zeros(orig_shape, dtype=np.int32)\n",
    "\n",
    "        print(\"Batch segmentation complete!\")\n",
    "    \n",
    "        # 4. PARALLEL CTCF MEASUREMENT AND RESULT GENERATION\n",
    "        batch_results = []\n",
    "        \n",
    "        # Process each image (CTCF calculation can be parallel)\n",
    "        for img_data in loaded_images:\n",
    "            path = img_data['path']\n",
    "            img_name = img_data['name']\n",
    "            img_base = os.path.splitext(img_name)[0]\n",
    "            \n",
    "            if path in cell_masks:\n",
    "                # Get mask and background models\n",
    "                masks = cell_masks[path]\n",
    "                bg_models = bg_models_by_image.get(path, {})\n",
    "                \n",
    "                try:\n",
    "                    # Measure cells with GPU or CPU\n",
    "                    cell_measurements = measure_cells(\n",
    "                        img_data['image'], masks, bg_models, config\n",
    "                    )\n",
    "\n",
    "                    # Define channels of interest from config\n",
    "                    channels_of_interest = config.get('channels_of_interest', list(range(img_data['image'].shape[-1])))\n",
    "                    \n",
    "                    # Save cell measurements to CSV\n",
    "                    cell_df = pd.DataFrame([\n",
    "                        {\n",
    "                            'image': img_name,\n",
    "                            'cell_id': i,\n",
    "                            'area': cell['area'] if 'area' in cell else cell.get('volume', 0),\n",
    "                            **{f'channel_{ch+1}_ctcf': cell['ctcf'][ch] for ch in channels_of_interest},\n",
    "                            **{f'channel_{ch+1}_mean': cell['mean'][ch] for ch in channels_of_interest},\n",
    "                            'centroid_x': cell['centroid'][1] if 'centroid' in cell else cell.get('centroid_3d', [0, 0, 0])[2],\n",
    "                            'centroid_y': cell['centroid'][0] if 'centroid' in cell else cell.get('centroid_3d', [0, 0, 0])[1]\n",
    "\n",
    "                        }\n",
    "                        for cell in cell_measurements\n",
    "                    ])\n",
    "                    cell_df.to_csv(os.path.join(results_dir, f\"{img_base}_cells.csv\"), index=False)\n",
    "                    \n",
    "                    # Create visualization if configured\n",
    "                    if config.get('visualize_segmentation', True):\n",
    "                        create_visualization(\n",
    "                            img_data['image'],\n",
    "                            masks,\n",
    "                            cell_measurements,\n",
    "                            os.path.join(results_dir, f\"{img_name}_analysis.png\"),\n",
    "                            debug=config.get('debug', False)\n",
    "                        )\n",
    "                    \n",
    "                    # Create QC region images if configured\n",
    "                    if config.get('save_qc_regions', True):\n",
    "                        save_segmentation_qc_images(\n",
    "                            img_data['image'],\n",
    "                            masks,\n",
    "                            results_dir,\n",
    "                            img_name,\n",
    "                            config\n",
    "                        )\n",
    "                    \n",
    "                    # Summarize results\n",
    "                    channels_of_interest = config.get('channels_of_interest', \n",
    "                                                   list(range(img_data['image'].shape[-1])))\n",
    "                    summary = {\n",
    "                        'image_name': img_name,\n",
    "                        'image_path': path,\n",
    "                        'total_cells': len(cell_measurements)\n",
    "                    }\n",
    "                    \n",
    "                    # Add channel statistics\n",
    "                    for ch in channels_of_interest:\n",
    "                        if ch < img_data['image'].shape[-1]:\n",
    "                            ch_ctcf = [cell['ctcf'][ch] for cell in cell_measurements]\n",
    "                            if ch_ctcf:\n",
    "                                summary[f'channel_{ch+1}_mean_ctcf'] = np.mean(ch_ctcf)\n",
    "                                summary[f'channel_{ch+1}_median_ctcf'] = np.median(ch_ctcf)\n",
    "                                summary[f'channel_{ch+1}_std_ctcf'] = np.std(ch_ctcf)\n",
    "                            else:\n",
    "                                summary[f'channel_{ch+1}_mean_ctcf'] = 0\n",
    "                                summary[f'channel_{ch+1}_median_ctcf'] = 0\n",
    "                                summary[f'channel_{ch+1}_std_ctcf'] = 0\n",
    "                    \n",
    "                    batch_results.append(summary)\n",
    "                    \n",
    "                    # Clean up memory\n",
    "                    del cell_measurements, cell_df\n",
    "                    gc.collect()\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {img_name}: {str(e)}\")\n",
    "                    batch_results.append({\n",
    "                        'image_name': img_name,\n",
    "                        'error': str(e),\n",
    "                        'total_cells': 0\n",
    "                    })\n",
    "            else:\n",
    "                batch_results.append({\n",
    "                    'image_name': img_name,\n",
    "                    'error': \"No mask generated\",\n",
    "                    'total_cells': 0\n",
    "                })\n",
    "        \n",
    "        # Append batch results to all results\n",
    "        all_results.extend(batch_results)\n",
    "        \n",
    "        # Clean up batch memory\n",
    "        del loaded_images, cellpose_inputs, cell_masks, bg_models_by_image, batch_results\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache() if config.get('use_gpu', True) else None\n",
    "    \n",
    "    # Save experiment results\n",
    "    if all_results:\n",
    "        exp_df = pd.DataFrame(all_results)\n",
    "        exp_df.to_csv(os.path.join(results_dir, \"experiment_results.csv\"), index=False)\n",
    "    \n",
    "    print(f\"Experiment processing complete. Results saved to: {results_dir}\")\n",
    "    return results_dir\n",
    "\n",
    "def process_experiments_optimized(main_directory, config):\n",
    "    \"\"\"\n",
    "    Process experiments in a main directory or a single experiment folder\n",
    "    \n",
    "    Parameters:\n",
    "    - main_directory: Path to main directory with multiple experiment folders\n",
    "                     OR path to a single experiment folder with TIF/TIFF files\n",
    "    - config: Configuration dictionary\n",
    "    \n",
    "    Returns:\n",
    "    - Path to results directory\n",
    "    \"\"\"\n",
    "    # Check if the main_directory contains TIF/TIFF files directly\n",
    "    tif_files = [f for f in os.listdir(main_directory) \n",
    "                if f.endswith(('.tif', '.tiff')) and not f.startswith('.')]\n",
    "    \n",
    "    if tif_files:\n",
    "        # This is a single experiment folder - process it directly\n",
    "        print(f\"Processing single experiment folder: {main_directory}\")\n",
    "        return process_experiment_folder(main_directory, config)\n",
    "    \n",
    "    # Create results directory for multiple experiments\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_dir = os.path.join(main_directory, f\"CTCF_Analysis_{timestamp}\")\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Find all experiment folders\n",
    "    experiment_folders = [f.path for f in os.scandir(main_directory) if f.is_dir() \n",
    "                         and not f.name.startswith('.') and not \"CTCF_Analysis\" in f.name]\n",
    "    \n",
    "    # Process each experiment folder\n",
    "    for experiment_folder in experiment_folders:\n",
    "        exp_name = os.path.basename(experiment_folder)\n",
    "        print(f\"\\nProcessing experiment: {exp_name}\")\n",
    "        \n",
    "        # Create experiment results folder\n",
    "        exp_results_dir = os.path.join(results_dir, exp_name)\n",
    "        \n",
    "        # Process this experiment folder\n",
    "        process_experiment_folder(experiment_folder, config, results_dir=exp_results_dir)\n",
    "        \n",
    "    print(f\"All experiments processed. Results saved to: {results_dir}\")\n",
    "    return results_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop Section testing \n",
    "In this section the functions for testing on a small cropped picture of the image are dealigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_central_region(image, crop_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Crop the central region of an image for quick segmentation testing\n",
    "    \n",
    "    Parameters:\n",
    "    - image: The input image (H, W, C)\n",
    "    - crop_ratio: Size of the crop relative to original image (0.1 = 10%)\n",
    "    \n",
    "    Returns:\n",
    "    - cropped_image: The central cropped region\n",
    "    - crop_coords: (y_start, y_end, x_start, x_end) for reference\n",
    "    \"\"\"\n",
    "    # Get image dimensions\n",
    "    h, w, c = image.shape\n",
    "    \n",
    "    # Calculate crop size\n",
    "    crop_h = int(h * crop_ratio)\n",
    "    crop_w = int(w * crop_ratio)\n",
    "    \n",
    "    # Calculate central coordinates\n",
    "    center_y, center_x = h // 2, w // 2\n",
    "    \n",
    "    # Calculate crop boundaries\n",
    "    y_start = center_y - (crop_h // 2)\n",
    "    y_end = center_y + (crop_h // 2)\n",
    "    x_start = center_x - (crop_w // 2)\n",
    "    x_end = center_x + (crop_w // 2)\n",
    "    \n",
    "    # Ensure coordinates are within image bounds\n",
    "    y_start = max(0, y_start)\n",
    "    y_end = min(h, y_end)\n",
    "    x_start = max(0, x_start)\n",
    "    x_end = min(w, x_end)\n",
    "    \n",
    "    # Extract crop\n",
    "    cropped_image = image[y_start:y_end, x_start:x_end, :]\n",
    "    \n",
    "    return cropped_image, (y_start, y_end, x_start, x_end)    \n",
    "\n",
    "def test_segmentation_on_crop(image_path, output_dir, config, crop_ratio=0.1):\n",
    "        \"\"\"\n",
    "        Test segmentation on a central crop of an image\n",
    "        \n",
    "        Parameters:\n",
    "        - image_path: Path to the input image\n",
    "        - output_dir: Directory to save results\n",
    "        - config: Configuration dictionary\n",
    "        - crop_ratio: Size of the crop relative to original image (0.1 = 10%)\n",
    "        \n",
    "        Returns:\n",
    "        - Dictionary with segmentation results and parameters\n",
    "        \"\"\"\n",
    "        # Load image and normalize channels\n",
    "        image = tiff.imread(image_path)\n",
    "        img_name = os.path.basename(image_path)\n",
    "        img_base = os.path.splitext(img_name)[0]\n",
    "        \n",
    "        print(f\"\\nTesting segmentation on cropped region of: {img_name}\")\n",
    "        \n",
    "        # Move the shortest axis (channels) to the last index if needed\n",
    "        shortest_axis = np.argmin(image.shape)\n",
    "        image = np.moveaxis(image, shortest_axis, -1)\n",
    "        \n",
    "        # Crop central region\n",
    "        cropped_image, crop_coords = crop_central_region(image, crop_ratio)\n",
    "        y_start, y_end, x_start, x_end = crop_coords\n",
    "        \n",
    "        print(f\"Original image shape: {image.shape}\")\n",
    "        print(f\"Cropped region shape: {cropped_image.shape}\")\n",
    "        print(f\"Crop coordinates: (y={y_start}:{y_end}, x={x_start}:{x_end})\")\n",
    "        \n",
    "        # Create output directory for this test if it doesn't exist\n",
    "        crop_output_dir = os.path.join(output_dir, f\"{img_base}_crop_test\")\n",
    "        os.makedirs(crop_output_dir, exist_ok=True)\n",
    "        \n",
    "        # 1. Estimate background for the cropped region\n",
    "        print(\"Estimating background using GMM...\")\n",
    "        bg_models = {}\n",
    "        for ch in range(cropped_image.shape[-1]):\n",
    "            channel_data = cropped_image[:,:,ch].copy()\n",
    "            bg_models[ch] = estimate_background_gmm(channel_data)\n",
    "            \n",
    "            # Save background mask visualization\n",
    "            visualize_background_mask(channel_data, bg_models[ch], \n",
    "                                     os.path.join(crop_output_dir, f\"crop_bg_mask_ch{ch+1}.png\"))\n",
    "        \n",
    "        # 2. Segment cells on the cropped region\n",
    "        cell_masks = segment_cells_with_downsampling(cropped_image, config, bg_models)\n",
    "        \n",
    "        # 3. Measure CTCF for each cell in the cropped region\n",
    "        cell_measurements = measure_cells(cropped_image, cell_masks, bg_models)\n",
    "        \n",
    "        # Save visualization of the segmentation results\n",
    "        create_visualization(cropped_image, cell_masks, cell_measurements, \n",
    "                            os.path.join(crop_output_dir, f\"{img_base}_crop_segmentation.png\"), \n",
    "                            debug=True)\n",
    "        \n",
    "        # Create a comparison visualization showing where the crop is from\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Show original with crop region highlighted\n",
    "        plt.subplot(1, 2, 1)\n",
    "        # Use first channel for display or create a composite\n",
    "        if image.shape[-1] >= 3:\n",
    "            display_img = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "            for i in range(min(3, image.shape[-1])):\n",
    "                ch_data = exposure.equalize_adapthist(image[:,:,i])\n",
    "                display_img[:,:,i] = ch_data\n",
    "        else:\n",
    "            display_img = exposure.equalize_adapthist(image[:,:,0])\n",
    "        \n",
    "        plt.imshow(display_img)\n",
    "        plt.gca().add_patch(plt.Rectangle((x_start, y_start), \n",
    "                                         x_end - x_start, \n",
    "                                         y_end - y_start, \n",
    "                                         fill=False, \n",
    "                                         edgecolor='red', \n",
    "                                         linewidth=2))\n",
    "        plt.title('Original Image with Crop Region')\n",
    "        \n",
    "        # Show the cropped region with segmentation overlay\n",
    "        plt.subplot(1, 2, 2)\n",
    "        # Create overlay of segmentation on image\n",
    "        if cropped_image.shape[-1] >= 3:\n",
    "            crop_display = np.zeros((cropped_image.shape[0], cropped_image.shape[1], 3))\n",
    "            for i in range(min(3, cropped_image.shape[-1])):\n",
    "                ch_data = exposure.equalize_adapthist(cropped_image[:,:,i])\n",
    "                crop_display[:,:,i] = ch_data\n",
    "        else:\n",
    "            crop_display = exposure.equalize_adapthist(cropped_image[:,:,0])\n",
    "        \n",
    "        plt.imshow(crop_display)\n",
    "        # Add cell mask overlay\n",
    "        plt.imshow(cell_masks > 0, alpha=0.7, cmap='cool')\n",
    "        plt.title(f'Segmentation on Cropped Region ({len(cell_measurements)} cells)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(crop_output_dir, f\"{img_base}_crop_location.png\"), dpi=150)\n",
    "        plt.close()\n",
    "        \n",
    "        # Save cell measurements to CSV\n",
    "        cell_df = pd.DataFrame([\n",
    "            {\n",
    "                'cell_id': cell['label'],\n",
    "                'area': cell['area'],\n",
    "                **{f'channel_{ch+1}_ctcf': cell['ctcf'][ch] for ch in range(cropped_image.shape[-1])},\n",
    "                **{f'channel_{ch+1}_mean': cell['mean'][ch] for ch in range(cropped_image.shape[-1])},\n",
    "                'centroid_x': cell['centroid'][1],\n",
    "                'centroid_y': cell['centroid'][0]\n",
    "            }\n",
    "            for cell in cell_measurements\n",
    "        ])\n",
    "        cell_df.to_csv(os.path.join(crop_output_dir, f\"{img_base}_crop_cells.csv\"), index=False)\n",
    "        \n",
    "        # Return info about the test\n",
    "        return {\n",
    "            'image_name': img_name,\n",
    "            'crop_region': crop_coords,\n",
    "            'cell_count': len(cell_measurements),\n",
    "            'output_dir': crop_output_dir\n",
    "        }\n",
    "\n",
    "# Test segmentation on a cropped region before full processing\n",
    "def test_segmentation_parameters(image_path, config, crop_ratio=0.1):\n",
    "    \"\"\"Test segmentation parameters on a cropped region of an image\"\"\"\n",
    "    # Create a temporary output directory\n",
    "    output_dir = os.path.join(os.path.dirname(image_path), \"segmentation_tests\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Run the crop test\n",
    "    test_result = test_segmentation_on_crop(\n",
    "        image_path=image_path,\n",
    "        output_dir=output_dir,\n",
    "        config=config,\n",
    "        crop_ratio=crop_ratio\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n✓ Segmentation test complete!\")\n",
    "    print(f\"  - Found {test_result['cell_count']} cells in the cropped region\")\n",
    "    print(f\"  - Results saved to: {test_result['output_dir']}\")\n",
    "    print(\"\\nTIP: Review the results and adjust segmentation parameters in config as needed\")\n",
    "    \n",
    "    return test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Images\n",
    "In this section firstly the configuratin will be set for the segmentation, and a test can be done for an individual file. On the second part, a batch processing of multiple files can be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the configuration for the pipeline\n",
    "config = {\n",
    "    # Hardware settings\n",
    "    'use_gpu': True,  # Set to False to force CPU processing\n",
    "    'auto_detect_gpu': True,  # Auto-detect and use GPU if available\n",
    "    \n",
    "    # CellPose settings\n",
    "    'segmentation_type': 'cyto_and_nuclei',  # or 'nuclei_only'\n",
    "    'segmentation_channels': [0, 1, 3],  # Channels for CellPose-SAM segmentation (Max 3)\n",
    "    'cytoplasm_channel': 4,  # Far Red channel for cytoplasm/membrane (Cyto3 - Model)\n",
    "    'nucleus_channel': 1,    # Blue channel (DAPI) for nuclei         (Cyto3 - Model)\n",
    "    'cell_diameter': 25.0,     # Approximate diameter in pixels       (Cyto3 - Model)\n",
    "    'flow_threshold': 0.4,   # Flow threshold for CellPose\n",
    "    'cellprob_threshold': 0.6,  # Cell probability threshold for CellPose\n",
    "    'downsample_factor': 0.5,  # Downsample factor for speed (1.0 = no downsampling)\n",
    "\n",
    "    \n",
    "    # Visualization settings\n",
    "    'visualize_bg': True,  # Set to False if you don't want intermediate visualizations\n",
    "    'visualize_segmentation': False,  # Show segmentation results\n",
    "    'save_qc_regions': True,  # Save QC regions for review\n",
    "    'qc_region_size': 500,  # Size of the QC region in pixels\n",
    "    \n",
    "    # Other pipeline settings\n",
    "    'channels_of_interest': [0, 1, 2, 3]  # All channels to measure\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_3d_params = {\n",
    "    # 3D specific parameters\n",
    "    'anisotropy': 3.0,  # Z-to-XY resolution ratio (common in microscopy)\n",
    "    'cell_diameter_3d': 30.0,  # Diameter in 3D (usually larger than 2D)\n",
    "    'use_3d': True,         # Flag to enable 3D processing (lowercase 'd')\n",
    "    'gpu_batch_size_3d': 2,  # Process fewer 3D images at once\n",
    "    \n",
    "    'z_downsampling': False,      # Whether to downsample in Z dimension \n",
    "    'aggressive_gc': True,        # More aggressive garbage collection for 3D\n",
    "}\n",
    "# Update your existing config\n",
    "config.update(config_3d_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropped segmentation and background substraction testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_test = select_folder()\n",
    "print(f'>>> Selected folder: {folder_path_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage in your script\n",
    "image_paths = glob.glob(os.path.join(folder_path_test, \"*.tiff\"))\n",
    "if len(image_paths) > 0:\n",
    "    # Test segmentation on first image before batch processing\n",
    "    test_result = test_segmentation_parameters(image_paths[0], config, crop_ratio=0.1)\n",
    "    \n",
    "else:\n",
    "    print(f\"No TIFF images found in {folder_path_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.update({\n",
    "    # Parallelization settings\n",
    "    'max_workers': min(os.cpu_count(), 8),  # Maximum number of parallel workers\n",
    "    'batch_size': 6,                         # Number of images to process in a batch\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_folder = select_folder()\n",
    "print(f'>>> Selected folder: {exp_folder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process single experiment folder\n",
    "results_dir = process_experiment_folder(exp_folder, config)\n",
    "print(f'>>> Experiment processing complete. Results saved to: {results_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".auto_img",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
