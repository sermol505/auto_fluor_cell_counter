{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideal Processing Pipeline for Consistent CTCF in Fluorescence Microscopy\n",
    "\n",
    "Here's a comprehensive pipeline for analyzing fluorescence microscopy images with consistent CTCF measurement across different conditions and microscopes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import necessary libraries\n",
    "import time, os, sys\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "import tifffile as tiff\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import measure, draw, exposure\n",
    "from skimage.transform import resize\n",
    "from skimage.segmentation import find_boundaries\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "import scipy.stats\n",
    "\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "from functools import partial\n",
    "from filelock import FileLock\n",
    "import torch\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 200\n",
    "mpl.use('Agg')  # Set non-interactive backend globally\n",
    "\n",
    "from AutoImgUtils import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version\n",
    "!nvidia-smi\n",
    "\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import core, utils, io, models, metrics, denoise\n",
    "from glob import glob\n",
    "\n",
    "use_GPU = core.use_gpu()\n",
    "yn = ['NO', 'YES']\n",
    "print(f'>>> GPU activated? {yn[use_GPU]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization functions\n",
    "Here the visualization functions are defined, that can be used to save plots regarding the background substraction as well as the segmentation results for quality control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_background_mask(channel_image, bg_model, output_path, n_components=3, enhance_contrast=True):\n",
    "    \"\"\"Visualize background mask from GMM model with distribution plots\"\"\"\n",
    "    # Create figure with 4 subplots (2x2 grid)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12), gridspec_kw={'height_ratios': [3, 1]})\n",
    "    \n",
    "    # Enhance contrast for visualization if requested\n",
    "    if enhance_contrast:\n",
    "        # Use percentile-based contrast stretching (robust to outliers)\n",
    "        p_low, p_high = 2, 98  # Percentiles for contrast stretching\n",
    "        display_img = exposure.rescale_intensity(\n",
    "            channel_image, \n",
    "            in_range=tuple(np.percentile(channel_image, (p_low, p_high))),\n",
    "            out_range='dtype'\n",
    "        )\n",
    "    else:\n",
    "        display_img = channel_image\n",
    "    \n",
    "    # Original image with enhanced contrast\n",
    "    axes[0, 0].imshow(display_img, cmap='gray')\n",
    "    axes[0, 0].set_title('Original Channel' + (' (Contrast Enhanced)' if enhance_contrast else ''))\n",
    "    plt.colorbar(axes[0, 0].get_images()[0], ax=axes[0, 0])\n",
    "    \n",
    "    # Background mask\n",
    "    axes[0, 1].imshow(bg_model['mask'], cmap='hot')\n",
    "    axes[0, 1].set_title(f'Background Mask\\nMean: {bg_model[\"mean\"]:.2f}, Std: {bg_model[\"std\"]:.2f}')\n",
    "    plt.colorbar(axes[0, 1].get_images()[0], ax=axes[0, 1])\n",
    "    \n",
    "    # Original with background highlighted\n",
    "    norm_img = (channel_image - np.min(channel_image)) / (np.max(channel_image) - np.min(channel_image))\n",
    "    rgb_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
    "    \n",
    "    # Highlight background in red\n",
    "    rgb_img[:,:,0][bg_model['mask']] = 1.0  # Set red high for background\n",
    "    rgb_img[:,:,1][bg_model['mask']] = 0.0  # Set green low for background\n",
    "    rgb_img[:,:,2][bg_model['mask']] = 0.0  # Set blue low for background\n",
    "    \n",
    "    axes[1, 0].imshow(rgb_img)\n",
    "    axes[1, 0].set_title('Background Regions (Red)')\n",
    "    \n",
    "    # Plot intensity histogram with GMM distributions\n",
    "    # Modified to use component parameters instead of GMM object\n",
    "    if 'component_weights' in bg_model and 'component_means' in bg_model and 'component_covs' in bg_model:\n",
    "        flat_img = channel_image.flatten()\n",
    "        \n",
    "        # Plot histogram\n",
    "        hist_range = (np.min(flat_img), np.max(flat_img))\n",
    "        n_bins = 100\n",
    "        axes[1, 1].hist(flat_img, bins=n_bins, range=hist_range, density=True, \n",
    "                       alpha=0.6, color='gray', label='Pixel Intensity')\n",
    "        \n",
    "        # Create x values for plotting GMM curves\n",
    "        x = np.linspace(hist_range[0], hist_range[1], 1000)\n",
    "        \n",
    "        # Plot the individual components\n",
    "        colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "        bg_component = bg_model['bg_component']\n",
    "        \n",
    "        for i in range(len(bg_model['component_means'])):\n",
    "            # Calculate component density\n",
    "            weight = bg_model['component_weights'][i]\n",
    "            mean = bg_model['component_means'][i]\n",
    "            std = np.sqrt(bg_model['component_covs'][i])\n",
    "            \n",
    "            # Create a normal distribution for this component\n",
    "            y = weight * scipy.stats.norm.pdf(x, mean, std)\n",
    "            \n",
    "            # Plot with higher alpha for background component\n",
    "            alpha = 0.8 if i == bg_component else 0.5\n",
    "            label = f\"Background (μ={mean:.1f})\" if i == bg_component else f\"Component {i+1} (μ={mean:.1f})\"\n",
    "            axes[1, 1].plot(x, y, color=colors[i % len(colors)], \n",
    "                         alpha=alpha, linewidth=2, label=label)\n",
    "            \n",
    "        axes[1, 1].set_title('Pixel Intensity Distribution')\n",
    "        axes[1, 1].set_xlabel('Pixel Value')\n",
    "        axes[1, 1].set_xscale('log')\n",
    "        axes[1, 1].set_ylabel('Density')\n",
    "        axes[1, 1].legend()\n",
    "        \n",
    "        del flat_img, hist_range, n_bins, x\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=200)\n",
    "    plt.close('all')\n",
    "\n",
    "    del display_img, rgb_img\n",
    "\n",
    "def save_segmentation_qc_images(image, cell_masks, output_dir, img_name, config=None):\n",
    "    \"\"\"\n",
    "    Save quality control images showing zoomed-in regions of segmentation results\n",
    "    \n",
    "    Parameters:\n",
    "    - image: Multi-channel image array\n",
    "    - cell_masks: Integer mask with cell labels\n",
    "    - output_dir: Directory to save output images\n",
    "    - img_name: Base name of the image being processed\n",
    "    - config: Configuration dictionary with QC settings\n",
    "    \"\"\"\n",
    "    if config is None:\n",
    "        config = {}\n",
    "    \n",
    "    # Extract configuration\n",
    "    num_regions = config.get('qc_num_regions', 3)\n",
    "    region_size = config.get('qc_region_size', 400)\n",
    "    channels_to_show = config.get('qc_channels', list(range(image.shape[-1])))\n",
    "    \n",
    "    # Get cell properties and centroids\n",
    "    props = measure.regionprops(cell_masks)\n",
    "    \n",
    "    if len(props) == 0:\n",
    "        print(\"No cells detected for QC visualization\")\n",
    "        return\n",
    "    \n",
    "    # Create QC directory\n",
    "    qc_dir = os.path.join(output_dir, \"qc_regions\")\n",
    "    os.makedirs(qc_dir, exist_ok=True)\n",
    "    \n",
    "    # Select cell regions to display\n",
    "    # Strategy 1: Select cells with most area (likely most interesting)\n",
    "    props_sorted_by_area = sorted(props, key=lambda x: x.area, reverse=True)\n",
    "    \n",
    "    # Select some large cells and some random cells for diversity\n",
    "    selected_props = props_sorted_by_area[:min(num_regions, len(props))]\n",
    "    \n",
    "    # Add some random cells from the remaining population if available\n",
    "    remaining_props = props_sorted_by_area[min(num_regions, len(props)):]\n",
    "    if remaining_props and len(remaining_props) > num_regions:\n",
    "        random_indices = np.random.choice(len(remaining_props), \n",
    "                                         min(num_regions, len(remaining_props)), \n",
    "                                         replace=False)\n",
    "        selected_props.extend([remaining_props[i] for i in random_indices])\n",
    "    \n",
    "    # Process each selected region\n",
    "    for i, prop in enumerate(selected_props):\n",
    "        # Get centroid and bounds for region extraction\n",
    "        y, x = int(prop.centroid[0]), int(prop.centroid[1])\n",
    "        \n",
    "        # Define boundaries ensuring they're within image bounds\n",
    "        h, w = image.shape[0:2]\n",
    "        half_size = region_size // 2\n",
    "        \n",
    "        y1 = max(0, y - half_size)\n",
    "        y2 = min(h, y + half_size)\n",
    "        x1 = max(0, x - half_size)\n",
    "        x2 = min(w, x + half_size)\n",
    "        \n",
    "        # Extract region masks\n",
    "        region_mask = cell_masks[y1:y2, x1:x2]\n",
    "        \n",
    "        # Create figure with rows for each channel and columns for (original, mask overlay)\n",
    "        num_channels = len(channels_to_show)\n",
    "        fig, axes = plt.subplots(num_channels, 2, figsize=(12, 4*num_channels))\n",
    "        \n",
    "        if num_channels == 1:\n",
    "            axes = np.array([axes])  # Make it 2D for consistent indexing\n",
    "            \n",
    "        region_name = f\"region_{i+1}_cell_{prop.label}\"\n",
    "        fig.suptitle(f\"Region {i+1}: Cell {prop.label} (Area: {prop.area}px)\")\n",
    "        \n",
    "        # Process each channel\n",
    "        for ch_idx, ch in enumerate(channels_to_show):\n",
    "            if ch < image.shape[-1]:  # Ensure channel exists\n",
    "                # Extract region for this channel\n",
    "                region_img = image[y1:y2, x1:x2, ch]\n",
    "                \n",
    "                # Normalize for display\n",
    "                p2, p98 = np.percentile(region_img, (2, 98))\n",
    "                region_img_norm = np.clip((region_img - p2) / (p98 - p2) * 255, 0, 255).astype(np.uint8)\n",
    "                \n",
    "                # Display original channel\n",
    "                axes[ch_idx, 0].imshow(region_img_norm, cmap='gray')\n",
    "                axes[ch_idx, 0].set_title(f\"Channel {ch+1}\")\n",
    "                axes[ch_idx, 0].axis('off')\n",
    "                \n",
    "                # Create mask overlay\n",
    "                mask_overlay = np.zeros((*region_img.shape, 4), dtype=np.uint8)\n",
    "                \n",
    "                # Unique colors for each cell in the region\n",
    "                unique_labels = np.unique(region_mask)\n",
    "                unique_labels = unique_labels[unique_labels > 0]  # Skip background\n",
    "                \n",
    "                # Create colorful mask overlay\n",
    "                for label in unique_labels:\n",
    "                    color = np.array(plt.cm.tab10(label % 10)) * 255\n",
    "                    mask_overlay[region_mask == label] = [*color[:3], 128]  # Semi-transparent\n",
    "                    \n",
    "                # Show mask overlaid on original image\n",
    "                axes[ch_idx, 1].imshow(region_img_norm, cmap='gray')\n",
    "                axes[ch_idx, 1].imshow(mask_overlay)\n",
    "                axes[ch_idx, 1].set_title(f\"Channel {ch+1} with segmentation\")\n",
    "                axes[ch_idx, 1].axis('off')\n",
    "        \n",
    "        # Adjust layout and save\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.95)  # Make room for suptitle\n",
    "        region_filename = os.path.join(qc_dir, f\"{os.path.splitext(img_name)[0]}_{region_name}.png\")\n",
    "        plt.savefig(region_filename, dpi=150)\n",
    "        plt.close(fig)\n",
    "    \n",
    "    print(f\"Saved {len(selected_props)} QC region visualizations to {qc_dir}\")\n",
    "\n",
    "def create_visualization(image, masks, measurements, output_path, debug=False):\n",
    "    \"\"\"\n",
    "    Create multi-panel visualization for QC with optimized memory usage and enhanced contrast\n",
    "    \n",
    "    Parameters:\n",
    "    - image: Multi-channel image\n",
    "    - masks: Cell segmentation masks\n",
    "    - measurements: Cell measurements\n",
    "    - output_path: Where to save the visualization\n",
    "    - debug: Enable detailed timing and progress tracking\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if debug:\n",
    "            start_time = time.time()\n",
    "            print(f\"Starting visualization for {output_path}...\")\n",
    "        \n",
    "        # Force garbage collection before starting\n",
    "        gc.collect()\n",
    "        \n",
    "        # Get image dimensions and channel count\n",
    "        h, w, n_channels = image.shape\n",
    "        \n",
    "        # Calculate reasonable figure size to avoid excessive memory usage\n",
    "        max_dim = 2000  # Maximum dimension in pixels\n",
    "        scale_factor = min(1.0, max_dim / max(h, w))\n",
    "        \n",
    "        # Create figure without displaying (reduces memory usage)\n",
    "        dpi = 300  # Mantain good quality\n",
    "        fig_width = (n_channels + 1) * 4  # 4 inches per panel\n",
    "        fig_height = 4  # Fixed height\n",
    "        \n",
    "        # Use Figure directly instead of pyplot to avoid memory leaks\n",
    "        fig = Figure(figsize=(fig_width, fig_height), dpi=dpi)\n",
    "        canvas = FigureCanvasAgg(fig)\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Created figure with size {fig_width}x{fig_height} inches at {dpi} DPI\")\n",
    "            print(f\"Processing {n_channels} channels and {len(measurements)} cells\")\n",
    "        \n",
    "        # Create subplot grid\n",
    "        grid = fig.add_gridspec(1, n_channels + 1)\n",
    "        \n",
    "        # Plot segmentation mask (first panel) with enhanced contrast\n",
    "        if debug:\n",
    "            print(\"Rendering segmentation mask...\")\n",
    "        \n",
    "        ax = fig.add_subplot(grid[0, 0])\n",
    "        \n",
    "        # Convert mask to float for better visualization\n",
    "        mask_display = (masks > 0).astype(float)\n",
    "        # Apply contrast enhancement to make it more visible\n",
    "        mask_display = exposure.equalize_adapthist(mask_display)\n",
    "        ax.imshow(mask_display, cmap='viridis')  # Use viridis for better contrast\n",
    "        ax.set_title('Cell Segmentation (Enhanced)')\n",
    "        ax.axis('off')  # Turn off axes to save memory\n",
    "        \n",
    "        # Only add labels for a subset of cells\n",
    "        if len(measurements) > 0:\n",
    "            if debug:\n",
    "                print(\"Adding cell labels...\")\n",
    "            # Select a random subset of 50 cells or fewer if there are less than 50\n",
    "            num_labels = min(50, len(measurements))\n",
    "            # Use numpy's random choice if measurements is a list, otherwise select first num_labels\n",
    "            if isinstance(measurements, list):\n",
    "                indices = np.random.choice(len(measurements), num_labels, replace=False)\n",
    "                label_subset = [measurements[i] for i in indices]\n",
    "            else:\n",
    "                label_subset = measurements[:num_labels]\n",
    "                \n",
    "            for cell in label_subset:\n",
    "                y, x = cell['centroid']\n",
    "                ax.text(x, y, str(cell['label']), color='red', fontsize=5)\n",
    "        \n",
    "        # Process channels with progress tracking\n",
    "        channel_range = range(n_channels)\n",
    "        if debug:\n",
    "            from tqdm import tqdm\n",
    "            channel_range = tqdm(channel_range, desc=\"Processing channels\")\n",
    "        \n",
    "        for ch_idx, ch in enumerate(channel_range):\n",
    "            if debug:\n",
    "                ch_start = time.time()\n",
    "                \n",
    "            # Create subplot for this channel\n",
    "            ax = fig.add_subplot(grid[0, ch_idx + 1])\n",
    "            \n",
    "            # Get channel data and apply adaptive contrast enhancement\n",
    "            channel_data = image[:,:,ch].copy()  # Make a copy to avoid modifying original\n",
    "            \n",
    "            # Adaptive histogram equalization - best for visualizing local features\n",
    "            enhanced_data = exposure.equalize_adapthist(channel_data, clip_limit=0.03)\n",
    "            \n",
    "            # Display the image\n",
    "            ax.imshow(enhanced_data, cmap='hot')\n",
    "            ax.set_title(f'Channel {ch+1} (Enhanced)')\n",
    "            ax.axis('off')  # Turn off axes to save memory\n",
    "            \n",
    "            # Show cell boundaries efficiently\n",
    "            boundaries = find_boundaries(masks > 0)\n",
    "            ax.imshow(boundaries, alpha=0.3, cmap='cool')\n",
    "            \n",
    "            # Free memory\n",
    "            del channel_data\n",
    "            del enhanced_data\n",
    "            del boundaries\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"  Channel {ch+1} rendered in {time.time() - ch_start:.2f}s\")\n",
    "        \n",
    "        # Adjust layout and save\n",
    "        if debug:\n",
    "            print(\"Saving figure...\")\n",
    "            save_start = time.time()\n",
    "            \n",
    "        fig.tight_layout()\n",
    "        fig.savefig(output_path, bbox_inches='tight')\n",
    "        \n",
    "        # Clean up matplotlib resources explicitly\n",
    "        fig.clf()\n",
    "        canvas.renderer.clear()\n",
    "        del fig\n",
    "        del canvas\n",
    "        \n",
    "        # Force garbage collection\n",
    "        gc.collect()\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Visualization saved in {time.time() - save_start:.2f}s\")\n",
    "            print(f\"Total visualization time: {time.time() - start_time:.2f}s\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in visualization: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        # Ensure cleanup even on error\n",
    "        if 'fig' in locals():\n",
    "            fig.clf()\n",
    "            del fig\n",
    "        if 'canvas' in locals():\n",
    "            canvas.renderer.clear()\n",
    "            del canvas\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background substraction and CellPose based Segmentation Functions\n",
    "Here the main functions for background substraction and cell segmentation based on de cyto3 model are defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for File processing and Directory Handling \n",
    "def process_experiments_batch(main_directory, config):\n",
    "    \"\"\"\n",
    "    Process all experiments in the main directory with improved memory management\n",
    "    \"\"\"\n",
    "    # Create results directory\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_dir = os.path.join(main_directory, f\"CTCF_Analysis_{timestamp}\")\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Find all experiment folders\n",
    "    experiment_folders = [f.path for f in os.scandir(main_directory) if f.is_dir() \n",
    "                         and not f.name.startswith('.') and not \"CTCF_Analysis\" in f.name]\n",
    "    \n",
    "    # Process each experiment folder\n",
    "    for experiment_folder in experiment_folders:\n",
    "        exp_name = os.path.basename(experiment_folder)\n",
    "        print(f\"\\nProcessing experiment: {exp_name}\")\n",
    "        \n",
    "        # Create experiment results folder\n",
    "        exp_results_dir = os.path.join(results_dir, exp_name)\n",
    "        os.makedirs(exp_results_dir, exist_ok=True)\n",
    "        \n",
    "        # Process all images in experiment folder\n",
    "        image_files = [f for f in os.listdir(experiment_folder) \n",
    "                      if f.endswith(('.tif', '.tiff')) and not f.startswith('.')]\n",
    "        \n",
    "        # Create a DataFrame for experiment results instead of list to save memory\n",
    "        exp_results_df = pd.DataFrame()\n",
    "        \n",
    "        for image_file in image_files:\n",
    "            # Full image processing pipeline for each image\n",
    "            img_result = process_single_image(\n",
    "                os.path.join(experiment_folder, image_file),\n",
    "                exp_results_dir,\n",
    "                config\n",
    "            )\n",
    "            \n",
    "            # Append result to DataFrame directly\n",
    "            exp_results_df = pd.concat([exp_results_df, pd.DataFrame([img_result])], ignore_index=True)\n",
    "            \n",
    "            # Force garbage collection after each image\n",
    "            gc.collect()\n",
    "        \n",
    "        # Save experiment results\n",
    "        exp_results_df.to_csv(os.path.join(exp_results_dir, f\"{exp_name}_results.csv\"), index=False)\n",
    "        \n",
    "        # Write to batch summary file incrementally instead of keeping in memory\n",
    "        batch_summary_path = os.path.join(results_dir, \"batch_summary.csv\")\n",
    "        if os.path.exists(batch_summary_path):\n",
    "            exp_results_df.to_csv(batch_summary_path, mode='a', header=False, index=False)\n",
    "        else:\n",
    "            exp_results_df.to_csv(batch_summary_path, index=False)\n",
    "        \n",
    "        # Clear DataFrame to free memory\n",
    "        del exp_results_df\n",
    "        gc.collect()\n",
    "    \n",
    "    print(f\"All experiments processed. Results saved to: {results_dir}\")\n",
    "    return results_dir\n",
    "\n",
    "def process_single_image(image_path, output_dir, config):\n",
    "    \"\"\"Process a single fluorescence microscopy image with improved memory management\"\"\"\n",
    "    try:\n",
    "        # Load image and normalize channels\n",
    "        image = tiff.imread(image_path)\n",
    "        img_name = os.path.basename(image_path)\n",
    "        img_base = os.path.splitext(img_name)[0]\n",
    "\n",
    "        print(f\"\\nProcessing image: {img_name}\")\n",
    "\n",
    "        # Extract debug flag from config\n",
    "        debug = config.get('debug', False)\n",
    "        \n",
    "        # Move the shortest axis (channels) to the last index\n",
    "        shortest_axis = np.argmin(image.shape)\n",
    "        image = np.moveaxis(image, shortest_axis, -1)\n",
    "        \n",
    "        # Extract configuration\n",
    "        channels_of_interest = config.get('channels_of_interest', list(range(image.shape[-1])))\n",
    "        \n",
    "        # 1. BACKGROUND ESTIMATION USING GMM\n",
    "        print(\"Estimating background using GMM...\")\n",
    "        bg_models = {}\n",
    "        for ch in tqdm(range(image.shape[-1]), desc=\"Background estimation\", leave=False):\n",
    "            # Process one channel at a time to reduce memory usage\n",
    "            channel_data = image[:,:,ch].copy()  # Make a copy to avoid reference issues\n",
    "            bg_models[ch] = estimate_background(channel_data,config)\n",
    "            \n",
    "            # Save background mask visualization if needed\n",
    "            if config.get('visualize_bg', True):\n",
    "                visualize_background_mask(channel_data, bg_models[ch], \n",
    "                                         os.path.join(output_dir, f\"{img_base}_bg_mask_ch{ch+1}.png\"))\n",
    "                plt.close('all')  # Ensure all plots are closed\n",
    "            \n",
    "            # Remove channel data from memory\n",
    "            del channel_data\n",
    "        \n",
    "        print(\"Background estimation complete.\")\n",
    "        \n",
    "        # 2. CELL SEGMENTATION USING CELLPOSE\n",
    "        cell_masks = segment_cells_with_downsampling(image, config, bg_models)\n",
    "        \n",
    "        # 3. MEASURE CTCF FOR EACH CELL AND CHANNEL\n",
    "        cell_measurements = measure_cells(image, cell_masks, bg_models, config)\n",
    "        \n",
    "        # Store key results in a DataFrame and save immediately\n",
    "        cell_df = pd.DataFrame([\n",
    "            {\n",
    "                'image': img_name,\n",
    "                'cell_id': i,\n",
    "                'area': cell['area'],\n",
    "                **{f'channel_{ch+1}_ctcf': cell['ctcf'][ch] for ch in channels_of_interest},\n",
    "                **{f'channel_{ch+1}_mean': cell['mean'][ch] for ch in channels_of_interest},\n",
    "                'centroid_x': cell['centroid'][0],\n",
    "                'centroid_y': cell['centroid'][1]\n",
    "            }\n",
    "            for i, cell in enumerate(cell_measurements)\n",
    "        ])\n",
    "        cell_df.to_csv(os.path.join(output_dir, f\"{img_base}_cells.csv\"), index=False)\n",
    "        \n",
    "        # 4. GENERATE VISUALIZATIONS - do this after saving measurements to free memory\n",
    "        if debug:\n",
    "            print(f\"Starting visualization with debug mode...\")\n",
    "        if config.get('visualize_segmentation', True):\n",
    "            create_visualization(image, cell_masks, cell_measurements, \n",
    "                                os.path.join(output_dir, f\"{img_name}_analysis.png\"),\n",
    "                                debug=debug)\n",
    "            \n",
    "            # Explicitly close all plots and collect garbage\n",
    "            plt.close('all')\n",
    "        \n",
    "        if config.get('save_qc_regions', True):\n",
    "            save_segmentation_qc_images(\n",
    "                image, \n",
    "                cell_masks, \n",
    "                output_dir, \n",
    "                img_name, \n",
    "                config\n",
    "            )\n",
    "            \n",
    "        gc.collect()\n",
    "        \n",
    "        # 5. CLEANUP AND RETURN RESULTS\n",
    "        # Create a minimal results dictionary with just the summary stats\n",
    "        results = {\n",
    "            'image_name': img_name,\n",
    "            'total_cells': len(cell_measurements),\n",
    "            'image_path': image_path,\n",
    "        }\n",
    "        \n",
    "        # Add summarized measurements\n",
    "        for ch in channels_of_interest:\n",
    "            ch_ctcf = [cell['ctcf'][ch] for cell in cell_measurements]\n",
    "            results[f'channel_{ch+1}_mean_ctcf'] = np.mean(ch_ctcf)\n",
    "            results[f'channel_{ch+1}_median_ctcf'] = np.median(ch_ctcf)\n",
    "            results[f'channel_{ch+1}_std_ctcf'] = np.std(ch_ctcf)\n",
    "            \n",
    "        # Clean up large objects\n",
    "        del image, cell_masks, cell_measurements, bg_models, cell_df\n",
    "        gc.collect()\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        gc.collect()\n",
    "        return {'image_name': os.path.basename(image_path), 'error': str(e), 'total_cells': 0}\n",
    "\n",
    "def resample_image(image, scale_factor=0.5):\n",
    "    \"\"\"Resample image by the given scale factor\"\"\"\n",
    "    \n",
    "    # Get original dimensions\n",
    "    h, w, c = image.shape\n",
    "    \n",
    "    # Calculate new dimensions\n",
    "    new_h, new_w = int(h * scale_factor), int(w * scale_factor)\n",
    "    \n",
    "    # Resize image\n",
    "    resized = resize(image, (new_h, new_w, c), preserve_range=True, anti_aliasing=True)\n",
    "    \n",
    "    return resized.astype(image.dtype)\n",
    "\n",
    "def check_gpu_availability():\n",
    "    \"\"\"Check if GPU is available for processing\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def estimate_background(channel_image, config):\n",
    "    \"\"\"\n",
    "    Select appropriate background estimation method based on configuration\n",
    "    \n",
    "    Parameters:\n",
    "    - channel_image: 2D array with image channel\n",
    "    - config: Configuration dictionary with parameters\n",
    "    \n",
    "    Returns:\n",
    "    - bg_model: Background model dict with estimation results\n",
    "    \"\"\"\n",
    "    n_components = config.get('bg_components', 3)\n",
    "    \n",
    "    return fast_estimate_background_gmm_cpu(channel_image, n_components)\n",
    "\n",
    "    # # Check if GPU should be used\n",
    "    # use_gpu = config.get('use_gpu', True) \n",
    "    # if use_gpu and config.get('auto_detect_gpu', True):\n",
    "    #     use_gpu = check_gpu_availability()\n",
    "        \n",
    "    # # Select appropriate implementation\n",
    "    # if use_gpu:\n",
    "    #     try:\n",
    "    #         return fast_estimate_background_gmm_gpu(channel_image, n_components)\n",
    "    #     except Exception as e:\n",
    "    #         print(f\"GPU background estimation failed: {str(e)}. Falling back to CPU.\")\n",
    "    #         return fast_estimate_background_gmm_cpu(channel_image, n_components)\n",
    "    # else:\n",
    "    #     return fast_estimate_background_gmm_cpu(channel_image, n_components)\n",
    "\n",
    "def fast_estimate_background_gmm_gpu(channel_image, n_components=3, max_iter=100, tol=1e-3):\n",
    "    \"\"\"\n",
    "    Fully GPU-based Gaussian Mixture Model for background estimation\n",
    "    \n",
    "    Parameters:\n",
    "    - channel_image: 2D numpy array with image channel\n",
    "    - n_components: Number of components\n",
    "    - max_iter: Maximum EM iterations\n",
    "    - tol: Convergence tolerance\n",
    "    \"\"\"\n",
    "    try: \n",
    "        device = torch.device('cuda')\n",
    "    \n",
    "        # Transfer to GPU once\n",
    "        flat_img = torch.from_numpy(channel_image.flatten()).float().to(device).reshape(-1, 1)\n",
    "        n_samples = flat_img.shape[0]\n",
    "        \n",
    "        # Sample if necessary (for large images)\n",
    "        if n_samples > 1000000:\n",
    "            indices = torch.randperm(n_samples, device=device)[:500000]\n",
    "            sample_data = flat_img[indices]\n",
    "        else:\n",
    "            sample_data = flat_img\n",
    "            \n",
    "        # Initialize means with k-means++\n",
    "        min_val, max_val = sample_data.min(), sample_data.max()\n",
    "        \n",
    "        # First mean is random\n",
    "        idx = torch.randint(0, sample_data.shape[0], (1,), device=device)\n",
    "        means = [sample_data[idx]]\n",
    "        \n",
    "        # Select remaining means with k-means++ strategy\n",
    "        for _ in range(1, n_components):\n",
    "            # Calculate distances to closest existing mean\n",
    "            dists = torch.cat([torch.norm(sample_data - mean, dim=1).unsqueeze(1) for mean in means], dim=1)\n",
    "            min_dists, _ = torch.min(dists, dim=1)\n",
    "            \n",
    "            # Sample proportional to squared distance\n",
    "            probs = min_dists ** 2\n",
    "            probs /= probs.sum()\n",
    "            idx = torch.multinomial(probs, 1)\n",
    "            means.append(sample_data[idx])\n",
    "        \n",
    "        # Stack means into tensor\n",
    "        means = torch.cat(means, dim=0)\n",
    "        \n",
    "        # Initialize covariances and weights\n",
    "        data_var = torch.var(sample_data)\n",
    "        covs = torch.ones(n_components, device=device) * data_var\n",
    "        weights = torch.ones(n_components, device=device) / n_components\n",
    "        \n",
    "        # Process in memory-efficient batches\n",
    "        batch_size = 10000  # Adjust based on your GPU memory\n",
    "            \n",
    "        # EM algorithm\n",
    "        log_likelihood = None\n",
    "        for iteration in range(max_iter):\n",
    "            # Prepare accumulators for sufficient statistics\n",
    "            N_k = torch.zeros(n_components, device=device)\n",
    "            mean_numerators = torch.zeros(n_components, 1, device=device)\n",
    "            cov_numerators = torch.zeros(n_components, device=device)\n",
    "            \n",
    "            # Compute log_likelihood in batches\n",
    "            total_log_resp_sum = 0.0\n",
    "            \n",
    "            # Process in batches\n",
    "            for batch_start in range(0, flat_img.shape[0], batch_size):\n",
    "                batch_end = min(batch_start + batch_size, flat_img.shape[0])\n",
    "                batch_data = flat_img[batch_start:batch_end]\n",
    "                \n",
    "                # Create batch responsibility matrix\n",
    "                batch_resp = torch.zeros(batch_end-batch_start, n_components, device=device)\n",
    "                \n",
    "                # E-step for this batch\n",
    "                for k in range(n_components):\n",
    "                    # Multivariate normal PDF (1D case)\n",
    "                    diff = batch_data - means[k]\n",
    "                    exponent = -0.5 * (diff ** 2) / covs[k]\n",
    "                    norm_const = 1.0 / torch.sqrt(2 * torch.pi * covs[k])\n",
    "                    batch_resp[:, k] = weights[k] * norm_const * torch.exp(exponent).squeeze()\n",
    "                \n",
    "                # Normalize responsibilities\n",
    "                resp_sum = torch.sum(batch_resp, dim=1, keepdim=True)\n",
    "                total_log_resp_sum += torch.sum(torch.log(resp_sum)).item()\n",
    "                batch_resp = batch_resp / resp_sum\n",
    "                \n",
    "                # Update sufficient statistics\n",
    "                for k in range(n_components):\n",
    "                    resp_k = batch_resp[:, k].unsqueeze(1)\n",
    "                    N_k[k] += torch.sum(resp_k)\n",
    "                    mean_numerators[k] += torch.sum(resp_k * batch_data, dim=0)\n",
    "                    diff = batch_data - means[k]\n",
    "                    cov_numerators[k] += torch.sum(resp_k * (diff ** 2))\n",
    "                \n",
    "                # Clear batch data from GPU memory\n",
    "                del batch_data, batch_resp, resp_sum\n",
    "            \n",
    "            # Calculate log-likelihood and check convergence\n",
    "            new_log_likelihood = total_log_resp_sum / flat_img.shape[0]\n",
    "            if log_likelihood is not None and abs(new_log_likelihood - log_likelihood) < tol:\n",
    "                break\n",
    "            log_likelihood = new_log_likelihood\n",
    "            \n",
    "            # M-step: Update parameters\n",
    "            weights = N_k / flat_img.shape[0]\n",
    "            \n",
    "            # Update means and covariances\n",
    "            for k in range(n_components):\n",
    "                if N_k[k] > 1e-10:  # Avoid division by zero\n",
    "                    means[k] = mean_numerators[k] / N_k[k]\n",
    "                    covs[k] = cov_numerators[k] / N_k[k]\n",
    "                    covs[k] = torch.clamp(covs[k], min=1e-6)  # Avoid singularity\n",
    "    \n",
    "        # Final prediction using batches\n",
    "        pixel_labels = torch.zeros(flat_img.shape[0], dtype=torch.int64, device=device)\n",
    "        \n",
    "        for batch_start in range(0, flat_img.shape[0], batch_size):\n",
    "            batch_end = min(batch_start + batch_size, flat_img.shape[0])\n",
    "            batch_data = flat_img[batch_start:batch_end]\n",
    "            \n",
    "            # Calculate log probabilities for each component\n",
    "            batch_log_probs = torch.zeros(batch_end-batch_start, n_components, device=device)\n",
    "            \n",
    "            for k in range(n_components):\n",
    "                diff = batch_data - means[k]\n",
    "                log_prob = -0.5 * (diff ** 2) / covs[k]\n",
    "                log_prob -= 0.5 * torch.log(2 * torch.pi * covs[k])\n",
    "                log_prob += torch.log(weights[k])\n",
    "                batch_log_probs[:, k] = log_prob.squeeze()\n",
    "            \n",
    "            # Assign most likely component\n",
    "            _, batch_labels = torch.max(batch_log_probs, dim=1)\n",
    "            pixel_labels[batch_start:batch_end] = batch_labels\n",
    "            \n",
    "            # Free memory\n",
    "            del batch_data, batch_log_probs, batch_labels\n",
    "\n",
    "        # Find background component (lowest mean)\n",
    "        bg_component = torch.argmin(means.squeeze()).item()\n",
    "        bg_mean = means[bg_component].item()\n",
    "        bg_std = torch.sqrt(covs[bg_component]).item()\n",
    "        \n",
    "        # Create background mask\n",
    "        bg_mask = (pixel_labels == bg_component).reshape(channel_image.shape)\n",
    "        \n",
    "        results = {\n",
    "            'mean': bg_mean,\n",
    "            'std': bg_std,\n",
    "            'mask': bg_mask.cpu().numpy(),\n",
    "            'bg_percentage': torch.sum(bg_mask).float().item() / bg_mask.numel() * 100,\n",
    "            'component_means': means.cpu().numpy(),\n",
    "            'component_weights': weights.cpu().numpy(),\n",
    "            'component_covs': covs.cpu().numpy(),\n",
    "            'n_components': n_components,\n",
    "            'bg_component': bg_component\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in GMM background estimation: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        # Return fallback values\n",
    "        return {'mean': 0, 'std': 0, 'mask': np.zeros_like(channel_image, dtype=bool)}\n",
    "\n",
    "def fast_estimate_background_gmm_cpu(channel_image, n_components=3, sample_ratio=0.1, \n",
    "                                max_iter=100, adaptive=False, max_components=6):\n",
    "    \"\"\"\n",
    "    Fast background estimation using GMM with optional adaptive component selection\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Flatten image\n",
    "        flat_img = channel_image.flatten()\n",
    "        \n",
    "        # Downsample by random sampling\n",
    "        n_samples = max(10000, int(sample_ratio * flat_img.size))\n",
    "        indices = np.random.choice(flat_img.size, size=n_samples, replace=False)\n",
    "        sample_data = flat_img[indices].reshape(-1, 1)\n",
    "        \n",
    "        # Select GMM model - adaptive or fixed\n",
    "        if adaptive:\n",
    "            bic_scores = []\n",
    "            models = []\n",
    "            \n",
    "            # Try different numbers of components\n",
    "            for n in range(1, max_components + 1):\n",
    "                # Initialize with K-means for faster convergence\n",
    "                kmeans = KMeans(n_clusters=n, n_init=1, max_iter=100)\n",
    "                kmeans.fit(sample_data)\n",
    "                \n",
    "                # Configure and fit GMM\n",
    "                gmm = GaussianMixture(\n",
    "                    n_components=n, \n",
    "                    random_state=42,\n",
    "                    n_init=1, \n",
    "                    max_iter=max_iter,\n",
    "                    tol=1e-3,\n",
    "                    means_init=kmeans.cluster_centers_\n",
    "                )\n",
    "                \n",
    "                gmm.fit(sample_data)\n",
    "                bic_scores.append(gmm.bic(sample_data))\n",
    "                models.append(gmm)\n",
    "                \n",
    "                del kmeans\n",
    "                \n",
    "            # Select model with lowest BIC score\n",
    "            best_idx = np.argmin(bic_scores)\n",
    "            gmm = models[best_idx]\n",
    "            n_components = models[best_idx].n_components\n",
    "            print(f\"Adaptive GMM selected {n_components} components with BIC: {bic_scores[best_idx]:.2f}\")\n",
    "            \n",
    "            # Clean up unused models\n",
    "            for i, model in enumerate(models):\n",
    "                if i != best_idx:\n",
    "                    del model\n",
    "            models = None\n",
    "        else:\n",
    "            # Non-adaptive - just use specified components\n",
    "            # Initialize with K-means for faster convergence\n",
    "            kmeans = KMeans(n_clusters=n_components, n_init=1, max_iter=100)\n",
    "            kmeans.fit(sample_data)\n",
    "            \n",
    "            # Configure GMM and fit\n",
    "            gmm = GaussianMixture(\n",
    "                n_components=n_components,\n",
    "                random_state=42,\n",
    "                n_init=1,\n",
    "                max_iter=max_iter,\n",
    "                tol=1e-3,\n",
    "                means_init=kmeans.cluster_centers_\n",
    "            )\n",
    "            gmm.fit(sample_data)\n",
    "            del kmeans\n",
    "        \n",
    "        # Extract model parameters\n",
    "        means = gmm.means_.flatten()\n",
    "        covs = np.array([gmm.covariances_[i].flatten()[0] for i in range(gmm.n_components)])\n",
    "        weights = gmm.weights_\n",
    "        \n",
    "        # Identify background component (lowest mean)\n",
    "        bg_component = np.argmin(means)\n",
    "        bg_mean = means[bg_component]\n",
    "        bg_std = np.sqrt(covs[bg_component])\n",
    "        \n",
    "        # Use original model to predict components - more efficient\n",
    "        pixel_labels = gmm.predict(flat_img.reshape(-1, 1))\n",
    "        bg_mask = (pixel_labels == bg_component).reshape(channel_image.shape)\n",
    "        \n",
    "        # Clean up sample data to free memory\n",
    "        del sample_data, flat_img, pixel_labels\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'mean': bg_mean,\n",
    "            'std': bg_std,\n",
    "            'mask': bg_mask,\n",
    "            'bg_percentage': np.sum(bg_mask) / bg_mask.size * 100,\n",
    "            'component_means': means,\n",
    "            'component_weights': weights,\n",
    "            'component_covs': covs,\n",
    "            'n_components': n_components,\n",
    "            'bg_component': bg_component,\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in GMM background estimation: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        # Return fallback values\n",
    "        return {'mean': 0, 'std': 0, 'mask': np.zeros_like(channel_image, dtype=bool)}\n",
    "    \n",
    "def estimate_background_gmm(channel_image, n_components=3, adaptive=False, max_components=6):\n",
    "    \"\"\"\n",
    "    Estimate background using Gaussian Mixture Model\n",
    "    \n",
    "    Parameters:\n",
    "    - channel_image: 2D array with image channel\n",
    "    - n_components: Number of GMM components (default=3)\n",
    "    - adaptive: If True, select optimal components using BIC (default=False)\n",
    "    - max_components: Maximum number of components to try if adaptive=True\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with background statistics and fitted GMM model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Flatten image for GMM\n",
    "    flat_img = channel_image.flatten().reshape(-1, 1)\n",
    "    \n",
    "    # If adaptive component selection is requested\n",
    "    if adaptive:\n",
    "        bic_scores = []\n",
    "        models = []\n",
    "        \n",
    "        # Try different numbers of components\n",
    "        for n in range(1, max_components + 1):\n",
    "            gmm = GaussianMixture(n_components=n, random_state=42, n_init=3)\n",
    "            gmm.fit(flat_img)\n",
    "            bic_scores.append(gmm.bic(flat_img))\n",
    "            models.append(gmm)\n",
    "        \n",
    "        # Select model with lowest BIC score\n",
    "        best_idx = np.argmin(bic_scores)\n",
    "        gmm = models[best_idx]\n",
    "        n_components = best_idx + 1  # Update n_components to the selected value\n",
    "        print(f\"Adaptive GMM selected {n_components} components with BIC: {bic_scores[best_idx]:.2f}\")\n",
    "    else:\n",
    "        # Fit GMM model with specified components\n",
    "        gmm = GaussianMixture(n_components=n_components, random_state=42, n_init=3)\n",
    "        gmm.fit(flat_img)\n",
    "    \n",
    "    # Identify background component (lowest mean)\n",
    "    means = gmm.means_.flatten()\n",
    "    bg_component = np.argmin(means)\n",
    "    \n",
    "    # Get background statistics\n",
    "    bg_mean = means[bg_component]\n",
    "    bg_std = np.sqrt(gmm.covariances_[bg_component].flatten()[0])\n",
    "    \n",
    "    # Create background mask \n",
    "    pixel_labels = gmm.predict(flat_img)\n",
    "    bg_mask = (pixel_labels == bg_component).reshape(channel_image.shape)\n",
    "    \n",
    "    # Calculate background percentage\n",
    "    bg_percentage = np.sum(bg_mask) / bg_mask.size * 100\n",
    "    \n",
    "    return {\n",
    "        'mean': bg_mean,\n",
    "        'std': bg_std,\n",
    "        'mask': bg_mask,\n",
    "        'gmm': gmm,  # Store the fitted model\n",
    "        'bg_percentage': bg_percentage,\n",
    "        'component_means': means,\n",
    "        'n_components': n_components,\n",
    "        'bg_component': bg_component\n",
    "    }\n",
    "\n",
    "def segment_cells_cellpose(image, config, bg_models=None):\n",
    "\n",
    "    \"\"\"Cell segmentation using CellPose with optimized memory usage\"\"\"\n",
    "    io.logger_setup()\n",
    "    \n",
    "    # Extract the right channels for segmentation\n",
    "    cyto_channel_idx = config.get('cytoplasm_channel', 4) - 1 \n",
    "    nuc_channel_idx = config.get('nucleus_channel', 1) - 1\n",
    "    \n",
    "    # Choose model based on segmentation type\n",
    "    if config.get('segmentation_type') == 'nuclei_only':\n",
    "        model = models.Cellpose(gpu=config.get('use_gpu', True), model_type='nuclei')\n",
    "        cellpose_channels = [0, 0]  # Standard for nuclei model\n",
    "        \n",
    "        # For single-channel segmentation\n",
    "        img_to_segment = image[:,:,nuc_channel_idx].copy()\n",
    "        \n",
    "        # Apply background subtraction if needed\n",
    "        if bg_models is not None and nuc_channel_idx in bg_models:\n",
    "            ch_mean = bg_models[nuc_channel_idx]['mean']\n",
    "            img_to_segment = np.clip(img_to_segment - ch_mean, 0, None)\n",
    "            print(f\"Channel {nuc_channel_idx}: Subtracted mean background {ch_mean:.2f}\")\n",
    "            \n",
    "    else:\n",
    "        model = models.Cellpose(gpu=config.get('use_gpu', True), model_type=\"cyto3\")\n",
    "        cellpose_channels = [2, 1]  # Standard for cyto model: 1=nuclei, 2=cyto\n",
    "        \n",
    "        # Create channels array with proper mapping between original and stacked indices\n",
    "        channel_mapping = [cyto_channel_idx, nuc_channel_idx] \n",
    "        \n",
    "        # Create the segmentation image \n",
    "        img_to_segment = np.stack([image[:,:,nuc_channel_idx], image[:,:,cyto_channel_idx]], axis=-1).copy()\n",
    "        \n",
    "        # Apply background subtraction with correct index mapping\n",
    "        if bg_models is not None:\n",
    "            for i, orig_idx in enumerate(channel_mapping):\n",
    "                if orig_idx in bg_models:\n",
    "                    ch_mean = bg_models[orig_idx]['mean']\n",
    "                    img_to_segment[:,:,i] = np.clip(img_to_segment[:,:,i] - ch_mean, 0, None)\n",
    "                    print(f\"Channel {orig_idx} (stack position {i}): Subtracted mean background {ch_mean:.2f}\")\n",
    "    \n",
    "    print(f\"Running Cellpose with channels: {ch+1}\" for ch in cellpose_channels)\n",
    "    print(f\"Image shape for segmentation: {img_to_segment.shape}\")\n",
    "    \n",
    "    # Run segmentation with debug info\n",
    "    try:\n",
    "        masks, flows, styles, diams = model.eval(\n",
    "            img_to_segment, \n",
    "            channels=cellpose_channels,\n",
    "            diameter=config.get('cell_diameter', 20.0),\n",
    "            flow_threshold=config.get('flow_threshold', 0.4),\n",
    "            cellprob_threshold=config.get('cellprob_threshold', 0.0),\n",
    "            normalize=True,\n",
    "            progress=True\n",
    "        )\n",
    "        \n",
    "        # Free memory\n",
    "        del img_to_segment\n",
    "        if 'flows' in locals() and flows is not None:\n",
    "            del flows\n",
    "        if 'styles' in locals() and styles is not None:\n",
    "            del styles\n",
    "        if 'diams' in locals() and diams is not None:\n",
    "            del diams\n",
    "        gc.collect()\n",
    "        \n",
    "        print(f\"Segmentation complete! Found {len(np.unique(masks))-1} objects\")\n",
    "        return masks\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR in Cellpose: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        return np.zeros(image.shape[:2], dtype=np.int32)\n",
    "\n",
    "def segment_cells_with_downsampling(image, config, bg_models=None):\n",
    "    \"\"\"Segment cells with better memory management\"\"\"\n",
    "    # Get downsampling factor from config\n",
    "    downsample_factor = config.get('downsample_factor', 1.0)\n",
    "    \n",
    "    try:\n",
    "        if downsample_factor >= 1.0:\n",
    "            # Process at original resolution\n",
    "            masks = segment_cells_cellpose(image, config, bg_models)\n",
    "            return masks\n",
    "        \n",
    "        # Downsample image for processing\n",
    "        small_image = resample_image(image, downsample_factor)\n",
    "        \n",
    "        # Adjust cell diameter for downsampled image\n",
    "        small_config = config.copy()\n",
    "        small_config['cell_diameter'] = config.get('cell_diameter', 20.0) * downsample_factor\n",
    "        \n",
    "        # Run segmentation on smaller image\n",
    "        small_masks = segment_cells_cellpose(small_image, small_config, bg_models)\n",
    "        \n",
    "        # Free memory before upsampling\n",
    "        del small_image\n",
    "        gc.collect()\n",
    "        \n",
    "        # Upsample masks to original size\n",
    "        masks_upscaled = resize(small_masks, image.shape[0:2], order=0, preserve_range=True)\n",
    "        masks_upscaled = masks_upscaled.astype(np.int32)\n",
    "        \n",
    "        # Free memory\n",
    "        del small_masks\n",
    "        \n",
    "        return masks_upscaled\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in segmentation: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        # Return empty mask in case of error\n",
    "        return np.zeros(image.shape[:2], dtype=np.int32)\n",
    "\n",
    "def measure_cells(image, cell_masks, bg_models, config, debug=False):\n",
    "    \"\"\"\n",
    "    Unified CTCF measurement function that uses GPU if available/configured\n",
    "    \n",
    "    Parameters:\n",
    "    - image: Multi-channel image array\n",
    "    - cell_masks: Integer mask with cell labels\n",
    "    - bg_models: Background models for each channel\n",
    "    - config: Configuration dictionary\n",
    "    - debug: Enable detailed timing and debugging outputs\n",
    "    \n",
    "    Returns:\n",
    "    - List of cell measurements\n",
    "    \"\"\"\n",
    "    # Check if GPU should be used\n",
    "    use_gpu = config.get('use_gpu', True)\n",
    "    if use_gpu and config.get('auto_detect_gpu', True):\n",
    "        use_gpu = check_gpu_availability()\n",
    "    \n",
    "    # Select appropriate implementation\n",
    "    if use_gpu:\n",
    "        try:\n",
    "            return measure_cells_ctcf_gpu(image, cell_masks, bg_models, debug)\n",
    "        except Exception as e:\n",
    "            print(f\"GPU CTCF measurement failed: {str(e)}. Falling back to CPU.\")\n",
    "            return measure_cells_ctcf(image, cell_masks, bg_models, debug)\n",
    "    else:\n",
    "        return measure_cells_ctcf(image, cell_masks, bg_models, debug)\n",
    "    \n",
    "def measure_cells_ctcf(image, cell_masks, bg_models, debug=False):\n",
    "    \"\"\"\n",
    "    Measure CTCF for all cells and channels with progress tracking and debugging\n",
    "    \n",
    "    Parameters:\n",
    "    - image: Multi-channel image array\n",
    "    - cell_masks: Integer mask with cell labels\n",
    "    - bg_models: Background models for each channel\n",
    "    - debug: Enable detailed timing and debugging outputs\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Get properties of each cell\n",
    "    props = measure.regionprops(cell_masks)\n",
    "    measurements = []\n",
    "    \n",
    "    # Create progress bar\n",
    "    total_cells = len(props)\n",
    "    print(f\"Measuring CTCF for {total_cells} cells across {image.shape[-1]} channels...\")\n",
    "    \n",
    "    # Process cells with progress bar\n",
    "    for i, prop in enumerate(tqdm(props, desc=\"Measuring cells\", leave=False)):\n",
    "        cell_start = time.time()\n",
    "        \n",
    "        # Basic cell properties\n",
    "        cell_data = {\n",
    "            'label': prop.label,\n",
    "            'area': prop.area,\n",
    "            'centroid': prop.centroid,\n",
    "            'ctcf': {},\n",
    "            'mean': {},\n",
    "            'total': {},\n",
    "            'bg_value': {}\n",
    "        }\n",
    "        \n",
    "        # Get cell mask (this can be optimized by using prop.coords directly)\n",
    "        mask = cell_masks == prop.label\n",
    "        \n",
    "        # Process all channels with a nested progress bar if debugging\n",
    "        channels_iter = tqdm(range(image.shape[-1]), desc=f\"Cell {i+1}/{total_cells} channels\", \n",
    "                            leave=False, disable=not debug)\n",
    "        \n",
    "        for ch in channels_iter:\n",
    "            # Extract channel and cell region\n",
    "            channel = image[:,:,ch]\n",
    "            \n",
    "            # Use vectorized operation instead of creating intermediate mask\n",
    "            # This is faster than doing channel[mask]\n",
    "            cell_region = np.take(channel, prop.coords[:, 0], axis=0)\n",
    "            cell_region = np.take(cell_region, prop.coords[:, 1], axis=1)\n",
    "            \n",
    "            # Background value\n",
    "            bg_value = bg_models[ch]['mean']\n",
    "            cell_data['bg_value'][ch] = bg_value\n",
    "            \n",
    "            # Calculate measurements\n",
    "            total_intensity = np.sum(cell_region)\n",
    "            mean_intensity = np.mean(cell_region)\n",
    "            \n",
    "            # CTCF = Integrated Density - (Area × Mean Background)\n",
    "            ctcf = total_intensity - (prop.area * bg_value)\n",
    "            \n",
    "            # Store results\n",
    "            cell_data['total'][ch] = total_intensity\n",
    "            cell_data['mean'][ch] = mean_intensity\n",
    "            cell_data['ctcf'][ch] = ctcf\n",
    "            \n",
    "        measurements.append(cell_data)\n",
    "        \n",
    "        # Print debug info periodically\n",
    "        if debug and (i == 0 or i == total_cells-1 or i % max(1, total_cells//100) == 0):\n",
    "            cell_time = time.time() - cell_start\n",
    "            print(f\"  Cell {i+1}/{total_cells} processed in {cell_time:.3f}s\")\n",
    "    \n",
    "    # Final timing\n",
    "    total_time = time.time() - start_time\n",
    "    cells_per_sec = total_cells / total_time\n",
    "    print(f\"CTCF measurement complete: {total_cells} cells in {total_time:.2f}s ({cells_per_sec:.2f} cells/sec)\")\n",
    "    \n",
    "    return measurements\n",
    "\n",
    "def measure_cells_ctcf_gpu(image, cell_masks, bg_models, debug=False):\n",
    "    \"\"\"GPU-accelerated CTCF measurement for improved performance\"\"\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Convert arrays to PyTorch tensors on GPU with explicit data type conversion\n",
    "    device = torch.device('cuda')\n",
    "    # Convert to float32 since uint16 is not supported by all operations\n",
    "    image_tensor = torch.from_numpy(image).to(device).float()\n",
    "    mask_tensor = torch.from_numpy(cell_masks).to(device)\n",
    "    \n",
    "    # Get unique cell IDs for processing\n",
    "    cell_ids = torch.unique(mask_tensor)[1:]  # Skip 0 (background)\n",
    "    total_cells = len(cell_ids)\n",
    "    print(f\"Measuring CTCF for {total_cells} cells across {image.shape[-1]} channels on GPU...\")\n",
    "    \n",
    "    # Prepare results container\n",
    "    measurements = []\n",
    "    \n",
    "    # Process in batches if there are many cells\n",
    "    batch_size = 500  # Adjust based on your GPU memory\n",
    "    for batch_start in tqdm(range(0, total_cells, batch_size), desc=\"Processing cell batches\"):\n",
    "        batch_end = min(batch_start + batch_size, total_cells)\n",
    "        batch_ids = cell_ids[batch_start:batch_end]\n",
    "        \n",
    "        # Process each cell in the batch\n",
    "        for cell_idx in range(len(batch_ids)):\n",
    "            cell_id = batch_ids[cell_idx].item()\n",
    "            \n",
    "            # Create binary mask for this cell\n",
    "            cell_mask = (mask_tensor == cell_id).bool()\n",
    "            cell_area = torch.sum(cell_mask).item()\n",
    "            \n",
    "            # Calculate centroid\n",
    "            y_indices, x_indices = torch.where(cell_mask)\n",
    "            centroid_y = torch.mean(y_indices.float()).item()\n",
    "            centroid_x = torch.mean(x_indices.float()).item()\n",
    "            \n",
    "            cell_data = {\n",
    "                'label': cell_id,\n",
    "                'area': cell_area,\n",
    "                'centroid': (centroid_y, centroid_x),\n",
    "                'ctcf': {},\n",
    "                'mean': {},\n",
    "                'total': {},\n",
    "                'bg_value': {}\n",
    "            }\n",
    "            \n",
    "            # Process all channels using GPU operations\n",
    "            for ch in range(image_tensor.shape[2]):\n",
    "                channel_data = image_tensor[:, :, ch]  # Already float32 from earlier conversion\n",
    "                bg_value = bg_models[ch]['mean']\n",
    "                cell_data['bg_value'][ch] = bg_value\n",
    "                \n",
    "                # GPU-accelerated measurements\n",
    "                cell_pixels = torch.masked_select(channel_data, cell_mask)\n",
    "                total_intensity = torch.sum(cell_pixels).item()\n",
    "                mean_intensity = torch.mean(cell_pixels).item()\n",
    "                ctcf = total_intensity - (cell_area * bg_value)\n",
    "                \n",
    "                cell_data['total'][ch] = total_intensity\n",
    "                cell_data['mean'][ch] = mean_intensity\n",
    "                cell_data['ctcf'][ch] = ctcf\n",
    "            \n",
    "            measurements.append(cell_data)\n",
    "        \n",
    "        # Free GPU memory after each batch\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    cells_per_sec = total_cells / total_time\n",
    "    print(f\"GPU CTCF measurement complete: {total_cells} cells in {total_time:.2f}s ({cells_per_sec:.2f} cells/sec)\")\n",
    "    \n",
    "    return measurements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process-Safe Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_matplotlib_for_parallel():\n",
    "    \"\"\"Configure matplotlib for non-interactive use in parallel environments\"\"\"\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')  # Set non-interactive backend before importing pyplot\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.ioff()  # Turn off interactive mode\n",
    "    return plt\n",
    "\n",
    "def visualize_in_main_process(image_data, masks, measurements, bg_models, output_paths, config):\n",
    "    \"\"\"Run all visualizations in the main process after parallel computation\"\"\"\n",
    "    # All visualization happens here, not in worker processes\n",
    "    for img_path, img, mask, measure, bg_model, out_path in zip(\n",
    "        image_data['paths'], image_data['images'], masks, \n",
    "        measurements, bg_models, output_paths):\n",
    "        \n",
    "        img_name = os.path.basename(img_path)\n",
    "        img_base = os.path.splitext(img_name)[0]\n",
    "        \n",
    "        # Generate visualizations safely in main process\n",
    "        if config.get('visualize_bg', True):\n",
    "            for ch in range(img.shape[-1]):\n",
    "                if ch in bg_model:\n",
    "                    visualize_background_mask(\n",
    "                        img[:,:,ch], \n",
    "                        bg_model[ch],\n",
    "                        os.path.join(out_path, f\"{img_base}_bg_mask_ch{ch+1}.png\")\n",
    "                    )\n",
    "        \n",
    "        if config.get('visualize_segmentation', True):\n",
    "            create_visualization(\n",
    "                img, mask, measure,\n",
    "                os.path.join(out_path, f\"{img_name}_analysis.png\"),\n",
    "                debug=config.get('debug', False)\n",
    "            )\n",
    "            \n",
    "        if config.get('save_qc_regions', True):\n",
    "            save_segmentation_qc_images(\n",
    "                img, mask, out_path, img_name, config\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_load_images(image_paths, max_workers):\n",
    "    \"\"\"Load images in parallel using threads (I/O bound task)\"\"\"\n",
    "    loaded_images = []\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(load_image_safe, path): path for path in image_paths}\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            path = futures[future]\n",
    "            try:\n",
    "                img_data = future.result()\n",
    "                loaded_images.append(img_data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {os.path.basename(path)}: {str(e)}\")\n",
    "                loaded_images.append({\n",
    "                    'path': path, \n",
    "                    'name': os.path.basename(path), \n",
    "                    'error': str(e)\n",
    "                })\n",
    "    \n",
    "    return loaded_images\n",
    "\n",
    "def load_image_safe(image_path):\n",
    "    \"\"\"Thread-safe image loading function\"\"\"\n",
    "    # Note: tifffile is thread-safe for reading\n",
    "    image = tiff.imread(image_path)\n",
    "    img_name = os.path.basename(image_path)\n",
    "    \n",
    "    # Move the shortest axis (channels) to the last index\n",
    "    shortest_axis = np.argmin(image.shape)\n",
    "    image = np.moveaxis(image, shortest_axis, -1)\n",
    "    \n",
    "    return {'path': image_path, 'name': img_name, 'image': image}\n",
    "\n",
    "def fast_estimate_background_gmm_cpu_parallel_safe(channel_data, n_components=3, sample_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Process-safe background estimation function without matplotlib dependencies\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        # Flatten image and ensure it's a copy\n",
    "        flat_img = channel_data.flatten().copy()\n",
    "        \n",
    "        # Downsample by random sampling for efficiency\n",
    "        n_samples = max(10000, int(sample_ratio * flat_img.size))\n",
    "        indices = np.random.choice(flat_img.size, size=min(n_samples, flat_img.size), replace=False)\n",
    "        sample_data = flat_img[indices].reshape(-1, 1)\n",
    "        \n",
    "        # Initialize with K-means for faster convergence\n",
    "        kmeans = KMeans(n_clusters=n_components, n_init=1, max_iter=100, random_state=42)\n",
    "        kmeans.fit(sample_data)\n",
    "        \n",
    "        # Configure GMM and fit\n",
    "        gmm = GaussianMixture(\n",
    "            n_components=n_components,\n",
    "            random_state=42,\n",
    "            n_init=1,\n",
    "            max_iter=100,\n",
    "            tol=1e-3,\n",
    "            means_init=kmeans.cluster_centers_\n",
    "        )\n",
    "        gmm.fit(sample_data)\n",
    "        \n",
    "        # Clean up K-means\n",
    "        del kmeans\n",
    "        \n",
    "        # Extract model parameters\n",
    "        means = gmm.means_.flatten()\n",
    "        covs = np.array([gmm.covariances_[i].flatten()[0] for i in range(gmm.n_components)])\n",
    "        weights = gmm.weights_\n",
    "        \n",
    "        # Identify background component (lowest mean)\n",
    "        bg_component = np.argmin(means)\n",
    "        bg_mean = means[bg_component]\n",
    "        bg_std = np.sqrt(covs[bg_component])\n",
    "        \n",
    "        # Apply model to full data without storing in memory\n",
    "        # Process in chunks to avoid memory issues\n",
    "        chunk_size = 1000000  # 1 million pixels at a time\n",
    "        pixel_labels = np.zeros_like(flat_img, dtype=np.int32)\n",
    "        \n",
    "        for i in range(0, len(flat_img), chunk_size):\n",
    "            chunk = flat_img[i:i+chunk_size].reshape(-1, 1)\n",
    "            pixel_labels[i:i+chunk_size] = gmm.predict(chunk)\n",
    "            del chunk\n",
    "            \n",
    "        # Create background mask\n",
    "        bg_mask = (pixel_labels == bg_component).reshape(channel_data.shape)\n",
    "        \n",
    "        # Clean up\n",
    "        del sample_data, flat_img, pixel_labels, gmm\n",
    "        \n",
    "        # Return only necessary data (avoid matplotlib outputs)\n",
    "        return {\n",
    "            'mean': float(bg_mean),              # Convert to Python float for pickling\n",
    "            'std': float(bg_std),                # Convert to Python float for pickling\n",
    "            'mask': bg_mask,                     # Boolean array\n",
    "            'bg_percentage': float(np.sum(bg_mask) / bg_mask.size * 100),\n",
    "            'component_means': means.tolist(),   # Convert to list for pickling\n",
    "            'component_weights': weights.tolist(),\n",
    "            'component_covs': covs.tolist(),\n",
    "            'n_components': n_components,\n",
    "            'bg_component': int(bg_component)    # Convert to Python int for pickling\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        error_trace = traceback.format_exc()\n",
    "        # Return error with traceback for debugging\n",
    "        return {'error': str(e), 'traceback': error_trace}\n",
    "    \n",
    "def parallel_estimate_background(valid_images, config, max_workers):\n",
    "    \"\"\"\n",
    "    Process-safe parallel background estimation with improved error handling\n",
    "    \"\"\"\n",
    "    \n",
    "    # Dictionary to store background models by image path\n",
    "    bg_models_by_image = {}\n",
    "    \n",
    "    # Create a list of all tasks (image_path, channel_index, channel_data)\n",
    "    all_tasks = []\n",
    "    for img_data in valid_images:\n",
    "        for ch_idx in range(img_data['image'].shape[-1]):\n",
    "            # Extract channel data as a copy to avoid shared memory issues\n",
    "            channel_data = img_data['image'][:,:,ch_idx].copy()\n",
    "            all_tasks.append((img_data['path'], ch_idx, channel_data))\n",
    "    \n",
    "    # Get components from config\n",
    "    n_components = config.get('bg_components', 3)\n",
    "    \n",
    "    # Process in smaller batches to avoid overwhelming the system\n",
    "    batch_size = min(20, len(all_tasks))\n",
    "    results = []\n",
    "    \n",
    "    # Show progress bar\n",
    "    print(f\"Processing {len(all_tasks)} background estimation tasks in batches of {batch_size}\")\n",
    "    \n",
    "    for batch_start in range(0, len(all_tasks), batch_size):\n",
    "        batch_end = min(batch_start + batch_size, len(all_tasks))\n",
    "        batch = all_tasks[batch_start:batch_end]\n",
    "        \n",
    "        # Use a fresh process pool for each batch to avoid resource leaks\n",
    "        with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "            # Submit all tasks in this batch\n",
    "            futures = []\n",
    "            for img_path, ch_idx, channel_data in batch:\n",
    "                future = executor.submit(\n",
    "                    fast_estimate_background_gmm_cpu_parallel_safe,\n",
    "                    channel_data, \n",
    "                    n_components\n",
    "                )\n",
    "                futures.append((future, img_path, ch_idx))\n",
    "            \n",
    "            # Process results\n",
    "            for future, img_path, ch_idx in tqdm(futures, \n",
    "                                                desc=f\"Batch {batch_start//batch_size+1}/{(len(all_tasks)+batch_size-1)//batch_size}\"):\n",
    "                try:\n",
    "                    bg_model = future.result()\n",
    "                    \n",
    "                    # Check if the result contains an error\n",
    "                    if 'error' in bg_model:\n",
    "                        print(f\"Error in background estimation for {os.path.basename(img_path)} ch{ch_idx+1}: {bg_model['error']}\")\n",
    "                        print(f\"Traceback: {bg_model.get('traceback', 'No traceback available')}\")\n",
    "                        # Use a simple fallback model\n",
    "                        channel_data = next(t[2] for t in batch if t[0] == img_path and t[1] == ch_idx)\n",
    "                        bg_model = {\n",
    "                            'mean': float(np.mean(channel_data)),\n",
    "                            'std': float(np.std(channel_data)),\n",
    "                            'mask': np.zeros(channel_data.shape, dtype=bool),\n",
    "                            'bg_percentage': 0.0,\n",
    "                            'component_means': [float(np.mean(channel_data))],\n",
    "                            'component_weights': [1.0],\n",
    "                            'component_covs': [float(np.var(channel_data))],\n",
    "                            'n_components': 1,\n",
    "                            'bg_component': 0\n",
    "                        }\n",
    "                    \n",
    "                    # Initialize dict for this image if needed\n",
    "                    if img_path not in bg_models_by_image:\n",
    "                        bg_models_by_image[img_path] = {}\n",
    "                        \n",
    "                    # Store result\n",
    "                    bg_models_by_image[img_path][ch_idx] = bg_model\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Future failed for {os.path.basename(img_path)} ch{ch_idx+1}: {str(e)}\")\n",
    "                    # Create a simple fallback background model\n",
    "                    channel_data = next(t[2] for t in batch if t[0] == img_path and t[1] == ch_idx)\n",
    "                    bg_models_by_image.setdefault(img_path, {})[ch_idx] = {\n",
    "                        'mean': float(np.mean(channel_data)),\n",
    "                        'std': float(np.std(channel_data)),\n",
    "                        'mask': np.zeros(channel_data.shape, dtype=bool),\n",
    "                        'bg_percentage': 0.0,\n",
    "                        'component_means': [float(np.mean(channel_data))],\n",
    "                        'component_weights': [1.0],\n",
    "                        'component_covs': [float(np.var(channel_data))],\n",
    "                        'n_components': 1,\n",
    "                        'bg_component': 0\n",
    "                    }\n",
    "    \n",
    "    return bg_models_by_image\n",
    "\n",
    "def measure_cells_parallel_safe(image, cell_masks, bg_models, config):\n",
    "    \"\"\"Process-safe cell measurement function\"\"\"\n",
    "    # Configure matplotlib for this process\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    \n",
    "    # Select GPU or CPU implementation based on config\n",
    "    use_gpu = config.get('use_gpu', True) and check_gpu_availability()\n",
    "    \n",
    "    if use_gpu:\n",
    "        try:\n",
    "            return measure_cells_ctcf_gpu(image, cell_masks, bg_models)\n",
    "        except Exception as e:\n",
    "            print(f\"GPU measurement failed: {str(e)}. Falling back to CPU.\")\n",
    "            return measure_cells_ctcf(image, cell_masks, bg_models)\n",
    "    else:\n",
    "        return measure_cells_ctcf(image, cell_masks, bg_models)\n",
    "    \n",
    "def prepare_image_for_cellpose(image, config, bg_models):\n",
    "    \"\"\"Prepare image for CellPose segmentation with background subtraction\"\"\"\n",
    "    if config.get('segmentation_type') == 'nuclei_only':\n",
    "        nuc_channel_idx = config.get('nucleus_channel', 1) - 1\n",
    "        img_to_segment = image[:,:,nuc_channel_idx].copy()\n",
    "        \n",
    "        # Apply background subtraction if available\n",
    "        if nuc_channel_idx in bg_models:\n",
    "            ch_mean = bg_models[nuc_channel_idx]['mean']\n",
    "            img_to_segment = np.clip(img_to_segment - ch_mean, 0, None)\n",
    "            \n",
    "        return img_to_segment\n",
    "    else:\n",
    "        # Use cytoplasm and nucleus channels\n",
    "        cyto_channel_idx = config.get('cytoplasm_channel', 4) - 1\n",
    "        nuc_channel_idx = config.get('nucleus_channel', 1) - 1\n",
    "        \n",
    "        # Create a 2-channel image for CellPose\n",
    "        img_to_segment = np.stack([\n",
    "            image[:,:,nuc_channel_idx].copy(), \n",
    "            image[:,:,cyto_channel_idx].copy()\n",
    "        ], axis=-1)\n",
    "        \n",
    "        # Apply background subtraction if available\n",
    "        if nuc_channel_idx in bg_models:\n",
    "            ch_mean = bg_models[nuc_channel_idx]['mean']\n",
    "            img_to_segment[:,:,0] = np.clip(img_to_segment[:,:,0] - ch_mean, 0, None)\n",
    "            \n",
    "        if cyto_channel_idx in bg_models:\n",
    "            ch_mean = bg_models[cyto_channel_idx]['mean']\n",
    "            img_to_segment[:,:,1] = np.clip(img_to_segment[:,:,1] - ch_mean, 0, None)\n",
    "            \n",
    "        return img_to_segment\n",
    "\n",
    "\n",
    "def batch_segment_with_cellpose(cellpose_inputs, cellpose_model, config):\n",
    "    \"\"\"Run CellPose segmentation on a batch of images\"\"\"\n",
    "    cell_masks = {}\n",
    "    \n",
    "    # Group images by shape for batch processing\n",
    "    shape_groups = {}\n",
    "    for input_data in cellpose_inputs:\n",
    "        img_shape = input_data['image'].shape\n",
    "        if img_shape not in shape_groups:\n",
    "            shape_groups[img_shape] = []\n",
    "        shape_groups[img_shape].append(input_data)\n",
    "    \n",
    "    # Process each shape group\n",
    "    for shape, group in shape_groups.items():\n",
    "        print(f\"Processing batch of {len(group)} images with shape {shape}\")\n",
    "        \n",
    "        # Stack images for batch processing\n",
    "        batch_images = [item['image'] for item in group]\n",
    "        batch_paths = [item['orig_path'] for item in group]\n",
    "        \n",
    "        # Configure CellPose parameters\n",
    "        if config.get('segmentation_type') == 'nuclei_only':\n",
    "            channels = [0, 0]  # Standard for nuclei model\n",
    "            diameter = config.get('cell_diameter', 20.0) \n",
    "            if config.get('downsample_factor', 1.0) < 1.0:\n",
    "                diameter *= config.get('downsample_factor')\n",
    "        else:\n",
    "            channels = [2, 1]  # Standard for cyto model\n",
    "            diameter = config.get('cell_diameter', 20.0)\n",
    "            if config.get('downsample_factor', 1.0) < 1.0:\n",
    "                diameter *= config.get('downsample_factor')\n",
    "        \n",
    "        # Run batch segmentation\n",
    "        try:\n",
    "            masks, flows, styles, diams = cellpose_model.eval(\n",
    "                batch_images,\n",
    "                channels=channels,\n",
    "                diameter=diameter,\n",
    "                flow_threshold=config.get('flow_threshold', 0.4),\n",
    "                cellprob_threshold=config.get('cellprob_threshold', 0.0),\n",
    "                normalize=True\n",
    "            )\n",
    "            \n",
    "            # Handle upscaling if needed\n",
    "            if config.get('downsample_factor', 1.0) < 1.0:\n",
    "                for i, path in enumerate(batch_paths):\n",
    "                    # Get original shape from loaded images\n",
    "                    for input_data in cellpose_inputs:\n",
    "                        if input_data['orig_path'] == path:\n",
    "                            orig_shape = input_data['image'].shape[:2]\n",
    "                            # Upscale mask\n",
    "                            cell_masks[path] = resize(masks[i], orig_shape, \n",
    "                                                    order=0, preserve_range=True).astype(np.int32)\n",
    "                            break\n",
    "            else:\n",
    "                # Store masks directly\n",
    "                for i, path in enumerate(batch_paths):\n",
    "                    cell_masks[path] = masks[i]\n",
    "                    \n",
    "            # Clean up memory\n",
    "            del masks, flows, styles, diams\n",
    "            gc.collect()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Batch segmentation error: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "            # Create empty masks for failures\n",
    "            for path in batch_paths:\n",
    "                # Find original shape\n",
    "                for input_data in cellpose_inputs:\n",
    "                    if input_data['orig_path'] == path:\n",
    "                        shape = input_data['image'].shape[:2]\n",
    "                        cell_masks[path] = np.zeros(shape, dtype=np.int32)\n",
    "                        break\n",
    "    \n",
    "    return cell_masks\n",
    "\n",
    "def create_cell_dataframe(cell_measurements, img_name, config):\n",
    "    \"\"\"Create a DataFrame from cell measurements\"\"\"\n",
    "    return pd.DataFrame([\n",
    "        {\n",
    "            'image': img_name,\n",
    "            'cell_id': cell['label'],\n",
    "            'area': cell['area'],\n",
    "            **{f'channel_{ch+1}_ctcf': cell['ctcf'][ch] for ch in range(len(cell['ctcf']))},\n",
    "            **{f'channel_{ch+1}_mean': cell['mean'][ch] for ch in range(len(cell['mean']))},\n",
    "            'centroid_x': cell['centroid'][1],\n",
    "            'centroid_y': cell['centroid'][0]\n",
    "        }\n",
    "        for cell in cell_measurements\n",
    "    ])\n",
    "\n",
    "def create_summary_dict(img_name, img_path, cell_measurements, config):\n",
    "    \"\"\"Create a summary dictionary from cell measurements\"\"\"\n",
    "    channels_of_interest = config.get('channels_of_interest', \n",
    "                                     list(range(len(cell_measurements[0]['ctcf']) \n",
    "                                              if cell_measurements else 0)))\n",
    "    \n",
    "    summary = {\n",
    "        'image_name': img_name,\n",
    "        'image_path': img_path,\n",
    "        'total_cells': len(cell_measurements),\n",
    "    }\n",
    "    \n",
    "    # Add channel statistics\n",
    "    for ch in channels_of_interest:\n",
    "        if cell_measurements and ch in cell_measurements[0]['ctcf']:\n",
    "            ch_ctcf = [cell['ctcf'][ch] for cell in cell_measurements]\n",
    "            if ch_ctcf:\n",
    "                summary[f'channel_{ch+1}_mean_ctcf'] = np.mean(ch_ctcf)\n",
    "                summary[f'channel_{ch+1}_median_ctcf'] = np.median(ch_ctcf)\n",
    "                summary[f'channel_{ch+1}_std_ctcf'] = np.std(ch_ctcf)\n",
    "            else:\n",
    "                summary[f'channel_{ch+1}_mean_ctcf'] = 0\n",
    "                summary[f'channel_{ch+1}_median_ctcf'] = 0\n",
    "                summary[f'channel_{ch+1}_std_ctcf'] = 0\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_experiments_batch_parallel(main_directory, config):\n",
    "    \"\"\"\n",
    "    Process experiments with robust parallelization:\n",
    "    - I/O handled in parallel\n",
    "    - Background estimation done sequentially in main process\n",
    "    - CellPose batching (already efficient internally)\n",
    "    - CTCF measurement in parallel\n",
    "    \n",
    "    This trades some speed for reliability.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create results directory\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_dir = os.path.join(main_directory, f\"CTCF_Analysis_{timestamp}\")\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Find all experiment folders\n",
    "    experiment_folders = [f.path for f in os.scandir(main_directory) if f.is_dir() \n",
    "                         and not f.name.startswith('.') and not \"CTCF_Analysis\" in f.name]\n",
    "    \n",
    "    # Get processing parameters from config\n",
    "    max_workers = config.get('max_workers', min(os.cpu_count(), 8))\n",
    "    batch_size = config.get('batch_size', 4)  # Adjust based on available memory\n",
    "    \n",
    "    # Initialize CellPose model in main process\n",
    "    model_type = \"nuclei\" if config.get('segmentation_type') == 'nuclei_only' else \"cyto3\"\n",
    "    print(f\"Initializing CellPose model: {model_type}\")\n",
    "    cellpose_model = models.Cellpose(gpu=config.get('use_gpu', True), model_type=model_type)\n",
    "    \n",
    "    # Process each experiment folder\n",
    "    for experiment_folder in experiment_folders:\n",
    "        exp_name = os.path.basename(experiment_folder)\n",
    "        print(f\"\\nProcessing experiment: {exp_name}\")\n",
    "        \n",
    "        # Create experiment results folder\n",
    "        exp_results_dir = os.path.join(results_dir, exp_name)\n",
    "        os.makedirs(exp_results_dir, exist_ok=True)\n",
    "        \n",
    "        # Get all images in experiment folder\n",
    "        image_files = [f for f in os.listdir(experiment_folder) \n",
    "                      if f.endswith(('.tif', '.tiff')) and not f.startswith('.')]\n",
    "        \n",
    "        # Process in batches\n",
    "        batch_summary_data = []\n",
    "        \n",
    "        for batch_idx in range(0, len(image_files), batch_size):\n",
    "            batch_files = image_files[batch_idx:batch_idx + batch_size]\n",
    "            batch_paths = [os.path.join(experiment_folder, f) for f in batch_files]\n",
    "            \n",
    "            print(f\"Processing batch {batch_idx//batch_size + 1}/{(len(image_files) + batch_size - 1)//batch_size} \" \n",
    "                 f\"({len(batch_files)} images)\")\n",
    "            \n",
    "            # Load images in parallel (I/O bound - parallel is safe)\n",
    "            images = load_images_in_parallel(batch_paths, max_workers)\n",
    "            \n",
    "            # Filter valid images\n",
    "            valid_images = [img for img in images if 'error' not in img]\n",
    "            error_images = [img for img in images if 'error' in img]\n",
    "            \n",
    "            if not valid_images:\n",
    "                print(\"No valid images in this batch\")\n",
    "                continue\n",
    "                \n",
    "            # For each valid image (sequential processing for reliability)\n",
    "            for img_data in valid_images:\n",
    "                img_path = img_data['path']\n",
    "                img_name = img_data['name']\n",
    "                img_base = os.path.splitext(img_name)[0]\n",
    "                image = img_data['image']\n",
    "                \n",
    "                # Background estimation - DO THIS IN MAIN PROCESS\n",
    "                print(f\"Estimating background for {img_name}...\")\n",
    "                bg_models = {}\n",
    "                \n",
    "                for ch_idx in range(image.shape[-1]):\n",
    "                    # Process channel in main process (avoid parallel issues)\n",
    "                    channel_data = image[:,:,ch_idx].copy()\n",
    "                    bg_models[ch_idx] = fast_estimate_background_gmm_cpu(channel_data, \n",
    "                                                                         config.get('bg_components', 3))\n",
    "                    \n",
    "                    # Visualize background if needed\n",
    "                    if config.get('visualize_bg', True):\n",
    "                        visualize_background_mask(channel_data, bg_models[ch_idx],\n",
    "                                              os.path.join(exp_results_dir, f\"{img_base}_bg_mask_ch{ch_idx+1}.png\"))\n",
    "                \n",
    "                # Prepare image for CellPose\n",
    "                if config.get('segmentation_type') == 'nuclei_only':\n",
    "                    nuc_channel_idx = config.get('nucleus_channel', 1) - 1\n",
    "                    img_to_segment = image[:,:,nuc_channel_idx].copy()\n",
    "                    \n",
    "                    # Apply background subtraction if available\n",
    "                    if nuc_channel_idx in bg_models:\n",
    "                        ch_mean = bg_models[nuc_channel_idx]['mean']\n",
    "                        img_to_segment = np.clip(img_to_segment - ch_mean, 0, None)\n",
    "                    \n",
    "                    channels = [0, 0]  # Standard for nuclei model\n",
    "                else:\n",
    "                    # Use cytoplasm and nucleus channels\n",
    "                    cyto_channel_idx = config.get('cytoplasm_channel', 4) - 1\n",
    "                    nuc_channel_idx = config.get('nucleus_channel', 1) - 1\n",
    "                    \n",
    "                    # Create a 2-channel image for CellPose\n",
    "                    img_to_segment = np.stack([\n",
    "                        image[:,:,nuc_channel_idx].copy(),\n",
    "                        image[:,:,cyto_channel_idx].copy()\n",
    "                    ], axis=-1)\n",
    "                    \n",
    "                    # Apply background subtraction if available\n",
    "                    if nuc_channel_idx in bg_models:\n",
    "                        ch_mean = bg_models[nuc_channel_idx]['mean']\n",
    "                        img_to_segment[:,:,0] = np.clip(img_to_segment[:,:,0] - ch_mean, 0, None)\n",
    "                    \n",
    "                    if cyto_channel_idx in bg_models:\n",
    "                        ch_mean = bg_models[cyto_channel_idx]['mean']\n",
    "                        img_to_segment[:,:,1] = np.clip(img_to_segment[:,:,1] - ch_mean, 0, None)\n",
    "                    \n",
    "                    channels = [2, 1]  # Standard for cyto model\n",
    "                \n",
    "                # Apply downsampling if needed\n",
    "                if config.get('downsample_factor', 1.0) < 1.0:\n",
    "                    orig_shape = img_to_segment.shape[:2]\n",
    "                    img_to_segment = resample_image(img_to_segment, config.get('downsample_factor'))\n",
    "                    diameter = config.get('cell_diameter', 20.0) * config.get('downsample_factor')\n",
    "                else:\n",
    "                    orig_shape = None\n",
    "                    diameter = config.get('cell_diameter', 20.0)\n",
    "                \n",
    "                # Run CellPose segmentation\n",
    "                print(f\"Running CellPose segmentation for {img_name}...\")\n",
    "                try:\n",
    "                    masks, _, _, _ = cellpose_model.eval(\n",
    "                        img_to_segment,\n",
    "                        channels=channels,\n",
    "                        diameter=diameter,\n",
    "                        flow_threshold=config.get('flow_threshold', 0.4),\n",
    "                        cellprob_threshold=config.get('cellprob_threshold', 0.0),\n",
    "                        normalize=True\n",
    "                    )\n",
    "                    \n",
    "                    # Upsample masks if needed\n",
    "                    if config.get('downsample_factor', 1.0) < 1.0 and orig_shape is not None:\n",
    "                        masks = resize(masks, orig_shape, order=0, preserve_range=True).astype(np.int32)\n",
    "                except Exception as e:\n",
    "                    print(f\"Segmentation error: {str(e)}\")\n",
    "                    masks = np.zeros(image.shape[:2], dtype=np.int32)\n",
    "                \n",
    "                # CTCF measurement can be parallelized safely using multiprocessing\n",
    "                # But for simplicity and reliability, we'll do it in the main process\n",
    "                print(f\"Measuring CTCF for {img_name}...\")\n",
    "                cell_measurements = measure_cells_ctcf(image, masks, bg_models)\n",
    "                \n",
    "                # Save cell measurements to CSV\n",
    "                cell_df = pd.DataFrame([\n",
    "                    {\n",
    "                        'image': img_name,\n",
    "                        'cell_id': cell['label'],\n",
    "                        'area': cell['area'],\n",
    "                        **{f'channel_{ch+1}_ctcf': cell['ctcf'][ch] for ch in range(image.shape[-1])},\n",
    "                        **{f'channel_{ch+1}_mean': cell['mean'][ch] for ch in range(image.shape[-1])},\n",
    "                        'centroid_x': cell['centroid'][1],\n",
    "                        'centroid_y': cell['centroid'][0]\n",
    "                    }\n",
    "                    for cell in cell_measurements\n",
    "                ])\n",
    "                cell_df.to_csv(os.path.join(exp_results_dir, f\"{img_base}_cells.csv\"), index=False)\n",
    "                \n",
    "                # Create visualizations\n",
    "                if config.get('visualize_segmentation', True):\n",
    "                    create_visualization(\n",
    "                        image, masks, cell_measurements,\n",
    "                        os.path.join(exp_results_dir, f\"{img_name}_analysis.png\"),\n",
    "                        debug=config.get('debug', False)\n",
    "                    )\n",
    "                \n",
    "                if config.get('save_qc_regions', True):\n",
    "                    save_segmentation_qc_images(\n",
    "                        image, masks, \n",
    "                        exp_results_dir, \n",
    "                        img_name, \n",
    "                        config\n",
    "                    )\n",
    "                \n",
    "                # Create summary\n",
    "                channels_of_interest = config.get('channels_of_interest', list(range(image.shape[-1])))\n",
    "                summary = {\n",
    "                    'image_name': img_name,\n",
    "                    'image_path': img_path,\n",
    "                    'total_cells': len(cell_measurements),\n",
    "                }\n",
    "                \n",
    "                # Add channel statistics\n",
    "                for ch in channels_of_interest:\n",
    "                    if ch < image.shape[-1]:\n",
    "                        ch_ctcf = [cell['ctcf'][ch] for cell in cell_measurements]\n",
    "                        if ch_ctcf:\n",
    "                            summary[f'channel_{ch+1}_mean_ctcf'] = np.mean(ch_ctcf)\n",
    "                            summary[f'channel_{ch+1}_median_ctcf'] = np.median(ch_ctcf)\n",
    "                            summary[f'channel_{ch+1}_std_ctcf'] = np.std(ch_ctcf)\n",
    "                        else:\n",
    "                            summary[f'channel_{ch+1}_mean_ctcf'] = 0\n",
    "                            summary[f'channel_{ch+1}_median_ctcf'] = 0\n",
    "                            summary[f'channel_{ch+1}_std_ctcf'] = 0\n",
    "                \n",
    "                batch_summary_data.append(summary)\n",
    "                \n",
    "                # Clean up memory\n",
    "                del image, masks, cell_measurements, bg_models, img_to_segment\n",
    "                gc.collect()\n",
    "                if config.get('use_gpu', True):\n",
    "                    torch.cuda.empty_cache()\n",
    "            \n",
    "            # Add error images to batch summary\n",
    "            for img in error_images:\n",
    "                batch_summary_data.append({\n",
    "                    'image_name': img['name'],\n",
    "                    'error': img.get('error', 'Unknown error'),\n",
    "                    'total_cells': 0\n",
    "                })\n",
    "        \n",
    "        # Save batch summary for this experiment\n",
    "        exp_df = pd.DataFrame(batch_summary_data)\n",
    "        exp_df.to_csv(os.path.join(exp_results_dir, f\"{exp_name}_summary.csv\"), index=False)\n",
    "        \n",
    "        # Write to batch summary\n",
    "        batch_summary_path = os.path.join(results_dir, \"batch_summary.csv\")\n",
    "        if os.path.exists(batch_summary_path):\n",
    "            exp_df.to_csv(batch_summary_path, mode='a', header=False, index=False)\n",
    "        else:\n",
    "            exp_df.to_csv(batch_summary_path, index=False)\n",
    "        \n",
    "        # Clean up\n",
    "        del exp_df, batch_summary_data\n",
    "        gc.collect()\n",
    "    \n",
    "    return results_dir\n",
    "\n",
    "def load_images_in_parallel(image_paths, max_workers):\n",
    "    \"\"\"Load images in parallel using threads\"\"\"\n",
    "    import concurrent.futures\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    images = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(load_single_image, path): path for path in image_paths}\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(image_paths), desc=\"Loading images\"):\n",
    "            path = futures[future]\n",
    "            try:\n",
    "                img_data = future.result()\n",
    "                images.append(img_data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {os.path.basename(path)}: {str(e)}\")\n",
    "                images.append({\n",
    "                    'path': path,\n",
    "                    'name': os.path.basename(path),\n",
    "                    'error': str(e)\n",
    "                })\n",
    "    return images\n",
    "\n",
    "def load_single_image(image_path):\n",
    "    \"\"\"Load a single image\"\"\"\n",
    "    import tifffile as tiff\n",
    "    import numpy as np\n",
    "    import os\n",
    "    \n",
    "    image = tiff.imread(image_path)\n",
    "    img_name = os.path.basename(image_path)\n",
    "    \n",
    "    # Move the shortest axis (channels) to the last index\n",
    "    shortest_axis = np.argmin(image.shape)\n",
    "    image = np.moveaxis(image, shortest_axis, -1)\n",
    "    \n",
    "    return {'path': image_path, 'name': img_name, 'image': image}\n",
    "\n",
    "def process_image_batch_parallel(image_paths, output_dir, cellpose_model, config, max_workers):\n",
    "    \"\"\"\n",
    "    Process a batch of images safely with parallel background estimation and CTCF measurement\n",
    "    with improved error handling and process safety\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Load all images in parallel (I/O bound, use threads)\n",
    "    print(\"Loading images in parallel...\")\n",
    "    loaded_images = []\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(load_image_safe, path): path for path in image_paths}\n",
    "        \n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(image_paths)):\n",
    "            path = futures[future]\n",
    "            try:\n",
    "                img_data = future.result()\n",
    "                loaded_images.append(img_data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {os.path.basename(path)}: {str(e)}\")\n",
    "                loaded_images.append({\n",
    "                    'path': path, \n",
    "                    'name': os.path.basename(path), \n",
    "                    'error': str(e)\n",
    "                })\n",
    "    \n",
    "    # Filter out failed loads\n",
    "    valid_images = [img for img in loaded_images if 'error' not in img]\n",
    "    error_images = [img for img in loaded_images if 'error' in img]\n",
    "    \n",
    "    if not valid_images:\n",
    "        print(\"No valid images to process in this batch\")\n",
    "        return [{\n",
    "            'image_name': img['name'],\n",
    "            'error': img.get('error', 'Unknown error'),\n",
    "            'total_cells': 0\n",
    "        } for img in error_images]\n",
    "    \n",
    "    # Step 2: Parallel background estimation with fixed implementation\n",
    "    print(\"Estimating background in parallel...\")\n",
    "    bg_models_by_image = parallel_estimate_background(valid_images, config, max_workers)\n",
    "    \n",
    "    # Step 3: Prepare images for CellPose\n",
    "    cellpose_inputs = []\n",
    "    for img_data in valid_images:\n",
    "        try:\n",
    "            path = img_data['path']\n",
    "            image = img_data['image']\n",
    "            bg_models = bg_models_by_image.get(path, {})\n",
    "            \n",
    "            # Prepare image for segmentation based on config\n",
    "            if config.get('segmentation_type') == 'nuclei_only':\n",
    "                nuc_channel_idx = config.get('nucleus_channel', 1) - 1\n",
    "                img_to_segment = image[:,:,nuc_channel_idx].copy()\n",
    "                \n",
    "                # Apply background subtraction if available\n",
    "                if nuc_channel_idx in bg_models:\n",
    "                    ch_mean = bg_models[nuc_channel_idx]['mean']\n",
    "                    img_to_segment = np.clip(img_to_segment - ch_mean, 0, None)\n",
    "            else:\n",
    "                # Use cytoplasm and nucleus channels\n",
    "                cyto_channel_idx = config.get('cytoplasm_channel', 4) - 1\n",
    "                nuc_channel_idx = config.get('nucleus_channel', 1) - 1\n",
    "                \n",
    "                # Create a 2-channel image for CellPose\n",
    "                img_to_segment = np.stack([\n",
    "                    image[:,:,nuc_channel_idx].copy(), \n",
    "                    image[:,:,cyto_channel_idx].copy()\n",
    "                ], axis=-1)\n",
    "                \n",
    "                # Apply background subtraction if available\n",
    "                if nuc_channel_idx in bg_models:\n",
    "                    ch_mean = bg_models[nuc_channel_idx]['mean']\n",
    "                    img_to_segment[:,:,0] = np.clip(img_to_segment[:,:,0] - ch_mean, 0, None)\n",
    "                    \n",
    "                if cyto_channel_idx in bg_models:\n",
    "                    ch_mean = bg_models[cyto_channel_idx]['mean']\n",
    "                    img_to_segment[:,:,1] = np.clip(img_to_segment[:,:,1] - ch_mean, 0, None)\n",
    "            \n",
    "            # Apply downsampling if needed\n",
    "            if config.get('downsample_factor', 1.0) < 1.0:\n",
    "                from skimage.transform import resize\n",
    "                original_shape = img_to_segment.shape[:2]\n",
    "                img_to_segment = resize(\n",
    "                    img_to_segment, \n",
    "                    (int(original_shape[0] * config['downsample_factor']), \n",
    "                     int(original_shape[1] * config['downsample_factor'])), \n",
    "                    preserve_range=True,\n",
    "                    anti_aliasing=True\n",
    "                ).astype(img_to_segment.dtype)\n",
    "            \n",
    "            cellpose_inputs.append({\n",
    "                'image': img_to_segment,\n",
    "                'orig_path': path,\n",
    "                'name': img_data['name'],\n",
    "                'orig_shape': image.shape[:2]\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error preparing {img_data['name']} for segmentation: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    # Step 4: Run CellPose on batch in main process\n",
    "    print(\"Running CellPose segmentation...\")\n",
    "    cell_masks = {}\n",
    "    \n",
    "    # Process each image with CellPose\n",
    "    for input_data in tqdm(cellpose_inputs, desc=\"Segmenting cells\"):\n",
    "        try:\n",
    "            path = input_data['orig_path']\n",
    "            img_to_segment = input_data['image']\n",
    "            orig_shape = input_data['orig_shape']\n",
    "            \n",
    "            # Determine CellPose parameters\n",
    "            if config.get('segmentation_type') == 'nuclei_only':\n",
    "                channels = [0, 0]\n",
    "            else:\n",
    "                channels = [2, 1]\n",
    "                \n",
    "            # Calculate cell diameter for potentially downsampled image\n",
    "            if config.get('downsample_factor', 1.0) < 1.0:\n",
    "                cell_diameter = config.get('cell_diameter', 20.0) * config.get('downsample_factor')\n",
    "            else:\n",
    "                cell_diameter = config.get('cell_diameter', 20.0)\n",
    "            \n",
    "            # Run segmentation\n",
    "            masks, _, _, _ = cellpose_model.eval(\n",
    "                img_to_segment,\n",
    "                channels=channels,\n",
    "                diameter=cell_diameter,\n",
    "                flow_threshold=config.get('flow_threshold', 0.4),\n",
    "                cellprob_threshold=config.get('cellprob_threshold', 0.0),\n",
    "                normalize=True\n",
    "            )\n",
    "            \n",
    "            # Upsample masks if image was downsampled\n",
    "            if config.get('downsample_factor', 1.0) < 1.0:\n",
    "                from skimage.transform import resize\n",
    "                masks = resize(masks, orig_shape, order=0, preserve_range=True).astype(np.int32)\n",
    "                \n",
    "            cell_masks[path] = masks\n",
    "            \n",
    "            # Free memory\n",
    "            del img_to_segment\n",
    "            gc.collect()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Segmentation error for {input_data['name']}: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "            # Create empty mask on error\n",
    "            cell_masks[input_data['orig_path']] = np.zeros(input_data['orig_shape'], dtype=np.int32)\n",
    "    \n",
    "    # Step 5: Parallel CTCF measurement (processed one at a time to reduce memory pressure)\n",
    "    print(\"Measuring CTCF...\")\n",
    "    results = []\n",
    "    \n",
    "    for img_data in tqdm(valid_images, desc=\"Processing measurements\"):\n",
    "        path = img_data['path']\n",
    "        if path in cell_masks:\n",
    "            try:\n",
    "                # Get mask and background models\n",
    "                masks = cell_masks[path]\n",
    "                bg_models = bg_models_by_image.get(path, {})\n",
    "                \n",
    "                # Measure cells in main process to avoid serialization issues\n",
    "                cell_measurements = measure_cells_ctcf(\n",
    "                    img_data['image'],\n",
    "                    masks,\n",
    "                    bg_models\n",
    "                )\n",
    "                \n",
    "                # Save cell measurements to CSV\n",
    "                img_name = img_data['name']\n",
    "                img_base = os.path.splitext(img_name)[0]\n",
    "                \n",
    "                # Create dataframe and save \n",
    "                cell_df = pd.DataFrame([\n",
    "                    {\n",
    "                        'image': img_name,\n",
    "                        'cell_id': cell['label'],\n",
    "                        'area': cell['area'],\n",
    "                        **{f'channel_{ch+1}_ctcf': cell['ctcf'][ch] for ch in range(img_data['image'].shape[-1])},\n",
    "                        **{f'channel_{ch+1}_mean': cell['mean'][ch] for ch in range(img_data['image'].shape[-1])},\n",
    "                        'centroid_x': cell['centroid'][1],\n",
    "                        'centroid_y': cell['centroid'][0]\n",
    "                    }\n",
    "                    for cell in cell_measurements\n",
    "                ])\n",
    "                cell_df.to_csv(os.path.join(output_dir, f\"{img_base}_cells.csv\"), index=False)\n",
    "                \n",
    "                # Create summaries\n",
    "                channels_of_interest = config.get('channels_of_interest', list(range(img_data['image'].shape[-1])))\n",
    "                summary = {\n",
    "                    'image_name': img_name,\n",
    "                    'image_path': path,\n",
    "                    'total_cells': len(cell_measurements),\n",
    "                }\n",
    "                \n",
    "                # Add channel statistics\n",
    "                for ch in channels_of_interest:\n",
    "                    if ch < img_data['image'].shape[-1]:\n",
    "                        ch_ctcf = [cell['ctcf'][ch] for cell in cell_measurements]\n",
    "                        if ch_ctcf:\n",
    "                            summary[f'channel_{ch+1}_mean_ctcf'] = np.mean(ch_ctcf)\n",
    "                            summary[f'channel_{ch+1}_median_ctcf'] = np.median(ch_ctcf)\n",
    "                            summary[f'channel_{ch+1}_std_ctcf'] = np.std(ch_ctcf)\n",
    "                        else:\n",
    "                            summary[f'channel_{ch+1}_mean_ctcf'] = 0\n",
    "                            summary[f'channel_{ch+1}_median_ctcf'] = 0\n",
    "                            summary[f'channel_{ch+1}_std_ctcf'] = 0\n",
    "                \n",
    "                # Create visualizations if configured\n",
    "                if config.get('visualize_segmentation', True):\n",
    "                    create_visualization(\n",
    "                        img_data['image'], \n",
    "                        masks, \n",
    "                        cell_measurements,\n",
    "                        os.path.join(output_dir, f\"{img_name}_analysis.png\"),\n",
    "                        debug=config.get('debug', False)\n",
    "                    )\n",
    "                \n",
    "                if config.get('save_qc_regions', True):\n",
    "                    save_segmentation_qc_images(\n",
    "                        img_data['image'], \n",
    "                        masks, \n",
    "                        output_dir, \n",
    "                        img_name, \n",
    "                        config\n",
    "                    )\n",
    "                \n",
    "                # Create background visualizations if configured\n",
    "                if config.get('visualize_bg', True):\n",
    "                    for ch in range(img_data['image'].shape[-1]):\n",
    "                        if ch in bg_models:\n",
    "                            visualize_background_mask(\n",
    "                                img_data['image'][:,:,ch], \n",
    "                                bg_models[ch],\n",
    "                                os.path.join(output_dir, f\"{img_base}_bg_mask_ch{ch+1}.png\")\n",
    "                            )\n",
    "                \n",
    "                results.append(summary)\n",
    "                \n",
    "                # Clean up memory\n",
    "                del cell_measurements, cell_df\n",
    "                gc.collect()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_data['name']}: {str(e)}\")\n",
    "                traceback.print_exc()\n",
    "                results.append({\n",
    "                    'image_name': img_data['name'],\n",
    "                    'error': str(e),\n",
    "                    'total_cells': 0\n",
    "                })\n",
    "        else:\n",
    "            results.append({\n",
    "                'image_name': img_data['name'],\n",
    "                'error': \"No mask generated\",\n",
    "                'total_cells': 0\n",
    "            })\n",
    "    \n",
    "    # Add failed images to results\n",
    "    for img in error_images:\n",
    "        results.append({\n",
    "            'image_name': img['name'],\n",
    "            'error': img.get('error', 'Unknown error'),\n",
    "            'total_cells': 0\n",
    "        })\n",
    "    \n",
    "    # Clean up memory\n",
    "    del valid_images, loaded_images, bg_models_by_image, cell_masks, cellpose_inputs\n",
    "    gc.collect()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 5. Add File Locking to Prevent Race Conditions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use in any function that writes to shared files\n",
    "def safely_write_csv(dataframe, filepath):\n",
    "    \"\"\"Thread-safe CSV writing with file locking\"\"\"\n",
    "    with FileLock(f\"{filepath}.lock\"):\n",
    "        dataframe.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop Section testing \n",
    "In this section the functions for testing on a small cropped picture of the image are dealigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_central_region(image, crop_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Crop the central region of an image for quick segmentation testing\n",
    "    \n",
    "    Parameters:\n",
    "    - image: The input image (H, W, C)\n",
    "    - crop_ratio: Size of the crop relative to original image (0.1 = 10%)\n",
    "    \n",
    "    Returns:\n",
    "    - cropped_image: The central cropped region\n",
    "    - crop_coords: (y_start, y_end, x_start, x_end) for reference\n",
    "    \"\"\"\n",
    "    # Get image dimensions\n",
    "    h, w, c = image.shape\n",
    "    \n",
    "    # Calculate crop size\n",
    "    crop_h = int(h * crop_ratio)\n",
    "    crop_w = int(w * crop_ratio)\n",
    "    \n",
    "    # Calculate central coordinates\n",
    "    center_y, center_x = h // 2, w // 2\n",
    "    \n",
    "    # Calculate crop boundaries\n",
    "    y_start = center_y - (crop_h // 2)\n",
    "    y_end = center_y + (crop_h // 2)\n",
    "    x_start = center_x - (crop_w // 2)\n",
    "    x_end = center_x + (crop_w // 2)\n",
    "    \n",
    "    # Ensure coordinates are within image bounds\n",
    "    y_start = max(0, y_start)\n",
    "    y_end = min(h, y_end)\n",
    "    x_start = max(0, x_start)\n",
    "    x_end = min(w, x_end)\n",
    "    \n",
    "    # Extract crop\n",
    "    cropped_image = image[y_start:y_end, x_start:x_end, :]\n",
    "    \n",
    "    return cropped_image, (y_start, y_end, x_start, x_end)    \n",
    "\n",
    "def test_segmentation_on_crop(image_path, output_dir, config, crop_ratio=0.1):\n",
    "        \"\"\"\n",
    "        Test segmentation on a central crop of an image\n",
    "        \n",
    "        Parameters:\n",
    "        - image_path: Path to the input image\n",
    "        - output_dir: Directory to save results\n",
    "        - config: Configuration dictionary\n",
    "        - crop_ratio: Size of the crop relative to original image (0.1 = 10%)\n",
    "        \n",
    "        Returns:\n",
    "        - Dictionary with segmentation results and parameters\n",
    "        \"\"\"\n",
    "        # Load image and normalize channels\n",
    "        image = tiff.imread(image_path)\n",
    "        img_name = os.path.basename(image_path)\n",
    "        img_base = os.path.splitext(img_name)[0]\n",
    "        \n",
    "        print(f\"\\nTesting segmentation on cropped region of: {img_name}\")\n",
    "        \n",
    "        # Move the shortest axis (channels) to the last index if needed\n",
    "        shortest_axis = np.argmin(image.shape)\n",
    "        image = np.moveaxis(image, shortest_axis, -1)\n",
    "        \n",
    "        # Crop central region\n",
    "        cropped_image, crop_coords = crop_central_region(image, crop_ratio)\n",
    "        y_start, y_end, x_start, x_end = crop_coords\n",
    "        \n",
    "        print(f\"Original image shape: {image.shape}\")\n",
    "        print(f\"Cropped region shape: {cropped_image.shape}\")\n",
    "        print(f\"Crop coordinates: (y={y_start}:{y_end}, x={x_start}:{x_end})\")\n",
    "        \n",
    "        # Create output directory for this test if it doesn't exist\n",
    "        crop_output_dir = os.path.join(output_dir, f\"{img_base}_crop_test\")\n",
    "        os.makedirs(crop_output_dir, exist_ok=True)\n",
    "        \n",
    "        # 1. Estimate background for the cropped region\n",
    "        print(\"Estimating background using GMM...\")\n",
    "        bg_models = {}\n",
    "        for ch in range(cropped_image.shape[-1]):\n",
    "            channel_data = cropped_image[:,:,ch].copy()\n",
    "            bg_models[ch] = fast_estimate_background_gmm_cpu(channel_data)\n",
    "            \n",
    "            # Save background mask visualization\n",
    "            visualize_background_mask(channel_data, bg_models[ch], \n",
    "                                     os.path.join(crop_output_dir, f\"crop_bg_mask_ch{ch+1}.png\"))\n",
    "        \n",
    "        # 2. Segment cells on the cropped region\n",
    "        cell_masks = segment_cells_with_downsampling(cropped_image, config, bg_models)\n",
    "        \n",
    "        # 3. Measure CTCF for each cell in the cropped region\n",
    "        cell_measurements = measure_cells(cropped_image, cell_masks, bg_models)\n",
    "        \n",
    "        # Save visualization of the segmentation results\n",
    "        create_visualization(cropped_image, cell_masks, cell_measurements, \n",
    "                            os.path.join(crop_output_dir, f\"{img_base}_crop_segmentation.png\"), \n",
    "                            debug=True)\n",
    "        \n",
    "        # Create a comparison visualization showing where the crop is from\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Show original with crop region highlighted\n",
    "        plt.subplot(1, 2, 1)\n",
    "        # Use first channel for display or create a composite\n",
    "        if image.shape[-1] >= 3:\n",
    "            display_img = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "            for i in range(min(3, image.shape[-1])):\n",
    "                ch_data = exposure.equalize_adapthist(image[:,:,i])\n",
    "                display_img[:,:,i] = ch_data\n",
    "        else:\n",
    "            display_img = exposure.equalize_adapthist(image[:,:,0])\n",
    "        \n",
    "        plt.imshow(display_img)\n",
    "        plt.gca().add_patch(plt.Rectangle((x_start, y_start), \n",
    "                                         x_end - x_start, \n",
    "                                         y_end - y_start, \n",
    "                                         fill=False, \n",
    "                                         edgecolor='red', \n",
    "                                         linewidth=2))\n",
    "        plt.title('Original Image with Crop Region')\n",
    "        \n",
    "        # Show the cropped region with segmentation overlay\n",
    "        plt.subplot(1, 2, 2)\n",
    "        # Create overlay of segmentation on image\n",
    "        if cropped_image.shape[-1] >= 3:\n",
    "            crop_display = np.zeros((cropped_image.shape[0], cropped_image.shape[1], 3))\n",
    "            for i in range(min(3, cropped_image.shape[-1])):\n",
    "                ch_data = exposure.equalize_adapthist(cropped_image[:,:,i])\n",
    "                crop_display[:,:,i] = ch_data\n",
    "        else:\n",
    "            crop_display = exposure.equalize_adapthist(cropped_image[:,:,0])\n",
    "        \n",
    "        plt.imshow(crop_display)\n",
    "        # Add cell mask overlay\n",
    "        plt.imshow(cell_masks > 0, alpha=0.7, cmap='cool')\n",
    "        plt.title(f'Segmentation on Cropped Region ({len(cell_measurements)} cells)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(crop_output_dir, f\"{img_base}_crop_location.png\"), dpi=150)\n",
    "        plt.close()\n",
    "        \n",
    "        # Save cell measurements to CSV\n",
    "        cell_df = pd.DataFrame([\n",
    "            {\n",
    "                'cell_id': cell['label'],\n",
    "                'area': cell['area'],\n",
    "                **{f'channel_{ch+1}_ctcf': cell['ctcf'][ch] for ch in range(cropped_image.shape[-1])},\n",
    "                **{f'channel_{ch+1}_mean': cell['mean'][ch] for ch in range(cropped_image.shape[-1])},\n",
    "                'centroid_x': cell['centroid'][1],\n",
    "                'centroid_y': cell['centroid'][0]\n",
    "            }\n",
    "            for cell in cell_measurements\n",
    "        ])\n",
    "        cell_df.to_csv(os.path.join(crop_output_dir, f\"{img_base}_crop_cells.csv\"), index=False)\n",
    "        \n",
    "        # Return info about the test\n",
    "        return {\n",
    "            'image_name': img_name,\n",
    "            'crop_region': crop_coords,\n",
    "            'cell_count': len(cell_measurements),\n",
    "            'output_dir': crop_output_dir\n",
    "        }\n",
    "\n",
    "# Test segmentation on a cropped region before full processing\n",
    "def test_segmentation_parameters(image_path, config, crop_ratio=0.1):\n",
    "    \"\"\"Test segmentation parameters on a cropped region of an image\"\"\"\n",
    "    # Create a temporary output directory\n",
    "    output_dir = os.path.join(os.path.dirname(image_path), \"segmentation_tests\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Run the crop test\n",
    "    test_result = test_segmentation_on_crop(\n",
    "        image_path=image_path,\n",
    "        output_dir=output_dir,\n",
    "        config=config,\n",
    "        crop_ratio=crop_ratio\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n✓ Segmentation test complete!\")\n",
    "    print(f\"  - Found {test_result['cell_count']} cells in the cropped region\")\n",
    "    print(f\"  - Results saved to: {test_result['output_dir']}\")\n",
    "    print(\"\\nTIP: Review the results and adjust segmentation parameters in config as needed\")\n",
    "    \n",
    "    return test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Images\n",
    "In this section firstly the configuratin will be set for the segmentation, and a test can be done for an individual file. On the second part, a batch processing of multiple files can be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the configuration for the pipeline\n",
    "config = {\n",
    "    # Hardware settings\n",
    "    'use_gpu': True,  # Set to False to force CPU processing\n",
    "    'auto_detect_gpu': True,  # Auto-detect and use GPU if available\n",
    "    \n",
    "    # CellPose settings\n",
    "    'segmentation_type': 'cyto_and_nuclei',  # or 'nuclei_only'\n",
    "    'cytoplasm_channel': 4,  # Far Red channel for cytoplasm/membrane\n",
    "    'nucleus_channel': 1,    # Blue channel (DAPI) for nuclei\n",
    "    'cell_diameter': 25.0,     # Approximate diameter in pixels\n",
    "    'flow_threshold': 0.4,   # Flow threshold for CellPose\n",
    "    'cellprob_threshold': 0.6,  # Cell probability threshold for CellPose\n",
    "    'downsample_factor': 0.5,  # Downsample factor for speed (1.0 = no downsampling)\n",
    "    \n",
    "    # Visualization settings\n",
    "    'visualize_bg': True,  # Set to False if you don't want intermediate visualizations\n",
    "    'visualize_segmentation': False,  # Show segmentation results\n",
    "    'save_qc_regions': True,  # Save QC regions for review\n",
    "    'qc_region_size': 300,  # Size of the QC region in pixels\n",
    "    \n",
    "    # Other pipeline settings\n",
    "    'channels_of_interest': [0, 1, 2, 3]  # All channels to measure\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropped segmentation and background substraction testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_test = select_folder()\n",
    "print(f'>>> Selected folder: {folder_path_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage in your script\n",
    "image_paths = glob.glob(os.path.join(folder_path_test, \"*.tiff\"))\n",
    "if len(image_paths) > 0:\n",
    "    # Test segmentation on first image before batch processing\n",
    "    test_result = test_segmentation_parameters(image_paths[0], config, crop_ratio=0.1)\n",
    "    \n",
    "else:\n",
    "    print(f\"No TIFF images found in {folder_path_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_folder = select_folder()\n",
    "print(f'>>> Selected folder: {batch_folder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all experiments in the selected folder\n",
    "batch_results = process_experiments_batch(batch_folder, config)\n",
    "print(f'>>> Batch processing complete. Results saved to: {batch_results}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.update({\n",
    "    # Parallelization settings\n",
    "    'max_workers': min(os.cpu_count(), 8),  # Maximum number of parallel workers\n",
    "    'batch_size': 4,                         # Number of images to process in a batch\n",
    "    \n",
    "    # Memory settings\n",
    "    'memory_limit_gb': None,                 # Set a memory limit in GB (None = auto)\n",
    "    'auto_batch_sizing': True,               # Automatically adjust batch size based on available memory\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all experiments in the selected folder with parallel execution\n",
    "batch_results = process_experiments_batch_parallel(batch_folder, config)\n",
    "print(f'>>> Batch processing complete. Results saved to: {batch_results}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".auto_img",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
