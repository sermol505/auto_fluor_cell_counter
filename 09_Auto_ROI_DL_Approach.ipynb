{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideal Processing Pipeline for Consistent CTCF in Fluorescence Microscopy\n",
    "\n",
    "Here's a comprehensive pipeline for analyzing fluorescence microscopy images with consistent CTCF measurement across different conditions and microscopes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tiff\n",
    "import time, os, sys\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "from skimage import measure, draw\n",
    "from skimage.transform import resize\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "import scipy.stats\n",
    "import h5py\n",
    "\n",
    "import gc\n",
    "import concurrent.futures as cf\n",
    "import multiprocessing\n",
    "import threading\n",
    "mpl.rcParams['figure.dpi'] = 200\n",
    "\n",
    "from AutoImgUtils import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2025 NVIDIA Corporation\n",
      "Built on Fri_Feb_21_20:42:46_Pacific_Standard_Time_2025\n",
      "Cuda compilation tools, release 12.8, V12.8.93\n",
      "Build cuda_12.8.r12.8/compiler.35583870_0\n",
      "Tue Apr  8 22:12:51 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 572.61                 Driver Version: 572.61         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA TITAN RTX             WDDM  |   00000000:81:00.0 Off |                  N/A |\n",
      "| 40%   39C    P8             21W /  280W |    1001MiB /  24576MiB |     18%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            5308    C+G   ...Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A            5396    C+G   ...x64__8wekyb3d8bbwe\\Photos.exe      N/A      |\n",
      "|    0   N/A  N/A            6640    C+G   ...xyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A            7304    C+G   ...h_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A            7988    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A            9120    C+G   ...Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A            9536    C+G   ...es\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A            9996    C+G   ...h_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A           11276    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           11732    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A           12164    C+G   ...crosoft\\OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A           13028    C+G   ...rage Manager\\JRE\\bin\\java.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      ">>> GPU activated? YES\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version\n",
    "!nvidia-smi\n",
    "\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import core, utils, io, models, metrics, denoise\n",
    "from glob import glob\n",
    "\n",
    "use_GPU = core.use_gpu()\n",
    "yn = ['NO', 'YES']\n",
    "print(f'>>> GPU activated? {yn[use_GPU]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_background_mask(channel_image, bg_model, output_path, n_components=3):\n",
    "    \"\"\"Visualize background mask from GMM model with distribution plots\"\"\"\n",
    "    # Create figure with 4 subplots (2x2 grid)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12), gridspec_kw={'height_ratios': [3, 1]})\n",
    "    \n",
    "    # Original image\n",
    "    axes[0, 0].imshow(channel_image, cmap='gray')\n",
    "    axes[0, 0].set_title('Original Channel')\n",
    "    plt.colorbar(axes[0, 0].get_images()[0], ax=axes[0, 0])\n",
    "    \n",
    "    # Background mask\n",
    "    axes[0, 1].imshow(bg_model['mask'], cmap='hot')\n",
    "    axes[0, 1].set_title(f'Background Mask\\nMean: {bg_model[\"mean\"]:.2f}, Std: {bg_model[\"std\"]:.2f}')\n",
    "    plt.colorbar(axes[0, 1].get_images()[0], ax=axes[0, 1])\n",
    "    \n",
    "    # Original with background highlighted\n",
    "    norm_img = (channel_image - np.min(channel_image)) / (np.max(channel_image) - np.min(channel_image))\n",
    "    rgb_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
    "    \n",
    "    # Highlight background in red\n",
    "    rgb_img[:,:,0][bg_model['mask']] = 1.0  # Set red high for background\n",
    "    rgb_img[:,:,1][bg_model['mask']] = 0.0  # Set green low for background\n",
    "    rgb_img[:,:,2][bg_model['mask']] = 0.0  # Set blue low for background\n",
    "    \n",
    "    axes[1, 0].imshow(rgb_img)\n",
    "    axes[1, 0].set_title('Background Regions (Red)')\n",
    "    \n",
    "    # Plot intensity histogram with GMM distributions\n",
    "    if 'gmm' in bg_model:\n",
    "        gmm = bg_model['gmm']\n",
    "        flat_img = channel_image.flatten()\n",
    "        \n",
    "        # Plot histogram\n",
    "        hist_range = (np.min(flat_img), np.max(flat_img))\n",
    "        n_bins = 100\n",
    "        axes[1, 1].hist(flat_img, bins=n_bins, range=hist_range, density=True, \n",
    "                       alpha=0.6, color='gray', label='Pixel Intensity')\n",
    "        \n",
    "        # Create x values for plotting GMM curves\n",
    "        x = np.linspace(hist_range[0], hist_range[1], 1000)\n",
    "        x_reshaped = x.reshape(-1, 1)\n",
    "        \n",
    "        # Plot the individual components\n",
    "        colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "        bg_component = np.argmin(gmm.means_.flatten())\n",
    "        \n",
    "        for i in range(gmm.n_components):\n",
    "            # Calculate component density\n",
    "            weight = gmm.weights_[i]\n",
    "            mean = gmm.means_[i, 0]\n",
    "            std = np.sqrt(gmm.covariances_[i, 0, 0])\n",
    "            \n",
    "            # Create a normal distribution for this component\n",
    "            y = weight * scipy.stats.norm.pdf(x, mean, std)\n",
    "            \n",
    "            # Plot with higher alpha for background component\n",
    "            alpha = 0.8 if i == bg_component else 0.5\n",
    "            label = f\"Background (μ={mean:.1f})\" if i == bg_component else f\"Component {i+1} (μ={mean:.1f})\"\n",
    "            axes[1, 1].plot(x, y, color=colors[i % len(colors)], \n",
    "                          alpha=alpha, linewidth=2, label=label)\n",
    "        \n",
    "        axes[1, 1].set_title('Pixel Intensity Distribution')\n",
    "        axes[1, 1].set_xlabel('Pixel Value')\n",
    "        axes[1, 1].set_xscale('log')\n",
    "        axes[1, 1].set_ylabel('Density')\n",
    "        axes[1, 1].legend()\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=200)\n",
    "    plt.close('all')\n",
    "    \n",
    "def create_visualization(image, masks, measurements, output_path):\n",
    "    \"\"\"Create multi-panel visualization for QC\"\"\"\n",
    "    fig, axes = plt.subplots(1, image.shape[2] + 1, figsize=(5*(image.shape[2]+1), 5))\n",
    "    \n",
    "    # Plot segmentation mask\n",
    "    axes[0].imshow(masks > 0, cmap='gray')\n",
    "    axes[0].set_title('Cell Segmentation')\n",
    "    \n",
    "    # Add cell labels\n",
    "    for cell in measurements:\n",
    "        y, x = cell['centroid']\n",
    "        axes[0].text(x, y, str(cell['label']), color='red', fontsize=5)\n",
    "    \n",
    "    # Plot each channel\n",
    "    for ch in range(image.shape[2]):\n",
    "        # Normalize channel for visualization\n",
    "        norm_channel = np.clip(normalize_img(image, method='percentile'), 0, 1)\n",
    "        \n",
    "        axes[ch+1].imshow(norm_channel, cmap='hot')\n",
    "        axes[ch+1].set_title(f'Channel {ch+1}')\n",
    "        \n",
    "        # Overlay cell outlines\n",
    "        for cell in measurements:\n",
    "            mask = masks == cell['label']\n",
    "            boundary = find_boundaries(mask)\n",
    "            axes[ch+1].imshow(boundary, alpha=0.3, cmap='cool')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_experiments_batch(main_directory, config):\n",
    "    \"\"\"\n",
    "    Process all experiments in the main directory with a robust CTCF analysis pipeline\n",
    "    \"\"\"\n",
    "    # Create results directory\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_dir = os.path.join(main_directory, f\"CTCF_Analysis_{timestamp}\")\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Find all experiment folders\n",
    "    experiment_folders = [f.path for f in os.scandir(main_directory) if f.is_dir() \n",
    "                         and not f.name.startswith('.') and not \"CTCF_Analysis\" in f.name]\n",
    "    \n",
    "    batch_results = {}\n",
    "    \n",
    "    # Process each experiment folder\n",
    "    for experiment_folder in experiment_folders:\n",
    "        exp_name = os.path.basename(experiment_folder)\n",
    "        print(f\"\\nProcessing experiment: {exp_name}\")\n",
    "        \n",
    "        # Create experiment results folder\n",
    "        exp_results_dir = os.path.join(results_dir, exp_name)\n",
    "        os.makedirs(exp_results_dir, exist_ok=True)\n",
    "        \n",
    "        # Process all images in experiment folder\n",
    "        image_files = [f for f in os.listdir(experiment_folder) \n",
    "                      if f.endswith(('.tif', '.tiff')) and not f.startswith('.')]\n",
    "        \n",
    "        exp_results = []\n",
    "        \n",
    "        for image_file in image_files:\n",
    "            # Full image processing pipeline for each image\n",
    "            img_result = process_single_image(\n",
    "                os.path.join(experiment_folder, image_file),\n",
    "                exp_results_dir,\n",
    "                config\n",
    "            )\n",
    "            exp_results.append(img_result)\n",
    "        \n",
    "        # Compile experiment results\n",
    "        exp_df = pd.DataFrame(exp_results)\n",
    "        exp_df.to_csv(os.path.join(exp_results_dir, f\"{exp_name}_results.csv\"), index=False)\n",
    "        batch_results[exp_name] = exp_df\n",
    "    \n",
    "    # Compile batch summary\n",
    "    all_results = pd.concat([df for df in batch_results.values()], keys=batch_results.keys())\n",
    "    all_results.to_csv(os.path.join(results_dir, \"batch_summary.csv\"))\n",
    "    \n",
    "    return batch_results\n",
    "\n",
    "def resample_image(image, scale_factor=0.5):\n",
    "    \"\"\"Resample image by the given scale factor\"\"\"\n",
    "    \n",
    "    # Get original dimensions\n",
    "    h, w, c = image.shape\n",
    "    \n",
    "    # Calculate new dimensions\n",
    "    new_h, new_w = int(h * scale_factor), int(w * scale_factor)\n",
    "    \n",
    "    # Resize image\n",
    "    resized = resize(image, (new_h, new_w, c), preserve_range=True, anti_aliasing=True)\n",
    "    \n",
    "    return resized.astype(image.dtype)\n",
    "\n",
    "\n",
    "def process_single_image(image_path, output_dir, config):\n",
    "    \"\"\"Process a single fluorescence microscopy image for CTCF analysis\"\"\"\n",
    "    # Load image and normalize channels\n",
    "    image = tiff.imread(image_path)\n",
    "    img_name = os.path.basename(image_path)\n",
    "    img_base = os.path.splitext(img_name)[0]\n",
    "\n",
    "    print(f\"\\nProcessing image: {img_name}\")\n",
    "    \n",
    "    # Move the shortest axis (channels) to the last index\n",
    "    shortest_axis = np.argmin(image.shape)\n",
    "    image = np.moveaxis(image, shortest_axis, -1)\n",
    "    \n",
    "    # Extract configuration\n",
    "    channels_of_interest = config.get('channels_of_interest', list(range(image.shape[-1])))\n",
    "    \n",
    "    # 1. BACKGROUND ESTIMATION USING GMM\n",
    "    print(\"Estimating background using GMM...\")\n",
    "    bg_models = {}\n",
    "    for ch in tqdm(range(image.shape[-1]), desc=\"Background estimation\", leave=False):\n",
    "        bg_models[ch] = fast_estimate_background_gmm(image[:,:,ch])\n",
    "        # Save background mask visualization\n",
    "        if config.get('visualize_steps', True):\n",
    "            visualize_background_mask(image[:,:,ch], bg_models[ch], \n",
    "                                     os.path.join(output_dir, f\"{img_base}_bg_mask_ch{ch+1}.png\"))\n",
    "    print(\"Background estimation complete.\")\n",
    "  \n",
    "    \n",
    "    # 2. CELL SEGMENTATION USING CELLPOSE\n",
    "    cell_masks = segment_cells_with_downsampling(image, config)\n",
    "\n",
    "    # 3. MEASURE CTCF FOR EACH CELL AND CHANNEL\n",
    "    cell_measurements = measure_cells_ctcf(image, cell_masks, bg_models)\n",
    "    \n",
    "    # 4. GENERATE VISUALIZATIONS\n",
    "    create_visualization(image, cell_masks, cell_measurements, \n",
    "                         os.path.join(output_dir, os.path.basename(image_path) + \"_analysis.png\"))\n",
    "    \n",
    "    # 5. SAVE RESULTS\n",
    "    img_name = os.path.basename(image_path)\n",
    "    results = {\n",
    "        'image_name': img_name,\n",
    "        'total_cells': len(cell_measurements),\n",
    "        'image_path': image_path,\n",
    "    }\n",
    "    \n",
    "    # Add summarized measurements\n",
    "    for ch in channels_of_interest:\n",
    "        ch_ctcf = [cell['ctcf'][ch] for cell in cell_measurements]\n",
    "        results[f'channel_{ch+1}_mean_ctcf'] = np.mean(ch_ctcf)\n",
    "        results[f'channel_{ch+1}_median_ctcf'] = np.median(ch_ctcf)\n",
    "        results[f'channel_{ch+1}_std_ctcf'] = np.std(ch_ctcf)\n",
    "    \n",
    "    # Save detailed cell measurements\n",
    "    cell_df = pd.DataFrame([\n",
    "        {\n",
    "            'image': img_name,\n",
    "            'cell_id': i,\n",
    "            'area': cell['area'],\n",
    "            **{f'channel_{ch+1}_ctcf': cell['ctcf'][ch] for ch in channels_of_interest},\n",
    "            **{f'channel_{ch+1}_mean': cell['mean'][ch] for ch in channels_of_interest},\n",
    "            'centroid_x': cell['centroid'][0],\n",
    "            'centroid_y': cell['centroid'][1]\n",
    "        }\n",
    "        for i, cell in enumerate(cell_measurements)\n",
    "    ])\n",
    "    cell_df.to_csv(os.path.join(output_dir, f\"{os.path.splitext(img_name)[0]}_cells.csv\"), index=False)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def fast_estimate_background_gmm(channel_image, n_components=3, sample_ratio=0.1, max_iter=100):\n",
    "    \"\"\"\n",
    "    Faster background estimation using GMM with downsampling\n",
    "    \n",
    "    Parameters:\n",
    "    - channel_image: 2D array with image channel\n",
    "    - n_components: Number of GMM components\n",
    "    - sample_ratio: Fraction of pixels to sample (smaller = faster)\n",
    "    - max_iter: Maximum EM iterations\n",
    "    \"\"\"\n",
    "    # Flatten image\n",
    "    flat_img = channel_image.flatten()\n",
    "    \n",
    "    # Downsample by random sampling (much faster)\n",
    "    n_samples = max(10000, int(sample_ratio * flat_img.size))\n",
    "    indices = np.random.choice(flat_img.size, size=n_samples, replace=False)\n",
    "    sample_data = flat_img[indices].reshape(-1, 1)\n",
    "    \n",
    "    # Initialize with K-means for faster convergence\n",
    "    kmeans = KMeans(n_clusters=n_components, n_init=1, max_iter=100)\n",
    "    kmeans.fit(sample_data)\n",
    "    \n",
    "    # Configure GMM with performance parameters\n",
    "    gmm = GaussianMixture(\n",
    "        n_components=n_components,\n",
    "        random_state=42,\n",
    "        n_init=1,\n",
    "        max_iter=max_iter,\n",
    "        tol=1e-3,\n",
    "        init_params='kmeans'\n",
    "    )\n",
    "    \n",
    "    # Fit on sample data\n",
    "    gmm.fit(sample_data)\n",
    "    \n",
    "    # Get background component (lowest mean)\n",
    "    means = gmm.means_.flatten()\n",
    "    bg_component = np.argmin(means)\n",
    "    bg_mean = means[bg_component]\n",
    "    bg_std = np.sqrt(gmm.covariances_[bg_component].flatten()[0])\n",
    "    \n",
    "    # Predict on full image for mask\n",
    "    pixel_labels = gmm.predict(flat_img.reshape(-1, 1))\n",
    "    bg_mask = (pixel_labels == bg_component).reshape(channel_image.shape)\n",
    "    \n",
    "    return {\n",
    "        'mean': bg_mean,\n",
    "        'std': bg_std,\n",
    "        'mask': bg_mask,\n",
    "        'gmm': gmm,\n",
    "        'bg_percentage': np.sum(bg_mask) / bg_mask.size * 100,\n",
    "        'component_means': means,\n",
    "        'n_components': n_components,\n",
    "        'bg_component': bg_component\n",
    "    }\n",
    "\n",
    "def estimate_background_gmm(channel_image, n_components=3, adaptive=False, max_components=6):\n",
    "    \"\"\"\n",
    "    Estimate background using Gaussian Mixture Model\n",
    "    \n",
    "    Parameters:\n",
    "    - channel_image: 2D array with image channel\n",
    "    - n_components: Number of GMM components (default=3)\n",
    "    - adaptive: If True, select optimal components using BIC (default=False)\n",
    "    - max_components: Maximum number of components to try if adaptive=True\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with background statistics and fitted GMM model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Flatten image for GMM\n",
    "    flat_img = channel_image.flatten().reshape(-1, 1)\n",
    "    \n",
    "    # If adaptive component selection is requested\n",
    "    if adaptive:\n",
    "        bic_scores = []\n",
    "        models = []\n",
    "        \n",
    "        # Try different numbers of components\n",
    "        for n in range(1, max_components + 1):\n",
    "            gmm = GaussianMixture(n_components=n, random_state=42, n_init=3)\n",
    "            gmm.fit(flat_img)\n",
    "            bic_scores.append(gmm.bic(flat_img))\n",
    "            models.append(gmm)\n",
    "        \n",
    "        # Select model with lowest BIC score\n",
    "        best_idx = np.argmin(bic_scores)\n",
    "        gmm = models[best_idx]\n",
    "        n_components = best_idx + 1  # Update n_components to the selected value\n",
    "        print(f\"Adaptive GMM selected {n_components} components with BIC: {bic_scores[best_idx]:.2f}\")\n",
    "    else:\n",
    "        # Fit GMM model with specified components\n",
    "        gmm = GaussianMixture(n_components=n_components, random_state=42, n_init=3)\n",
    "        gmm.fit(flat_img)\n",
    "    \n",
    "    # Identify background component (lowest mean)\n",
    "    means = gmm.means_.flatten()\n",
    "    bg_component = np.argmin(means)\n",
    "    \n",
    "    # Get background statistics\n",
    "    bg_mean = means[bg_component]\n",
    "    bg_std = np.sqrt(gmm.covariances_[bg_component].flatten()[0])\n",
    "    \n",
    "    # Create background mask \n",
    "    pixel_labels = gmm.predict(flat_img)\n",
    "    bg_mask = (pixel_labels == bg_component).reshape(channel_image.shape)\n",
    "    \n",
    "    # Calculate background percentage\n",
    "    bg_percentage = np.sum(bg_mask) / bg_mask.size * 100\n",
    "    \n",
    "    return {\n",
    "        'mean': bg_mean,\n",
    "        'std': bg_std,\n",
    "        'mask': bg_mask,\n",
    "        'gmm': gmm,  # Store the fitted model\n",
    "        'bg_percentage': bg_percentage,\n",
    "        'component_means': means,\n",
    "        'n_components': n_components,\n",
    "        'bg_component': bg_component\n",
    "    }\n",
    "\n",
    "def segment_cells_cellpose(image, config):\n",
    "    \"\"\"\n",
    "    Optimized cell segmentation using CellPose with proper channel mapping\n",
    "    \n",
    "    Parameters:\n",
    "    - image: multi-channel image\n",
    "    - config: dict with channel mappings and model settings\n",
    "    \"\"\"\n",
    "\n",
    "    io.logger_setup()\n",
    "    \n",
    "    # Extract the right channels based on your staining\n",
    "    cyto_channel_idx = config.get('cytoplasm_channel', 4)  # Default to channel 4 (Far Red)\n",
    "    nuc_channel_idx = config.get('nucleus_channel', 1)     # Default to channel 1 (Blue)\n",
    "    \n",
    "    # Get the right model based on what's visible in your images\n",
    "    if config.get('segmentation_type') == 'nuclei_only':\n",
    "        model = models.CellposeDenoiseModel(model_type='nuclei', gpu=config.get('use_gpu', True), restore_type = 'denoise_nuclei')\n",
    "        # For nuclei-only segmentation, use the same channel twice\n",
    "        cellpose_channels = [0, 0]\n",
    "        img_to_segment = image[:,:,nuc_channel_idx]\n",
    "    else:\n",
    "        # For cytoplasm+nuclei segmentation\n",
    "        model = models.Cellpose(gpu=config.get('use_gpu', True), model_type=\"cyto3\")\n",
    "        img_to_segment = image\n",
    "        cellpose_channels = [nuc_channel_idx, cyto_channel_idx]  # Tell CellPose which is which\n",
    "    \n",
    "    \n",
    "    # Run segmentation with optimized parameters\n",
    "    diameter = config.get('cell_diameter', 30)\n",
    "    flow_th = config.get('flow_threshold', 0.4)\n",
    "    cell_prob_th = config.get('cellprob_threshold', 0.0)\n",
    "\n",
    "    masks, flows, styles, imgs_dn = model.eval(\n",
    "        img_to_segment, \n",
    "        channels=cellpose_channels,\n",
    "        channel_axis=-1,\n",
    "        normalize=True,\n",
    "        diameter=diameter,\n",
    "        flow_threshold=flow_th,\n",
    "        cellprob_threshold= cell_prob_th\n",
    "    )\n",
    "    \n",
    "    return masks\n",
    "\n",
    "def segment_cells_with_downsampling(image, config):\n",
    "    \"\"\"Segment cells with optional downsampling for speed\"\"\"\n",
    "    # Get downsampling factor from config\n",
    "    downsample_factor = config.get('downsample_factor', 1.0)\n",
    "    \n",
    "    # Skip if no downsampling requested\n",
    "    if downsample_factor >= 1.0:\n",
    "        return segment_cells_cellpose(image, config)\n",
    "    \n",
    "    # Downsample image\n",
    "    small_image = resample_image(image, downsample_factor)\n",
    "    \n",
    "    # Adjust cell diameter for downsampled image\n",
    "    small_config = config.copy()\n",
    "    small_config['cell_diameter'] = config.get('cell_diameter', 30) * downsample_factor\n",
    "    \n",
    "    # Run segmentation on smaller image\n",
    "    small_masks = segment_cells_cellpose(small_image, small_config)\n",
    "    \n",
    "    # Upsample masks to original size\n",
    "    masks_upscaled = resize(small_masks, image.shape[0:2], order=0, preserve_range=True)\n",
    "    \n",
    "    # Post-process to ensure integer labels are preserved\n",
    "    masks_upscaled = masks_upscaled.astype(np.int32)\n",
    "    \n",
    "    return masks_upscaled\n",
    "\n",
    "def measure_cells_ctcf(image, cell_masks, bg_models):\n",
    "    \"\"\"Measure CTCF for all cells and channels\"\"\"\n",
    "    # Get properties of each cell\n",
    "    props = measure.regionprops(cell_masks)\n",
    "    measurements = []\n",
    "    \n",
    "    for prop in props:\n",
    "        # Basic cell properties\n",
    "        cell_data = {\n",
    "            'label': prop.label,\n",
    "            'area': prop.area,\n",
    "            'centroid': prop.centroid,\n",
    "            'ctcf': {},\n",
    "            'mean': {},\n",
    "            'total': {},\n",
    "            'bg_value': {}\n",
    "        }\n",
    "        \n",
    "        # Get cell mask\n",
    "        mask = cell_masks == prop.label\n",
    "        \n",
    "        # Calculate measurements for each channel\n",
    "        for ch in range(image.shape[-1]):\n",
    "            # Extract channel and cell region\n",
    "            channel = image[:,:,ch]\n",
    "            cell_region = channel[mask]\n",
    "            \n",
    "            # Background value\n",
    "            bg_value = bg_models[ch]['mean']\n",
    "            cell_data['bg_value'][ch] = bg_value\n",
    "            \n",
    "            # Calculate measurements\n",
    "            total_intensity = np.sum(cell_region)\n",
    "            mean_intensity = np.mean(cell_region)\n",
    "            \n",
    "            # CTCF = Integrated Density - (Area × Mean Background)\n",
    "            ctcf = total_intensity - (prop.area * bg_value)\n",
    "            \n",
    "            # Store results\n",
    "            cell_data['total'][ch] = total_intensity\n",
    "            cell_data['mean'][ch] = mean_intensity\n",
    "            cell_data['ctcf'][ch] = ctcf\n",
    "        \n",
    "        measurements.append(cell_data)\n",
    "    \n",
    "    return measurements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Selected folder: H:/01_Colaboration/02_Slide_Scanner/20250605_TestFolder\n"
     ]
    }
   ],
   "source": [
    "folder_path = select_folder()\n",
    "print(f'>>> Selected folder: {folder_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the configuration for the pipeline\n",
    "config = {\n",
    "    # CellPose settings\n",
    "    'segmentation_type': 'cyto_and_nuclei',  # or 'nuclei_only'\n",
    "    'cytoplasm_channel': 4,  # Far Red channel for cytoplasm/membrane\n",
    "    'nucleus_channel': 1,    # Blue channel (DAPI) for nuclei\n",
    "    'cell_diameter': 20,     # Approximate diameter in pixels\n",
    "    'use_gpu': True,         # Use GPU acceleration\n",
    "    'flow_threshold': 0.4,   # Flow threshold for CellPose\n",
    "    'cellprob_threshold': 0.0,  # Cell probability threshold for CellPose\n",
    "    'downsample_factor': 0.5,  # Downsample factor for speed (1.0 = no downsampling)\n",
    "    \n",
    "    # Visualization settings\n",
    "    'visualize_steps': True,  # Set to False if you don't want intermediate visualizations\n",
    "    \n",
    "    # Other pipeline settings\n",
    "    'channels_of_interest': [0, 1, 2, 3]  # All channels to measure\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing experiment: Exp1\n",
      "\n",
      "Processing image: EXP10_2_1_1_1_2_3_scFl_DoxCont_Light-OME_s5.ome.tiff\n",
      "Estimating background using GMM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Background estimation:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Process all experiments in the selected folder\n",
    "batch_results = process_experiments_batch(folder_path, config)\n",
    "print(f'>>> Batch processing complete. Results saved to: {batch_results}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".auto_img",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
